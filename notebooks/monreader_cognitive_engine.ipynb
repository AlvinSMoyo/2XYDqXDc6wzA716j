{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e859ad2e",
      "metadata": {
        "id": "e859ad2e"
      },
      "source": [
        "# üìò MonReader Project Overview\n",
        "*The MonReader project is an end-to-end exploration of building an AI-powered accessibility tool. What begins as a computer vision challenge‚Äîteaching a machine to know when a book page is still and ready to be read‚Äîevolves into a sophisticated multi-modal pipeline. Using a Shona hymnbook as our guide, we move from simple image classification to the complex tasks of transcription and translation analysis, testing the limits of modern AI. The final phase will transform this silent text into a synthesized voice, completing the core mission: to turn the printed word into an accessible, audible experience for everyone.*\n",
        "\n",
        "---\n",
        "**Background:**\n",
        "\n",
        ">Our company develops innovative Artificial Intelligence and Computer Vision solutions that revolutionize industries. Machines that can see: We pack our solutions in small yet intelligent devices that can be easily integrated to your existing data flow. Computer vision for everyone: Our devices can recognize faces, estimate age and gender, classify clothing types and colors, identify everyday objects and detect motion. Technical consultancy: We help you identify use cases of artificial intelligence and computer vision in your industry. Artificial intelligence is the technology of today, not the future.\n",
        "\n",
        ">MonReader is a new mobile document digitization experience for the blind, for researchers and for everyone else in need for fully automatic, highly fast and high-quality document scanning in bulk. It is composed of a mobile app and all the user needs to do is flip pages and everything is handled by MonReader: it detects page flips from low-resolution camera preview and takes a high-resolution picture of the document, recognizing its corners and crops it accordingly, and it dewarps the cropped document to obtain a bird's eye view, sharpens the contrast between the text and the background and finally recognizes the text with formatting kept intact, being further corrected by MonReader's ML powered redactor.\n",
        "\n",
        "**Data Description:**\n",
        "\n",
        ">We collected page flipping video from smart phones and labelled them as flipping and not flipping.\n",
        "\n",
        ">We clipped the videos as short videos and labelled them as flipping or not flipping. The extracted frames are then saved to disk in a sequential order with the following naming structure: VideoID_FrameNumber\n",
        "\n",
        "**Download Data:**\n",
        "\n",
        "*Dataset = Images.zip*\n",
        "\n",
        "**Goal(s):**\n",
        "\n",
        "- Predict if the page is being flipped using a single image.\n",
        "\n",
        "**Success Metrics:**\n",
        "\n",
        "- Evaluate model performance based on F1 score, the higher the better.\n",
        "\n",
        "**Current Challenges:**\n",
        "\n",
        "- Predict if a given sequence of images contains an action of flipping.\n",
        "\n",
        "**Submission Instructions:**\n",
        "- Project should be implemented with **Python**\n",
        "- Please name your repository on GitHub ___ without exposing your project information\n",
        "\n",
        "---\n",
        "# üì∏ Phase 1\n",
        "\n",
        "## üìë Table of Contents\n",
        "1. [üì∏ Phase 1: Image Classification Pipeline](#phase1)\n",
        "   - [1.1: Load Dependencies](#step1)\n",
        "   - [1.2: Exploratory Data Analysis](#step2)\n",
        "   - [1.3: Dataset Preparation](#step3)\n",
        "   - [1.4: Utilities and Validation Split](#step4)\n",
        "   - [1.5.1: MobileNetV2 (Transfer Learning)](#step5a)\n",
        "   - [1.5.2: ResNet18 (Transfer Learning)](#step5b)\n",
        "   - [1.5.3: EfficientNet-B0 (Transfer Learning)](#step5c)\n",
        "   - [1.6: Model Performance Comparison](#step6)\n",
        "   - [1.7: Grad-CAM Visualization](#step7)\n",
        "   - [1.8: Custom CNN - AlvinNetBinary](#step8)\n",
        "   - [1.9: Executive Summary](#step9)\n",
        "\n",
        "---\n",
        "\n",
        "# üì∏ Phase 1: Image Classification Pipeline\n",
        "\n",
        "A deep learning pipeline for detecting page flipping events using image frames extracted from video. This classification system acts as the **first stage** of the MonReader vision workflow ‚Äî helping identify the right moment to capture a document page.\n",
        "\n",
        "We evaluated multiple pretrained architectures (MobileNetV2, ResNet18, EfficientNet-B0) using transfer learning, then designed and trained a **custom CNN (AlvinNet)** to explore lean model design. Finally, we tuned AlvinNet using the **Lion optimizer** to test the effects of cutting-edge training strategies.\n",
        "\n",
        "Interpretability techniques (Grad-CAM++) were applied to confirm the models focused on relevant visual features.\n",
        "\n",
        "The outcome: a production-ready classifier that reliably distinguishes ‚Äúflip‚Äù from ‚Äúnotflip‚Äù with **>99% F1 score**, enabling robust automation of the next phase: **OCR & Text Extraction**.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2aed95e",
      "metadata": {
        "id": "b2aed95e"
      },
      "source": [
        "## üìÇ 1.1: Load Dependencies, Fix Seed & Mount Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- üîß Install Dependencies ---\n",
        "\n",
        "# ‚úÖ Clean install: Torch + TorchVision (CUDA 12.1), TorchCAM, compatible NumPy\n",
        "!pip install -q torch==2.2.2+cu121 torchvision==0.17.2+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html\n",
        "!pip install -q torchcam matplotlib seaborn --user\n",
        "!pip install -q numpy==1.26.4 --user # ‚úÖ Avoid ABI conflicts with PyTorch\n",
        "!pip install lion-pytorch -q --user # ‚úÖ Install Lion for\n",
        "\n",
        "\n",
        "# ‚úÖ Restart runtime after NumPy downgrade (Colab will crash here ON PURPOSE)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "yKZ5ssXaw29H"
      },
      "id": "yKZ5ssXaw29H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üé≤ Seed Selection Note\n",
        "\n",
        "To ensure reproducibility and controlled randomness, the global seed for this notebook was **randomly drawn** from the range `1000‚Äì9999` using:\n",
        "\n",
        "```python\n",
        "import random\n",
        "seed_range = range(1000, 10000)\n",
        "selected_seed = random.choice(seed_range)\n",
        "print(\"üé≤ Selected Seed:\", selected_seed)\n",
        "\n",
        ">üé≤ **Selected Seed:** 9691"
      ],
      "metadata": {
        "id": "aksBgAn6WsgR"
      },
      "id": "aksBgAn6WsgR"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ‚úÖ Fixed Seed (drawn from controlled process above) ---\n",
        "SEED = 9691\n",
        "\n",
        "def set_global_seed(seed=SEED):\n",
        "    import torch, numpy as np, random\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_global_seed()"
      ],
      "metadata": {
        "id": "vQPyl0k3V1ES"
      },
      "id": "vQPyl0k3V1ES",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f14a817",
      "metadata": {
        "id": "4f14a817"
      },
      "outputs": [],
      "source": [
        "# Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "221d7d66",
      "metadata": {
        "id": "221d7d66"
      },
      "outputs": [],
      "source": [
        "# --- Define the path to zip file on Google Drive ---\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Paths\n",
        "zip_path = '/content/drive/MyDrive/Colab_Notebooks/images.zip'\n",
        "extract_dir = '/content/images_data'\n",
        "\n",
        "# Unzip\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "# List the contents\n",
        "os.listdir(extract_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16da52b3",
      "metadata": {
        "id": "16da52b3"
      },
      "source": [
        "## üîç 1.2: Exploratory Data Analysis\n",
        "We begin with basic dataset inspection:\n",
        "- Sample file structure\n",
        "- Class distributions\n",
        "- Example images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74970dcd",
      "metadata": {
        "id": "74970dcd"
      },
      "outputs": [],
      "source": [
        " # Should show: ['train', 'test']\n",
        "import os\n",
        "root_dir = '/content/images_data/images'\n",
        "os.listdir(root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a91481e2",
      "metadata": {
        "id": "a91481e2"
      },
      "outputs": [],
      "source": [
        "# --- Create Transformers and Dataloaders ---\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch # Added this import\n",
        "\n",
        "# Paths\n",
        "train_dir = '/content/images_data/images/training'\n",
        "test_dir = '/content/images_data/images/testing'\n",
        "\n",
        "# Transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Dataset and Split\n",
        "train_full = datasets.ImageFolder(train_dir, transform=train_transform)\n",
        "test_data = datasets.ImageFolder(test_dir, transform=test_transform)\n",
        "\n",
        "val_size = int(0.2 * len(train_full))\n",
        "train_size = len(train_full) - val_size\n",
        "\n",
        "# ‚úÖ Use fixed seed to ensure reproducibility\n",
        "train_data, val_data = random_split(\n",
        "    train_full,\n",
        "    [train_size, val_size],\n",
        "    generator=torch.Generator().manual_seed(SEED)\n",
        ")\n",
        "\n",
        "# Dataloaders\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=32)\n",
        "test_loader = DataLoader(test_data, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4decccfa",
      "metadata": {
        "id": "4decccfa"
      },
      "outputs": [],
      "source": [
        "# --- Distribution of Train and Test sets ---\n",
        "import numpy as np\n",
        "all_train_labels = []\n",
        "for _, labels in train_loader:\n",
        "    all_train_labels.extend(labels.numpy())\n",
        "\n",
        "all_test_labels = []\n",
        "for _, labels in test_loader:\n",
        "    all_test_labels.extend(labels.numpy())\n",
        "\n",
        "# Count occurrences\n",
        "train_counts = np.bincount(all_train_labels)\n",
        "test_counts = np.bincount(all_test_labels)\n",
        "\n",
        "# Print class counts\n",
        "print(f\"Train counts (flip = 0, notflip = 1): {train_counts}\")\n",
        "print(f\"Test counts  (flip = 0, notflip = 1): {test_counts}\")\n",
        "\n",
        "# Ratios\n",
        "train_ratio = train_counts / train_counts.sum()\n",
        "test_ratio = test_counts / test_counts.sum()\n",
        "print(\"\\nTrain Ratios:\", train_ratio)\n",
        "print(\"Test Ratios:\", test_ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "500d4059",
      "metadata": {
        "id": "500d4059"
      },
      "outputs": [],
      "source": [
        "# Inspect label-to-class mapping:\n",
        "print(\"Class Mapping:\", train_full.class_to_idx)\n",
        "# e.g. {'flip': 0, 'notflip': 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42b98f6c",
      "metadata": {
        "id": "42b98f6c"
      },
      "outputs": [],
      "source": [
        "# --- üñºÔ∏è Visualize sample from Train set ---\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# üîÅ Get a batch of images and labels from the training loader\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "# üñºÔ∏è Plot the first 9 images\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "\n",
        "    # üîÑ Convert from [C, H, W] to [H, W, C] for matplotlib\n",
        "    img = images[i].permute(1, 2, 0)\n",
        "\n",
        "    # Optional: Unnormalize if needed here\n",
        "    def unnormalize(img_tensor):\n",
        "        mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 1, 3) # Reshape mean to [1, 1, 3]\n",
        "        std = torch.tensor([0.229, 0.224, 0.225]).view(1, 1, 3)   # Reshape std to [1, 1, 3]\n",
        "        return img_tensor * std + mean\n",
        "\n",
        "    # Apply unnormalization\n",
        "    img = unnormalize(img)\n",
        "\n",
        "\n",
        "    # üè∑Ô∏è Map class index to label\n",
        "    class_label = 'flip' if labels[i] == 0 else 'notflip'\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.title(class_label, fontsize=12)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- üñºÔ∏è Visualize sample from Test set ---\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# üîÅ Get a batch of test images and labels\n",
        "test_images, test_labels = next(iter(test_loader))\n",
        "\n",
        "# üñºÔ∏è Plot the first 9 test images\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "\n",
        "    # üîÑ Convert from [C, H, W] to [H, W, C]\n",
        "    img = test_images[i].permute(1, 2, 0)\n",
        "\n",
        "    # Optional: Unnormalize if needed here\n",
        "    def unnormalize(img_tensor):\n",
        "        mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 1, 3)\n",
        "        std = torch.tensor([0.229, 0.224, 0.225]).view(1, 1, 3)\n",
        "        return img_tensor * std + mean\n",
        "\n",
        "    # Apply unnormalization\n",
        "    img = unnormalize(img)\n",
        "\n",
        "\n",
        "    # üè∑Ô∏è Map label\n",
        "    class_label = 'flip' if test_labels[i] == 0 else 'notflip'\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.title(f'Test: {class_label}', fontsize=12)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wQAwk3x1I1Kb"
      },
      "id": "wQAwk3x1I1Kb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß™ 1.3: Dataset Preparation\n",
        "\n",
        "We now define the image transformation pipeline and prepare PyTorch `ImageFolder` datasets along with `DataLoaders` for training and testing.\n",
        "\n",
        "Key steps:\n",
        "- Resize and normalize images\n",
        "- Apply minimal augmentation to training data\n",
        "- Set appropriate batch size and shuffling\n",
        "- Prepare loaders for efficient iteration during training"
      ],
      "metadata": {
        "id": "cf1piNmWIoLj"
      },
      "id": "cf1piNmWIoLj"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- üîí Set Global Seed for Reproducibility ---\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "SEED = 9691\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "mvywOYSpbNnf"
      },
      "id": "mvywOYSpbNnf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- üß™ Data Preparation ---\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# ‚úÖ Set seed for reproducibility\n",
        "SEED = 9691\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# ‚úÖ Create torchvision-compatible generator\n",
        "torchvision_rng = torch.Generator().manual_seed(SEED)\n",
        "\n",
        "# ‚úÖ Reproducible worker init function\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = SEED + worker_id\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "# ‚úÖ Set parameters\n",
        "image_size = 224        # EfficientNet-friendly size\n",
        "batch_size = 32\n",
        "\n",
        "# ‚úÖ Define transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.RandomHorizontalFlip(),  # Will now be deterministic\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ‚úÖ Dataset paths\n",
        "train_dir = '/content/images_data/images/training'\n",
        "test_dir = '/content/images_data/images/testing'\n",
        "\n",
        "# ‚úÖ Load datasets\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transforms)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=test_transforms)\n",
        "\n",
        "# ‚úÖ DataLoaders with reproducibility\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=torchvision_rng\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "# ‚úÖ Show class mapping\n",
        "print(\"Class Mapping:\", train_dataset.class_to_idx)"
      ],
      "metadata": {
        "id": "njKckN_GIpIy"
      },
      "id": "njKckN_GIpIy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† 1.4: Utilities & Validation Split\n",
        "\n",
        "Before training any models, we define core utilities for training and evaluation. This ensures we follow the same standard across MobileNetV2, ResNet18, and EfficientNet.\n",
        "\n",
        "Included here:\n",
        "- Train/Validation split from the training set\n",
        "- Accuracy and F1-score computation\n",
        "- Unified training and evaluation loop (with metrics tracking)"
      ],
      "metadata": {
        "id": "-6CkuuUjMINf"
      },
      "id": "-6CkuuUjMINf"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Splitting Test & Validation ---\n",
        "from torch.utils.data import random_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "# ‚úÖ Global seed (declared earlier in notebook)\n",
        "SEED = 9691\n",
        "\n",
        "# ‚úÖ Load raw dataset first, no transforms yet\n",
        "train_full = datasets.ImageFolder(root=train_dir)\n",
        "\n",
        "# ‚úÖ Split into train and val subsets with fixed seed\n",
        "val_size = int(0.2 * len(train_full))\n",
        "train_size = len(train_full) - val_size\n",
        "\n",
        "train_data, val_data = random_split(\n",
        "    train_full,\n",
        "    [train_size, val_size],\n",
        "    generator=torch.Generator().manual_seed(SEED)\n",
        ")\n",
        "\n",
        "# ‚úÖ Apply transforms\n",
        "train_data.dataset.transform = train_transforms\n",
        "val_data.dataset.transform = test_transforms\n",
        "\n",
        "# ‚úÖ Dataloaders\n",
        "train_loader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=torchvision_rng\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "CvgnNWbJMRNe"
      },
      "id": "CvgnNWbJMRNe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#   --- ‚úÖ Accuracy + F1 utility ---\n",
        "def evaluate_model(model, data_loader, device, criterion=None):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            if criterion:\n",
        "                loss = criterion(outputs, labels)\n",
        "                total_loss += loss.item()\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    avg_loss = total_loss / len(data_loader) if criterion else None\n",
        "    return acc, f1, avg_loss"
      ],
      "metadata": {
        "id": "1hXqINVSMYjV"
      },
      "id": "1hXqINVSMYjV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#   --- ‚úÖ Training loop (basic version) ---\n",
        "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5):\n",
        "    model.to(device)\n",
        "    history = {'train_loss': [], 'val_loss': [], 'val_acc': [], 'val_f1': []}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Evaluate on train and val sets\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        train_acc, train_f1, _ = evaluate_model(model, train_loader, device, criterion) # Unpack 3 values, ignore loss\n",
        "        val_acc, val_f1, val_loss = evaluate_model(model, val_loader, device, criterion)\n",
        "        history['val_loss'].append(val_loss)\n",
        "\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "              f\"Train Acc: {train_acc:.4f} | Train F1: {train_f1:.4f} | \"\n",
        "              f\"Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f}\")"
      ],
      "metadata": {
        "id": "d4HoJcixMltV"
      },
      "id": "d4HoJcixMltV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ 1.5: Transfer Learning with Pretrained CNNs\n",
        "> *‚ÄúHow can pre-trained models accelerate training and improve accuracy?‚Äù*\n",
        "\n",
        "Before diving into individual architectures, this section introduces the concept of **transfer learning**, which forms the backbone of modern computer vision workflows. By leveraging pretrained weights from large-scale datasets like ImageNet, we can drastically reduce training time, especially when working with smaller or domain-specific datasets.\n",
        "\n",
        "We then evaluate three widely used architectures ‚Äî **MobileNetV2**, **ResNet18**, and **EfficientNet-B0** ‚Äî using a consistent training pipeline and validation strategy. Each model is fine-tuned and assessed not only on accuracy and F1 score but also on interpretability and training behavior.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Fz_iK2iMIU64"
      },
      "id": "Fz_iK2iMIU64"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ 1.5.1: MobileNetV2\n",
        "\n",
        "MobileNetV2 is a lightweight convolutional neural network optimized for mobile and edge devices. It uses **depthwise separable convolutions** and **inverted residual blocks** to reduce parameters while maintaining performance.\n",
        "\n",
        "In this step:\n",
        "- We load pretrained ImageNet weights\n",
        "- Replace the final classifier layer for binary classification\n",
        "- Train using our unified loop"
      ],
      "metadata": {
        "id": "JxDivDGNO2ii"
      },
      "id": "JxDivDGNO2ii"
    },
    {
      "cell_type": "code",
      "source": [
        "#  --- üß± Model Definition + Transfer Learning ---\n",
        "from torchvision import models\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# ‚úÖ Load MobileNetV2 with pretrained ImageNet weights\n",
        "mobilenet = models.mobilenet_v2(pretrained=True)\n",
        "\n",
        "# ‚úÖ Freeze base layers (optional for transfer learning)\n",
        "for param in mobilenet.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# ‚úÖ Replace classifier for binary classification\n",
        "mobilenet.classifier = nn.Sequential(\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(mobilenet.last_channel, 2)  # 2 output classes: flip / notflip\n",
        ")"
      ],
      "metadata": {
        "id": "ZNhN_IdXO-1H"
      },
      "id": "ZNhN_IdXO-1H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  --- üöÄ Train MobileNetV2 ---\n",
        "# ‚úÖ Set up loss and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(mobilenet.parameters(), lr=0.001)\n",
        "\n",
        "# üöÄ Train MobileNetV2\n",
        "train_model(\n",
        "    model=mobilenet,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer,\n",
        "    criterion=criterion,\n",
        "    device=device,\n",
        "    epochs=5\n",
        ")"
      ],
      "metadata": {
        "id": "fGR8-pVuPMER"
      },
      "id": "fGR8-pVuPMER",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìà MobileNetV2 ‚Äì Training & Validation Performance\n",
        "\n",
        "Let‚Äôs plot loss and accuracy trends across epochs to understand the model‚Äôs learning behavior.\n"
      ],
      "metadata": {
        "id": "yt0AFDwhP79Y"
      },
      "id": "yt0AFDwhP79Y"
    },
    {
      "cell_type": "code",
      "source": [
        "#   --- ‚ú® Enhanced training loop with history tracking ---\n",
        "def train_model_with_history(model, train_loader, val_loader, optimizer, criterion, device, epochs=5):\n",
        "    model.to(device)\n",
        "    history = {'train_loss': [], 'val_loss': [], 'val_acc': [], 'val_f1': [], 'train_acc': [], 'train_f1': []}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0  # ‚úÖ Correctly initialized here\n",
        "        all_preds_train, all_labels_train = [], []\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Capture training predictions & labels for metrics calculation\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds_train.extend(preds.cpu().numpy())\n",
        "            all_labels_train.extend(labels.cpu().numpy())\n",
        "\n",
        "        # ‚úÖ Compute avg loss now\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "        # Calculate training accuracy & F1 after each epoch\n",
        "        train_acc = accuracy_score(all_labels_train, all_preds_train)\n",
        "        train_f1 = f1_score(all_labels_train, all_preds_train, average='macro')\n",
        "        val_acc, val_f1, val_loss = evaluate_model(model, val_loader, device, criterion)\n",
        "\n",
        "        history['train_loss'].append(avg_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['val_f1'].append(val_f1)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['train_f1'].append(train_f1)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {avg_loss:.4f} | Train Acc: {train_acc:.4f} | Train F1: {train_f1:.4f} | Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f}\")\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "codhqH_nP9Bi"
      },
      "id": "codhqH_nP9Bi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Train MobileNetV2 with history logging\n",
        "mobilenet_history = train_model_with_history(\n",
        "    model=mobilenet,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer,\n",
        "    criterion=criterion,\n",
        "    device=device,\n",
        "    epochs=5\n",
        ")"
      ],
      "metadata": {
        "id": "Uh_WluWUQWrx"
      },
      "id": "Uh_WluWUQWrx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  --- üìä Plot performance ----\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs_range = range(1, len(mobilenet_history['train_loss']) + 1)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, mobilenet_history['train_loss'], label=\"Train Loss\", marker='o')\n",
        "plt.plot(epochs_range, mobilenet_history['val_loss'], label=\"Val Loss\", marker='x')\n",
        "plt.title(\"Fine-Tuned: Train vs Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "# Accuracy & F1\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, mobilenet_history['train_acc'], marker='s', label=\"Train Accuracy\")\n",
        "plt.plot(epochs_range, mobilenet_history['train_f1'], marker='d', label=\"Train F1 Score\")\n",
        "plt.plot(epochs_range, mobilenet_history['val_acc'], marker='o', label=\"Val Accuracy\")\n",
        "plt.plot(epochs_range, mobilenet_history['val_f1'], marker='x', label=\"Val F1 Score\")\n",
        "plt.title(\"Train vs Validation Accuracy & F1\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f83is-xcQZfo"
      },
      "id": "f83is-xcQZfo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîß MobileNetV2 Fine-Tuning\n",
        "\n",
        "To further improve MobileNetV2, we now unfreeze all layers and fine-tune the model end-to-end using a lower learning rate. This allows the network to adapt ImageNet-learned features to the MonReader dataset more precisely.\n"
      ],
      "metadata": {
        "id": "koD64vyZTi3j"
      },
      "id": "koD64vyZTi3j"
    },
    {
      "cell_type": "code",
      "source": [
        "# #--- üîì Unfreeze + Re-init Optimizer (Code Cell) ---\n",
        "# ‚úÖ Unfreeze all feature layers\n",
        "for param in mobilenet.features.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# ‚úÖ New optimizer with lower LR for fine-tuning\n",
        "fine_tune_optimizer = optim.Adam(mobilenet.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "WRjyCFJKTiWM"
      },
      "id": "WRjyCFJKTiWM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #--- üîÅ Re-train with Fine-Tuning ---\n",
        "# ‚úÖ Fine-tune using the same training function\n",
        "mobilenet_ft_history = train_model_with_history(\n",
        "    model=mobilenet,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=fine_tune_optimizer,\n",
        "    criterion=criterion,\n",
        "    device=device,\n",
        "    epochs=5\n",
        ")"
      ],
      "metadata": {
        "id": "T-xnAVDOTpNU"
      },
      "id": "T-xnAVDOTpNU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  --- üìä Fine-Tuning Visuals ---\n",
        "# üìà Compare post-fine-tuning performance\n",
        "epochs_range = range(1, len(mobilenet_ft_history['train_loss']) + 1)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# üîπ Loss Plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, mobilenet_ft_history['train_loss'], marker='o', label=\"Train Loss\")\n",
        "plt.plot(epochs_range, mobilenet_ft_history['val_loss'], marker='x', label=\"Val Loss\")\n",
        "plt.title(\"Fine-Tuned: Train vs Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# üîπ Accuracy & F1 Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, mobilenet_ft_history['train_acc'], marker='s', label=\"Train Accuracy\")\n",
        "plt.plot(epochs_range, mobilenet_ft_history['train_f1'], marker='d', label=\"Train F1 Score\")\n",
        "plt.plot(epochs_range, mobilenet_ft_history['val_acc'], marker='o', label=\"Val Accuracy\")\n",
        "plt.plot(epochs_range, mobilenet_ft_history['val_f1'], marker='x', label=\"Val F1 Score\")\n",
        "plt.title(\"Fine-Tuned: Train vs Validation Accuracy & F1\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VpaF-7buTtis"
      },
      "id": "VpaF-7buTtis",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úÖ MobileNetV2: Transfer vs Fine-Tuning Summary\n",
        "\n",
        "Transfer learning gave us a strong baseline, but fine-tuning further improved validation performance ‚Äî showing the benefit of letting the model adapt lower-level features to MonReader-specific patterns.\n",
        "\n",
        "We now move on to a deeper architecture: ResNet18.\n",
        "\n",
        "---\n",
        "## üî© 1.5.2: ResNet18\n",
        "\n",
        "ResNet18 is a deeper convolutional neural network that introduced **residual connections**, allowing gradients to flow through very deep layers without vanishing. It‚Äôs part of the ResNet family that won the 2015 ImageNet challenge.\n",
        "\n",
        "In this step:\n",
        "- We load pretrained ImageNet weights\n",
        "- Replace the classifier for binary classification\n",
        "- Perform transfer learning\n",
        "- Then fine-tune the entire network"
      ],
      "metadata": {
        "id": "8953IFwuUvjy"
      },
      "id": "8953IFwuUvjy"
    },
    {
      "cell_type": "code",
      "source": [
        "#  --- üß± Model Definition + Transfer Learning ---\n",
        "from torchvision import models\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# ‚úÖ Load pretrained ResNet18\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "# ‚úÖ Freeze base layers for transfer learning\n",
        "for param in resnet18.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# ‚úÖ Replace classifier (fully connected layer)\n",
        "num_features = resnet18.fc.in_features\n",
        "resnet18.fc = nn.Linear(num_features, 2)"
      ],
      "metadata": {
        "id": "h2MQug2jVERy"
      },
      "id": "h2MQug2jVERy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  ---üöÄ Train ResNet18 (Transfer Learning) ---\n",
        "# ‚úÖ Optimizer and loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "resnet_optimizer = optim.Adam(resnet18.fc.parameters(), lr=0.001)\n",
        "\n",
        "# ‚úÖ Train\n",
        "resnet_history = train_model_with_history(\n",
        "    model=resnet18,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=resnet_optimizer,\n",
        "    criterion=criterion,\n",
        "    device=device,\n",
        "    epochs=5\n",
        ")"
      ],
      "metadata": {
        "id": "31biLpXNVYYT"
      },
      "id": "31biLpXNVYYT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- üìä ResNet18 Transfer Learning: Unified Metrics Plot (Loss + Accuracy & F1) ---\n",
        "epochs_range = range(1, len(resnet_history['train_loss']) + 1)\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "\n",
        "# üîµ Plot 1: Train vs Validation Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, resnet_history['train_loss'], marker='o', label=\"Train Loss\")\n",
        "plt.plot(epochs_range, resnet_history['val_loss'], marker='x', label=\"Val Loss\")\n",
        "plt.title(\"ResNet18 Transfer Learning: Train vs Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# üü¢ Plot 2: Train vs Validation Accuracy & F1\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, resnet_history['train_acc'], marker='o', label=\"Train Accuracy\")\n",
        "plt.plot(epochs_range, resnet_history['val_acc'], marker='x', label=\"Val Accuracy\")\n",
        "plt.plot(epochs_range, resnet_history['train_f1'], marker='o', linestyle='--', label=\"Train F1\")\n",
        "plt.plot(epochs_range, resnet_history['val_f1'], marker='x', linestyle='--', label=\"Val F1\")\n",
        "plt.title(\"ResNet18 Transfer Learning: Accuracy & F1\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.suptitle(\"ResNet18 Transfer Learning: Train vs Validation Metrics\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LJKggfAuVjXh"
      },
      "id": "LJKggfAuVjXh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîß ResNet18 Fine-Tuning\n",
        "\n",
        "We now unfreeze all ResNet18 layers and fine-tune using a lower learning rate.\n"
      ],
      "metadata": {
        "id": "8G0u9X9FVySB"
      },
      "id": "8G0u9X9FVySB"
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Unfreeze all layers\n",
        "for param in resnet18.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# ‚úÖ New optimizer\n",
        "resnet_ft_optimizer = optim.Adam(resnet18.parameters(), lr=5e-5)\n",
        "\n",
        "# ‚úÖ Train again\n",
        "resnet_ft_history = train_model_with_history(\n",
        "    model=resnet18,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=resnet_ft_optimizer,\n",
        "    criterion=criterion,\n",
        "    device=device,\n",
        "    epochs=5\n",
        ")"
      ],
      "metadata": {
        "id": "oIDZ4H-zVzNo"
      },
      "id": "oIDZ4H-zVzNo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- üìä ResNet18 Fine-Tuning: Unified Metrics Plot (Loss + Accuracy & F1) ---\n",
        "epochs_range = range(1, len(resnet_ft_history['train_loss']) + 1)\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "\n",
        "# üîµ Plot 1: Train vs Validation Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, resnet_ft_history['train_loss'], marker='o', label=\"Train Loss\")\n",
        "plt.plot(epochs_range, resnet_ft_history['val_loss'], marker='x', label=\"Val Loss\")\n",
        "plt.title(\"ResNet18 Fine-Tuning: Train vs Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# üü¢ Plot 2: Train vs Validation Accuracy & F1\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, resnet_ft_history['train_acc'], marker='o', label=\"Train Accuracy\")\n",
        "plt.plot(epochs_range, resnet_ft_history['val_acc'], marker='x', label=\"Val Accuracy\")\n",
        "plt.plot(epochs_range, resnet_ft_history['train_f1'], marker='o', linestyle='--', label=\"Train F1\")\n",
        "plt.plot(epochs_range, resnet_ft_history['val_f1'], marker='x', linestyle='--', label=\"Val F1\")\n",
        "plt.title(\"ResNet18 Fine-Tuning: Accuracy & F1\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.suptitle(\"ResNet18 Fine-Tuning: Train vs Validation Metrics\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vNTuDKGUV4gY"
      },
      "id": "vNTuDKGUV4gY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úÖ ResNet18: Transfer vs Fine-Tuning Summary\n",
        "\n",
        "ResNet18‚Äôs deeper architecture provided better learning capacity, especially after fine-tuning. It generally improved validation F1-score and showed better generalization than MobileNetV2 in our early runs.\n",
        "\n",
        "We now move to a newer and more efficient model ‚Äî EfficientNet-B0.\n",
        "\n",
        "---\n",
        "## ‚öôÔ∏è 1.5.3: EfficientNet-B0\n",
        "\n",
        "EfficientNet is a family of CNNs developed by Google that scales depth, width, and resolution in a compound way. EfficientNet-B0 is the base model, offering **high accuracy with fewer parameters** than traditional CNNs like ResNet.\n",
        "\n",
        "In this step:\n",
        "- We load pretrained ImageNet weights for EfficientNet-B0\n",
        "- Replace the final classifier\n",
        "- Apply transfer learning\n",
        "- Then fine-tune all layers"
      ],
      "metadata": {
        "id": "Up6OiQ0bWEU6"
      },
      "id": "Up6OiQ0bWEU6"
    },
    {
      "cell_type": "code",
      "source": [
        "#  --- üß± Model Definition + Transfer Learning ---\n",
        "from torchvision import models\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# ‚úÖ Load EfficientNet-B0 with pretrained weights\n",
        "efficientnet = models.efficientnet_b0(pretrained=True)\n",
        "\n",
        "# ‚úÖ Freeze base layers\n",
        "for param in efficientnet.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# ‚úÖ Replace classifier for binary classification\n",
        "efficientnet.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.3, inplace=True),\n",
        "    nn.Linear(in_features=1280, out_features=2)\n",
        ")"
      ],
      "metadata": {
        "id": "RcPze8vgWnQo"
      },
      "id": "RcPze8vgWnQo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  --- üöÄ Train EfficientNet (Transfer Learning) ---\n",
        "# ‚úÖ Optimizer and loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "effnet_optimizer = optim.Adam(efficientnet.parameters(), lr=0.001)\n",
        "\n",
        "# ‚úÖ Train\n",
        "effnet_history = train_model_with_history(\n",
        "    model=efficientnet,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=effnet_optimizer,\n",
        "    criterion=criterion,\n",
        "    device=device,\n",
        "    epochs=5\n",
        ")"
      ],
      "metadata": {
        "id": "jRgi6dUTW3eA"
      },
      "id": "jRgi6dUTW3eA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- üìä EfficientNet-B0 Transfer Learning: Unified Metrics Plot ---\n",
        "epochs_range = range(1, len(effnet_history['train_loss']) + 1)\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "\n",
        "# üîµ Plot 1: Train vs Validation Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, effnet_history['train_loss'], marker='o', label=\"Train Loss\")\n",
        "plt.plot(epochs_range, effnet_history['val_loss'], marker='x', label=\"Val Loss\")\n",
        "plt.title(\"EfficientNet-B0 Transfer Learning: Train vs Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# üü¢ Plot 2: Accuracy & F1\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, effnet_history['train_acc'], marker='o', label=\"Train Accuracy\")\n",
        "plt.plot(epochs_range, effnet_history['val_acc'], marker='x', label=\"Val Accuracy\")\n",
        "plt.plot(epochs_range, effnet_history['train_f1'], marker='o', linestyle='--', label=\"Train F1\")\n",
        "plt.plot(epochs_range, effnet_history['val_f1'], marker='x', linestyle='--', label=\"Val F1\")\n",
        "plt.title(\"EfficientNet-B0 Transfer Learning: Accuracy & F1\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.suptitle(\"EfficientNet-B0 Transfer Learning: Train vs Validation Metrics\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i9mI3nR_XA9g"
      },
      "id": "i9mI3nR_XA9g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîß EfficientNet Fine-Tuning\n",
        "\n",
        "To unlock deeper performance, we now unfreeze all EfficientNet layers and fine-tune with a lower learning rate."
      ],
      "metadata": {
        "id": "AvCvDWbEXhIP"
      },
      "id": "AvCvDWbEXhIP"
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Unfreeze all layers\n",
        "for param in efficientnet.features.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# ‚úÖ Lower LR for fine-tuning\n",
        "effnet_ft_optimizer = optim.Adam(efficientnet.parameters(), lr=5e-5)\n",
        "\n",
        "# ‚úÖ Train again\n",
        "effnet_ft_history = train_model_with_history(\n",
        "    model=efficientnet,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=effnet_ft_optimizer,\n",
        "    criterion=criterion,\n",
        "    device=device,\n",
        "    epochs=5\n",
        ")"
      ],
      "metadata": {
        "id": "e2Dng5zlXgYP"
      },
      "id": "e2Dng5zlXgYP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- üìä EfficientNet-B0 Fine-Tuning: Unified Metrics Plot ---\n",
        "epochs_range = range(1, len(effnet_ft_history['train_loss']) + 1)\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "\n",
        "# üîµ Plot 1: Train vs Validation Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, effnet_ft_history['train_loss'], marker='o', label=\"Train Loss\")\n",
        "plt.plot(epochs_range, effnet_ft_history['val_loss'], marker='x', label=\"Val Loss\")\n",
        "plt.title(\"EfficientNet-B0 Fine-Tuning: Train vs Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# üü¢ Plot 2: Accuracy & F1\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, effnet_ft_history['train_acc'], marker='o', label=\"Train Accuracy\")\n",
        "plt.plot(epochs_range, effnet_ft_history['val_acc'], marker='x', label=\"Val Accuracy\")\n",
        "plt.plot(epochs_range, effnet_ft_history['train_f1'], marker='o', linestyle='--', label=\"Train F1\")\n",
        "plt.plot(epochs_range, effnet_ft_history['val_f1'], marker='x', linestyle='--', label=\"Val F1\")\n",
        "plt.title(\"EfficientNet-B0 Fine-Tuning: Accuracy & F1\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.suptitle(\"EfficientNet-B0 Fine-Tuning: Train vs Validation Metrics\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l3fWnaGcXprv"
      },
      "id": "l3fWnaGcXprv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úÖ EfficientNet-B0: Transfer vs Fine-Tuning Summary\n",
        "\n",
        "EfficientNet-B0 balances performance and efficiency. With fewer parameters than ResNet18, it often matches or exceeds validation F1-score when fine-tuned. This makes it a strong candidate for deployment in lightweight or mobile environments.\n",
        "\n",
        "We now move to compare all models side by side.\n",
        "\n",
        "---\n",
        "## üìä 1.6: Model Comparison & Evaluation\n",
        "\n",
        "We now compare the three CNN architectures we trained ‚Äî MobileNetV2, ResNet18, and EfficientNet-B0 ‚Äî based on validation performance. Then we evaluate the best model on the test set using a confusion matrix."
      ],
      "metadata": {
        "id": "34j62ojcZkGG"
      },
      "id": "34j62ojcZkGG"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- üìÑ Summary Table (Training, Validation & Test) ---\n",
        "import pandas as pd\n",
        "\n",
        "# ‚úÖ Evaluate all models on test set if not already done\n",
        "acc_mobilenet, f1_mobilenet, _ = evaluate_model(mobilenet, test_loader, device)\n",
        "acc_resnet18, f1_resnet18, _ = evaluate_model(resnet18, test_loader, device)\n",
        "acc_efficientnet, f1_efficientnet, _ = evaluate_model(efficientnet, test_loader, device)\n",
        "\n",
        "# ‚úÖ Build results table\n",
        "results_summary_all = pd.DataFrame({\n",
        "    \"Model\": [\"MobileNetV2\", \"ResNet18\", \"EfficientNet-B0\"],\n",
        "\n",
        "    # üîπ Transfer Learning Metrics\n",
        "    \"Train Acc (TL)\": [\n",
        "        mobilenet_history['train_acc'][-1],\n",
        "        resnet_history['train_acc'][-1],\n",
        "        effnet_history['train_acc'][-1]\n",
        "    ],\n",
        "    \"Train F1 (TL)\": [\n",
        "        mobilenet_history['train_f1'][-1],\n",
        "        resnet_history['train_f1'][-1],\n",
        "        effnet_history['train_f1'][-1]\n",
        "    ],\n",
        "    \"Val Acc (TL)\": [\n",
        "        mobilenet_history['val_acc'][-1],\n",
        "        resnet_history['val_acc'][-1],\n",
        "        effnet_history['val_acc'][-1]\n",
        "    ],\n",
        "    \"Val F1 (TL)\": [\n",
        "        mobilenet_history['val_f1'][-1],\n",
        "        resnet_history['val_f1'][-1],\n",
        "        effnet_history['val_f1'][-1]\n",
        "    ],\n",
        "\n",
        "    # üîπ Fine-Tuning Metrics (Validation Only)\n",
        "    \"Val Acc (FT)\": [\n",
        "        mobilenet_ft_history['val_acc'][-1],\n",
        "        resnet_ft_history['val_acc'][-1],\n",
        "        effnet_ft_history['val_acc'][-1]\n",
        "    ],\n",
        "    \"Val F1 (FT)\": [\n",
        "        mobilenet_ft_history['val_f1'][-1],\n",
        "        resnet_ft_history['val_f1'][-1],\n",
        "        effnet_ft_history['val_f1'][-1]\n",
        "    ],\n",
        "\n",
        "    # üîπ Final Test Set Metrics\n",
        "    \"Test Acc\": [acc_mobilenet, acc_resnet18, acc_efficientnet],\n",
        "    \"Test F1\": [f1_mobilenet, f1_resnet18, f1_efficientnet]\n",
        "})\n",
        "\n",
        "# ‚úÖ Optional rounding for presentation\n",
        "results_summary_all = results_summary_all.round(4)\n",
        "\n",
        "# ‚úÖ Display in notebook\n",
        "display(results_summary_all)"
      ],
      "metadata": {
        "id": "wOBMPTq2LfLV"
      },
      "id": "wOBMPTq2LfLV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- üìä Barplot: Test F1 Comparison ---\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "models = [\"MobileNetV2\", \"ResNet18\", \"EfficientNet-B0\"]\n",
        "test_f1s = [f1_mobilenet, f1_resnet18, f1_efficientnet]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(models, test_f1s, color='skyblue')\n",
        "plt.title(\"Test F1 Score Comparison\")\n",
        "plt.ylabel(\"F1 Score\")\n",
        "plt.ylim(0.90, 1.01)\n",
        "plt.grid(axis='y')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6-9R835iMJHC"
      },
      "id": "6-9R835iMJHC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- üìâ Line Plot (F1 Score Across Stages) ---\n",
        "import numpy as np\n",
        "\n",
        "x_labels = [\"Train (TL)\", \"Val (TL)\", \"Val (FT)\", \"Test\"]\n",
        "mobilenet_f1 = [\n",
        "    mobilenet_history['train_f1'][-1],\n",
        "    mobilenet_history['val_f1'][-1],\n",
        "    mobilenet_ft_history['val_f1'][-1],\n",
        "    f1_mobilenet\n",
        "]\n",
        "resnet_f1 = [\n",
        "    resnet_history['train_f1'][-1],\n",
        "    resnet_history['val_f1'][-1],\n",
        "    resnet_ft_history['val_f1'][-1],\n",
        "    f1_resnet18\n",
        "]\n",
        "effnet_f1 = [\n",
        "    effnet_history['train_f1'][-1],\n",
        "    effnet_history['val_f1'][-1],\n",
        "    effnet_ft_history['val_f1'][-1],\n",
        "    f1_efficientnet\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(x_labels, mobilenet_f1, marker='o', label=\"MobileNetV2\")\n",
        "plt.plot(x_labels, resnet_f1, marker='o', label=\"ResNet18\")\n",
        "plt.plot(x_labels, effnet_f1, marker='o', label=\"EfficientNet-B0\")\n",
        "plt.title(\"F1 Score Across Training Stages\")\n",
        "plt.ylabel(\"F1 Score\")\n",
        "plt.ylim(0.85, 1.01)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-kiPE80UMfFR"
      },
      "id": "-kiPE80UMfFR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a summary bar chart: Train, Val, Test\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "labels = ['MobileNetV2', 'ResNet18', 'EfficientNet-B0']\n",
        "train_f1 = [\n",
        "    mobilenet_ft_history['train_f1'][-1],\n",
        "    resnet_ft_history['train_f1'][-1],\n",
        "    effnet_ft_history['train_f1'][-1]\n",
        "]\n",
        "val_f1 = [\n",
        "    mobilenet_ft_history['val_f1'][-1],\n",
        "    resnet_ft_history['val_f1'][-1],\n",
        "    effnet_ft_history['val_f1'][-1]\n",
        "]\n",
        "test_f1 = [f1_mobilenet, f1_resnet18, f1_efficientnet]\n",
        "\n",
        "x = range(len(labels))\n",
        "width = 0.25\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar([i - width for i in x], train_f1, width=width, label='Train F1')\n",
        "plt.bar(x, val_f1, width=width, label='Val F1')\n",
        "plt.bar([i + width for i in x], test_f1, width=width, label='Test F1')\n",
        "\n",
        "plt.xticks(x, labels)\n",
        "plt.ylabel(\"F1 Score\")\n",
        "plt.title(\"Train vs Val vs Test F1 Comparison\")\n",
        "plt.ylim(0.9, 1.01)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-i-9BTKOEIt1"
      },
      "id": "-i-9BTKOEIt1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß† Key Observations\n",
        "\n",
        "- **EfficientNet-B0** consistently delivered the highest **test F1 score**, validating its strength after fine-tuning.\n",
        "- **ResNet18** improved significantly after fine-tuning, though it started off slower in transfer learning.\n",
        "- **MobileNetV2** trained quickly and performed solidly, though slightly behind EfficientNet in test generalization.\n",
        "- Across all models, **fine-tuning boosted validation and test scores**, underscoring the value of unfreezing layers and reducing learning rates."
      ],
      "metadata": {
        "id": "cpEi_LnlE0r5"
      },
      "id": "cpEi_LnlE0r5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix Display (Side-by-Side)\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# ‚úÖ Prepare subplots\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# ‚úÖ Predictions\n",
        "def get_preds(model):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "    return all_labels, all_preds\n",
        "\n",
        "# ‚úÖ Plot for MobileNetV2\n",
        "labels, preds = get_preds(mobilenet)\n",
        "cm = confusion_matrix(labels, preds)\n",
        "ConfusionMatrixDisplay(cm).plot(ax=axes[0])\n",
        "axes[0].set_title(\"MobileNetV2\")\n",
        "\n",
        "# ‚úÖ Plot for ResNet18\n",
        "labels, preds = get_preds(resnet18)\n",
        "cm = confusion_matrix(labels, preds)\n",
        "ConfusionMatrixDisplay(cm).plot(ax=axes[1])\n",
        "axes[1].set_title(\"ResNet18\")\n",
        "\n",
        "# ‚úÖ Plot for EfficientNet-B0\n",
        "labels, preds = get_preds(efficientnet)\n",
        "cm = confusion_matrix(labels, preds)\n",
        "ConfusionMatrixDisplay(cm).plot(ax=axes[2])\n",
        "axes[2].set_title(\"EfficientNet-B0\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yeux5h12W6Wc"
      },
      "id": "Yeux5h12W6Wc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üì¶ List of models with their scores\n",
        "all_models = [\n",
        "    (\"MobileNetV2\", mobilenet, mobilenet_f1[-1]),\n",
        "    (\"ResNet18\", resnet18, resnet_f1[-1]),\n",
        "    (\"EfficientNet-B0\", efficientnet, effnet_f1[-1])\n",
        "]\n",
        "\n",
        "# ‚úÖ Sort by F1 descending, then by preferred model order\n",
        "preferred_order = [\"MobileNetV2\", \"EfficientNet-B0\", \"ResNet18\"]\n",
        "\n",
        "all_models_sorted = sorted(\n",
        "    all_models,\n",
        "    key=lambda x: (-x[2], preferred_order.index(x[0]))\n",
        ")\n",
        "\n",
        "# ‚úÖ Print all models with F1 scores\n",
        "print(\"üìä Test F1 Scores:\")\n",
        "for name, _, score in all_models_sorted:\n",
        "    print(f\"{name:<16} F1: {score:.4f}\")\n",
        "\n",
        "# ‚úÖ Print the best model\n",
        "best_model = all_models_sorted[0]\n",
        "best_model_name, best_model_instance, best_f1_score = best_model\n",
        "print(f\"\\n‚úÖ Best Model Based on Test F1: {best_model_name}\")"
      ],
      "metadata": {
        "id": "3MhvaTvkakar"
      },
      "id": "3MhvaTvkakar",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Step 6 Wrap-Up: Final Model Selection Summary\n",
        "\n",
        "> *‚ÄúWhich model generalizes best across training, validation, and test data?‚Äù*\n",
        "\n",
        "After training and fine-tuning three convolutional neural network architectures ‚Äî **MobileNetV2**, **ResNet18**, and **EfficientNet-B0** ‚Äî we compared their performance across all stages using accuracy, F1 score, and confusion matrices. Below are the final F1 scores on the unseen test set:\n",
        "\n",
        "| Model           | Test F1 Score |\n",
        "|-----------------|----------------|\n",
        "| EfficientNet-B0 | **0.9983**     |\n",
        "| ResNet18        | 0.9950         |\n",
        "| MobileNetV2     | 0.9933         |\n",
        "\n",
        "### üß† Selected Model: `EfficientNet-B0`\n",
        "\n",
        "While all three models achieved strong results, **EfficientNet-B0** was ultimately selected for deployment based on the following strengths:\n",
        "\n",
        "- ‚úÖ **Highest test F1 score**: 0.9983 ‚Äî the best generalization to unseen data.\n",
        "- ‚úÖ **Balanced training curve**: Smooth improvement from low initial TL scores to strong FT and test performance.\n",
        "- ‚úÖ **Lowest total test errors**: Just **1 false negative**, with zero false positives ‚Äî outperforming all rivals in confusion matrix analysis.\n",
        "\n",
        "> üèÜ **Conclusion**: EfficientNet-B0 demonstrated the most stable and effective learning curve across all phases. Its superior generalization makes it the recommended model for deployment in this binary image classification task.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "J2u0IgVoa6ML"
      },
      "id": "J2u0IgVoa6ML"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîç 1.7: Model Explainability with Grad-CAM\n",
        "\n",
        "> *‚ÄúCan we trust what the model is looking at?‚Äù*\n",
        "\n",
        "To complement our performance-based evaluation, we now turn to **Grad-CAM (Gradient-weighted Class Activation Mapping)** to interpret how our CNN makes predictions. This helps us understand **which regions of the input image contributed most** to a given classification, offering both explainability and trust in model decisions.\n",
        "\n",
        "In this step, we:\n",
        "\n",
        "- Apply **Grad-CAM++** to the **best-performing model (EfficientNet-B0)** selected in Step 6  \n",
        "- Visualize activation heatmaps overlaid on real test samples\n",
        "- Assess whether the model is focusing on relevant page-flipping cues (e.g., hand movement, finger positions, or the page itself)\n",
        "- Use this interpretability to confirm robustness and uncover potential blind spots\n",
        "\n",
        "Grad-CAM++ allows us to probe the **attention regions** of the model. In several test cases, we observe that the model tends to activate most strongly around **hands and fingertips** ‚Äî which aligns with how a human might visually detect a page-flip event. However, heatmaps also show less emphasis on the **page area itself**, suggesting that the model is relying more on **gesture patterns** than explicit page content.\n",
        "\n",
        "> ‚úÖ These insights affirm the model‚Äôs utility while also signaling an opportunity for refinement ‚Äî especially if future versions are expected to distinguish more subtle types of flipping motion or work in varied lighting/background conditions.\n",
        "\n",
        "Visual interpretability is especially important in assistive applications like **MonReader**, where **human-in-the-loop trust** is essential.\n"
      ],
      "metadata": {
        "id": "47KbzJ0pcdqM"
      },
      "id": "47KbzJ0pcdqM"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- üß† Step 7: Grad-CAM Visualization for Model Explainability ---\n",
        "from torchcam.methods import GradCAM\n",
        "from torchvision.transforms import ToPILImage\n",
        "import torch.nn.functional as F_torch\n",
        "import torchvision.transforms.functional as F_vision\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# ‚úÖ Set model to evaluation mode\n",
        "efficientnet.eval()\n",
        "\n",
        "# ‚úÖ Automatically find the last Conv2d layer (without printing names)\n",
        "conv_layers = [(name, module) for name, module in efficientnet.named_modules() if isinstance(module, nn.Conv2d)]\n",
        "if not conv_layers:\n",
        "    raise ValueError(\"No Conv2d layer found in the model.\")\n",
        "_, target_layer = conv_layers[-1]  # last Conv2d layer\n",
        "\n",
        "# ‚úÖ Initialize Grad-CAM\n",
        "cam_extractor = GradCAM(model=efficientnet, target_layer=target_layer)\n",
        "\n",
        "# üñºÔ∏è Get a single image from test_loader\n",
        "test_img, _ = next(iter(test_loader))\n",
        "test_img = test_img[0].unsqueeze(0).to(device)\n",
        "\n",
        "# üîç Forward pass\n",
        "output = efficientnet(test_img)\n",
        "pred_class = output.argmax().item()\n",
        "\n",
        "# üî• Generate and normalize CAM\n",
        "activation_map = cam_extractor(pred_class, output)[0].squeeze().cpu()\n",
        "activation_map = (activation_map - activation_map.min()) / (activation_map.max() - activation_map.min() + 1e-8)\n",
        "\n",
        "# üåÄ Resize CAM to match image size\n",
        "activation_map_resized = F_torch.interpolate(\n",
        "    activation_map.unsqueeze(0).unsqueeze(0),\n",
        "    size=test_img.shape[-2:], mode='bilinear', align_corners=False\n",
        ").squeeze()\n",
        "\n",
        "# üé® De-normalize the image for display\n",
        "img_denorm = test_img.cpu().squeeze()\n",
        "img_denorm = F_vision.normalize(\n",
        "    img_denorm,\n",
        "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
        "    std=[1/0.229, 1/0.224, 1/0.225]\n",
        ")\n",
        "img_denorm = torch.clamp(img_denorm, 0, 1)\n",
        "\n",
        "# üìä Overlay CAM on image\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "ax.imshow(ToPILImage()(img_denorm))\n",
        "ax.imshow(activation_map_resized, cmap='jet', alpha=0.5)\n",
        "ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OMzK0jmKcacH"
      },
      "id": "OMzK0jmKcacH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† 1.7: Visualizing Attention with Grad-CAM  \n",
        "> *‚ÄúCan we see what the model is focusing on when predicting page flips?‚Äù*\n",
        "\n",
        "To interpret how **EfficientNet-B0** arrives at its predictions, we applied **SmoothGradCAM++** ‚Äî a class activation mapping technique that highlights regions of the input image that most influence the model‚Äôs decision.\n",
        "\n",
        "Using the final convolutional block (`features.7`) as our target layer, we extracted and overlaid **heatmaps** on representative test samples. The resulting visualizations reveal that the model consistently focuses on **hand regions and finger gestures**, which are often strong indicators of a page being turned. This confirms that the model has learned to prioritize spatial areas aligned with flipping motion rather than background or text.\n",
        "\n",
        "---\n",
        "\n",
        "### üîç Why This Matters:\n",
        "\n",
        "- üß© **Adds interpretability** to an otherwise black-box deep model  \n",
        "- üß™ **Complements accuracy/F1 metrics** with visual explanation  \n",
        "- ‚úÖ **Supports trust and transparency** in real-world deployments (e.g. assistive tech)\n",
        "\n",
        "---\n",
        "\n",
        "### üì∏ Grad-CAM Output on Test Sample  \n",
        "The heatmap below shows which image regions were most influential in EfficientNet-B0‚Äôs prediction.  \n",
        "The model attends strongly to the **page spread**, particularly the left-hand page region, suggesting it relies on **structural cues within the paper layout** rather than hand or finger motion alone:\n",
        "\n",
        "<img src=\"data:image/png;base64,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\" />\n"
      ],
      "metadata": {
        "id": "dxV97KRtprL4"
      },
      "id": "dxV97KRtprL4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "<a name=\"1.8\"></a>\n",
        "## üì¶ 1.8: Custom CNN ‚Äì Building AlvinNet from Scratch\n",
        "\n",
        "> *‚ÄúWhat if we could design our own neural network, tailored to this problem?‚Äù*\n",
        "\n",
        "In this section, we take full control of the architecture by building **AlvinNet**, a custom Convolutional Neural Network (CNN) designed from the ground up. Unlike prebuilt models like ResNet or MobileNet, this network is handcrafted to reflect a deeper understanding of CNN design principles, regularization strategies, and performance trade-offs.\n",
        "\n",
        "We also close this section with a **Grad-CAM visual explanation**, allowing us to inspect whether AlvinNet learns meaningful patterns (e.g., hand gestures or page motion) in the input images.\n",
        "\n",
        "\n",
        "\n",
        "### üîß Key Design Highlights:\n",
        "- üß± **Three convolutional blocks**, each with Conv ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool ‚Üí Dropout\n",
        "- üõ°Ô∏è **Built-in regularization** using `Dropout` to combat overfitting\n",
        "- üß† **Fully connected classifier** with additional dropout to stabilize training\n",
        "- ‚öñÔ∏è **Balanced architecture**, complex enough to learn robust patterns, yet lean enough to avoid overfitting on small datasets\n",
        "\n",
        "We define input shapes and model structure explicitly, instantiate AlvinNet, and run it through the enhanced training loop used in prior models. After training, we evaluate performance using:\n",
        "- Accuracy and F1 Score (train/val/test)\n",
        "- Confusion Matrix\n",
        "- Grad-CAM interpretation to inspect prediction logic\n",
        "\n",
        "Let‚Äôs see how well AlvinNet stacks up ‚Äî not just in performance metrics, but also in interpretability.\n"
      ],
      "metadata": {
        "id": "XtjK9Y15XfhC"
      },
      "id": "XtjK9Y15XfhC"
    },
    {
      "cell_type": "code",
      "source": [
        "# ---  Define Image Properties ---\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "IMG_CHANNELS = 3  # RGB input\n",
        "NUM_CLASSES = 2  # Binary classification (e.g., flip vs no-flip)\n",
        "\n",
        "# --- AlvinNet Definition ---\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AlvinNet(nn.Module):\n",
        "    def __init__(self, num_classes=NUM_CLASSES):\n",
        "        super(AlvinNet, self).__init__()\n",
        "\n",
        "        # Block 1\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(IMG_CHANNELS, 32, kernel_size=3, padding=1),  # 224x224 ‚Üí 224x224\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                                        # ‚Üí 112x112\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "\n",
        "        # Block 2\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),            # ‚Üí 112x112\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                                        # ‚Üí 56x56\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "        # Block 3\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),           # ‚Üí 56x56\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                                        # ‚Üí 28x28\n",
        "            nn.Dropout(0.4)\n",
        "        )\n",
        "\n",
        "        # Fully Connected\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Flatten(),                                           # ‚Üí 128*28*28\n",
        "            nn.Linear(128 * 28 * 28, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "E_24La25ccZo"
      },
      "id": "E_24La25ccZo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate and print model summary\n",
        "model = AlvinNet()\n",
        "\n",
        "# Move model to GPU before summary\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Summary with shape (requires torchsummary)\n",
        "from torchsummary import summary\n",
        "summary(model, input_size=(IMG_CHANNELS, IMG_HEIGHT, IMG_WIDTH))\n",
        "\n",
        "# Total parameter count\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\nTotal Parameters: {total_params:,}\")\n",
        "print(f\"Trainable Parameters: {trainable_params:,}\")"
      ],
      "metadata": {
        "id": "_zSRPw5sXQ8V"
      },
      "id": "_zSRPw5sXQ8V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üöÇ Enhanced training loop that tracks loss and accuracy per epoch\n",
        "# üìà Returns a history dict for plotting (train_loss, val_loss, train_acc, val_acc)\n",
        "def train_with_history(model, train_loader, val_loader, criterion, optimizer, epochs, device):\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'train_acc': [],\n",
        "        'val_acc': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            train_correct += (preds == labels).sum().item()\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc = train_correct / len(train_loader.dataset)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_correct += (preds == labels).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_acc = val_correct / len(val_loader.dataset)\n",
        "\n",
        "        # Save history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        print(f\"üìÜ Epoch {epoch+1}/{epochs} ‚Äî \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "fPqm-1Y18Vwm"
      },
      "id": "fPqm-1Y18Vwm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to device (already instantiated)\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train using enhanced training loop\n",
        "EPOCHS = 15\n",
        "history = train_with_history(model, train_loader, val_loader, criterion, optimizer, EPOCHS, device)\n",
        "\n",
        "# Evaluate on test set\n",
        "test_accuracy, test_f1, _ = evaluate_model(model, test_loader, device)\n",
        "print(f\"\\nüéØ Test Accuracy: {test_accuracy:.4f}, Test F1 Score: {test_f1:.4f}\")"
      ],
      "metadata": {
        "id": "LSxZZuj5aM1C"
      },
      "id": "LSxZZuj5aM1C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üì¶ Utility function to plot training & validation loss/accuracy curves per epoch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(history, model_name=\"Model\"):\n",
        "    epochs_range = range(len(history['train_loss']))\n",
        "\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, history['train_loss'], label='Train Loss')\n",
        "    plt.plot(epochs_range, history['val_loss'], label='Val Loss')\n",
        "    plt.title(f'{model_name} - Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, history['train_acc'], label='Train Acc')\n",
        "    plt.plot(epochs_range, history['val_acc'], label='Val Acc')\n",
        "    plt.title(f'{model_name} - Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bCeBf7AXam0h"
      },
      "id": "bCeBf7AXam0h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìä Plot training & validation loss/accuracy curves for AlvinNet\n",
        "plot_history(history, model_name=\"AlvinNet\")"
      ],
      "metadata": {
        "id": "oopEZRbPbGx5"
      },
      "id": "oopEZRbPbGx5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üöÇ Enhanced training loop that tracks loss and accuracy per epoch\n",
        "# üìà Returns a history dict for plotting (train_loss, val_loss, train_acc, val_acc)\n",
        "def train_with_history(model, train_loader, val_loader, criterion, optimizer, epochs, device):\n",
        "    ..."
      ],
      "metadata": {
        "id": "3U9wqgbGdgJN"
      },
      "id": "3U9wqgbGdgJN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üéØ Evaluate on test set\n",
        "test_accuracy, test_f1, _ = evaluate_model(model, test_loader, device)\n",
        "print(f\"\\nüéØ Test Accuracy: {test_accuracy:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
        "\n",
        "# üíæ Save the trained model\n",
        "torch.save(model.state_dict(), \"alvinnet_best.pth\")\n",
        "print(\"‚úÖ AlvinNet model saved as 'alvinnet_best.pth'\")"
      ],
      "metadata": {
        "id": "GQeYaG8ANOAO"
      },
      "id": "GQeYaG8ANOAO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîç Evaluate AlvinNet with confusion matrix and per-class metrics\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "# Predict on test set\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# Get class names from the dataset\n",
        "class_names = list(train_dataset.class_to_idx.keys())\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "disp.plot(cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix - AlvinNet\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Classification Report - AlvinNet\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))"
      ],
      "metadata": {
        "id": "PRQKllbufqws"
      },
      "id": "PRQKllbufqws",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- üß† Grad-CAM++ for AlvinNet ---\n",
        "\n",
        "from torchcam.methods import SmoothGradCAMpp\n",
        "from torchvision.transforms import ToPILImage\n",
        "import torch.nn.functional as F_torch\n",
        "import torchvision.transforms.functional as F_vision\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# ‚úÖ Ensure model is in eval mode\n",
        "model.eval()\n",
        "\n",
        "# ‚úÖ Safely find the last Conv2d layer\n",
        "conv_layers = [(name, module) for name, module in model.named_modules() if isinstance(module, nn.Conv2d)]\n",
        "if not conv_layers:\n",
        "    raise ValueError(\"No Conv2d layer found in the model.\")\n",
        "\n",
        "target_layer_name, target_layer = conv_layers[-1]\n",
        "print(f\"‚úÖ Using '{target_layer_name}' as target layer.\")\n",
        "\n",
        "# ‚úÖ Initialize Grad-CAM++\n",
        "cam_extractor = SmoothGradCAMpp(model=model, target_layer=target_layer)\n",
        "\n",
        "# üñºÔ∏è Grab one test image\n",
        "test_img, test_label = next(iter(test_loader))\n",
        "test_img = test_img[0].unsqueeze(0).to(device)\n",
        "\n",
        "# üöÄ Forward pass\n",
        "output = model(test_img)\n",
        "pred_class = output.argmax().item()\n",
        "\n",
        "# üî• Generate & normalize CAM\n",
        "activation_map = cam_extractor(pred_class, output)[0].squeeze().cpu()\n",
        "activation_map -= activation_map.min()\n",
        "activation_map /= activation_map.max()\n",
        "\n",
        "# üîÅ Resize CAM to match image\n",
        "activation_map_resized = F_torch.interpolate(\n",
        "    activation_map.unsqueeze(0).unsqueeze(0),\n",
        "    size=test_img.shape[-2:], mode='bilinear', align_corners=False\n",
        ").squeeze()\n",
        "\n",
        "# üé® De-normalize image\n",
        "img_denorm = test_img.cpu().squeeze()\n",
        "img_denorm = F_vision.normalize(\n",
        "    img_denorm,\n",
        "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
        "    std=[1/0.229, 1/0.224, 1/0.225]\n",
        ")\n",
        "img_denorm = torch.clamp(img_denorm, 0, 1)\n",
        "\n",
        "# üìä Plot\n",
        "plt.imshow(ToPILImage()(img_denorm))\n",
        "plt.imshow(activation_map_resized, cmap='jet', alpha=0.5)\n",
        "plt.title(f\"Grad-CAM - AlvinNet | Predicted: {pred_class}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q4PiBNENjG2C"
      },
      "id": "q4PiBNENjG2C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úÖ 1.8: Custom CNN Evaluation ‚Äì AlvinNetBinary <a name=\"step8\"></a>\n",
        "\n",
        "AlvinNetBinary is a lightweight custom convolutional neural network, designed from scratch for binary image classification. It was trained using `BCEWithLogitsLoss`, cosine annealing scheduler, early stopping, and dropout regularization.\n",
        "\n",
        "#### üéØ Test Results (Final Model)\n",
        "- **Test Accuracy:** 95.98%  \n",
        "- **Test F1 Score:** 95.98%\n",
        "\n",
        "#### üìÑ Classification Report\n",
        "| Class     | Precision | Recall | F1 Score | Support |\n",
        "|-----------|-----------|--------|----------|---------|\n",
        "| **flip**     | 0.94      | 0.98   | 0.96     | 290     |\n",
        "| **notflip**  | 0.98      | 0.94   | 0.96     | 307     |\n",
        "| **Overall**  |           |        | 0.96     | 597     |\n",
        "\n",
        "#### üìä Confusion Matrix\n",
        "- **True Positives (flip):** 284  \n",
        "- **True Negatives (notflip):** 289  \n",
        "- **False Positives:** 6  \n",
        "- **False Negatives:** 18\n",
        "\n",
        "> ‚úÖ Refer to the plotted confusion matrix for visual confirmation.\n",
        "\n",
        "#### üìâ Training Curves\n",
        "Both loss and accuracy trends confirm steady learning and generalization. No overfitting was observed, and validation performance remained strong throughout the 15 epochs.\n",
        "\n",
        "> ‚úÖ See the dual subplot for training vs validation accuracy and loss over epochs.\n",
        "\n",
        "#### üåà Grad-CAM Heatmap\n",
        "The Grad-CAM visualization shows that AlvinNet attends to the **correct regions** of interest: hands and page-turn motion zones ‚Äî validating that it has learned meaningful visual cues for classification.\n",
        "\n",
        "> ‚úÖ See the heatmap visualization confirming motion-sensitive activation.\n",
        "\n",
        "---\n",
        "\n",
        "> üß† **Takeaway**: AlvinNetBinary exceeded the performance of all pretrained models (MobileNetV2, ResNet18, EfficientNet-B0) and is now the top candidate for deployment.\n",
        "\n",
        "ü¶Å **Next Step**: We'll tune AlvinNet with **Lion optimizer** and explore additional Grad-CAM variants like **SmoothGradCAM++** to boost both performance and interpretability."
      ],
      "metadata": {
        "id": "0cg9V46VCmkB"
      },
      "id": "0cg9V46VCmkB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"1.9\"></a>\n",
        "## ü¶Å 1.9: AlvinNet + Lion Optimizer ‚Äî An Experimental Fine-Tune\n",
        "\n",
        "> *‚ÄúCan optimizer choice unlock new potential in a custom model?‚Äù*\n",
        "\n",
        "In this final modeling experiment, we explore the impact of optimizer selection by retraining our custom-built CNN (**AlvinNet**) using the **Lion optimizer** ‚Äî a recent innovation from Google designed for **faster convergence and better generalization**.\n",
        "\n",
        "To give the optimizer the best chance to shine, we also adjust AlvinNet for **explicit binary classification**, replacing the final layer with a single logit and training it with **`BCEWithLogitsLoss`**, which is better suited for binary outputs.\n",
        "\n",
        "**What we do:**\n",
        "- Reconfigure and reinitialize AlvinNet for binary output.\n",
        "- Train it from scratch using the Lion optimizer.\n",
        "- Compare performance against the original AlvinNet (Adam + multiclass).\n",
        "- Visualize predictions via **side-by-side confusion matrices** and a **Grad-CAM++ heatmap**.\n",
        "\n",
        "This concludes the modeling section ‚Äî showing how **even a custom CNN can benefit from innovations in both loss function design and optimizer architecture**."
      ],
      "metadata": {
        "id": "V_jKCd_vDM_-"
      },
      "id": "V_jKCd_vDM_-"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from lion_pytorch import Lion\n",
        "\n",
        "# ‚úÖ Define AlvinNet for Binary Classification\n",
        "class AlvinNetLion(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlvinNetLion, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.4)\n",
        "        )\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 28 * 28, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.fc2 = nn.Linear(256, 1)  # ‚úÖ 1 logit output\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.fc1(x)\n",
        "        return self.fc2(x)  # ‚úÖ Return logits\n",
        "\n",
        "# ‚úÖ Initialize\n",
        "alvin_net_lion = AlvinNetLion().to(device)\n",
        "\n",
        "# ‚úÖ Binary loss + Lion optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = Lion(alvin_net_lion.parameters(), lr=3e-4, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "eAV3N5TliLds"
      },
      "id": "eAV3N5TliLds",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from sklearn.metrics import f1_score\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ‚úÖ Cosine Annealing Scheduler\n",
        "num_epochs = 15\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "# ‚úÖ Tracking\n",
        "best_val_f1 = 0.0\n",
        "train_losses, val_losses = [], []\n",
        "train_f1s, val_f1s = [], []\n",
        "\n",
        "# ‚úÖ Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    alvin_net_lion.train()\n",
        "    train_loss, train_preds, train_labels = 0.0, [], []\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = alvin_net_lion(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        preds = torch.sigmoid(outputs) > 0.5\n",
        "        train_preds.extend(preds.cpu().numpy())\n",
        "        train_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    train_f1 = f1_score(train_labels, train_preds)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    train_f1s.append(train_f1)\n",
        "\n",
        "    # ‚úÖ Validation\n",
        "    alvin_net_lion.eval()\n",
        "    val_loss, val_preds, val_labels = 0.0, [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
        "\n",
        "            outputs = alvin_net_lion(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_f1 = f1_score(val_labels, val_preds)\n",
        "    val_losses.append(avg_val_loss)\n",
        "    val_f1s.append(val_f1)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"\\nüìä Epoch {epoch+1} Summary:\")\n",
        "    print(f\"Train Loss: {avg_train_loss:.4f}, Train F1: {train_f1:.4f}\")\n",
        "    print(f\"Val Loss:   {avg_val_loss:.4f}, Val F1:   {val_f1:.4f}\")\n",
        "\n",
        "    # ‚úÖ Save best model\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        torch.save(alvin_net_lion.state_dict(), \"alvinnet_lion_best.pth\")\n",
        "\n",
        "print(\"\\nüèÜ Best model saved as 'alvinnet_lion_best.pth' based on Val F1.\")"
      ],
      "metadata": {
        "id": "uFQdEYKaiR_b"
      },
      "id": "uFQdEYKaiR_b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Reload the best saved binary model\n",
        "alvin_net_lion_loaded = AlvinNetLion().to(device)\n",
        "alvin_net_lion_loaded.load_state_dict(torch.load(\"alvinnet_lion_best.pth\"))\n",
        "alvin_net_lion_loaded.eval()\n",
        "\n",
        "# ‚úÖ Make predictions on test set\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = alvin_net_lion_loaded(images)\n",
        "        preds = torch.round(torch.sigmoid(outputs)).squeeze().long()\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# ‚úÖ Compute test metrics\n",
        "lion_test_accuracy = accuracy_score(all_labels, all_preds)\n",
        "lion_test_f1 = f1_score(all_labels, all_preds)\n",
        "\n",
        "print(f\"üéØ AlvinNet Lion - Test Accuracy: {lion_test_accuracy:.4f}, F1 Score: {lion_test_f1:.4f}\")"
      ],
      "metadata": {
        "id": "bzdh-ZTYlrTJ"
      },
      "id": "bzdh-ZTYlrTJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def compare_models_side_by_side(models, model_names, model_types, test_loader):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))  # 2 columns for side-by-side plots\n",
        "\n",
        "    for idx, (model, name, mtype) in enumerate(zip(models, model_names, model_types)):\n",
        "        model.eval()\n",
        "        all_preds, all_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(images)\n",
        "\n",
        "                if mtype == 'multiclass':\n",
        "                    preds = torch.argmax(outputs, dim=1)\n",
        "                elif mtype == 'binary':\n",
        "                    preds = torch.round(torch.sigmoid(outputs)).squeeze().long()\n",
        "                else:\n",
        "                    raise ValueError(\"Invalid model_type\")\n",
        "\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        cm = confusion_matrix(all_labels, all_preds)\n",
        "        acc = accuracy_score(all_labels, all_preds)\n",
        "        f1 = f1_score(all_labels, all_preds, average='macro' if mtype == 'multiclass' else 'binary')\n",
        "\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axs[idx])\n",
        "        axs[idx].set_title(f\"{name}\\nAccuracy: {acc:.4f}, F1: {f1:.4f}\")\n",
        "        axs[idx].set_xlabel(\"Predicted\")\n",
        "        axs[idx].set_ylabel(\"Actual\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ‚úÖ Load both models if not already loaded\n",
        "base = AlvinNet().to(device)\n",
        "base.load_state_dict(torch.load(\"alvinnet_best.pth\"))\n",
        "tuned = AlvinNetLion().to(device)\n",
        "tuned.load_state_dict(torch.load(\"alvinnet_lion_best.pth\"))\n",
        "\n",
        "# ‚úÖ Run comparison\n",
        "compare_models_side_by_side(\n",
        "    models=[base, tuned],\n",
        "    model_names=[\"Base AlvinNet\", \"Tuned AlvinNet (Lion)\"],\n",
        "    model_types=[\"multiclass\", \"binary\"],\n",
        "    test_loader=test_loader\n",
        ")"
      ],
      "metadata": {
        "id": "BBPjek8Y8Q75"
      },
      "id": "BBPjek8Y8Q75",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úÖ 1.9 Summary: Optimizer-Driven Fine-Tuning (AlvinNet + Lion)\n",
        "\n",
        "AlvinNet was reconfigured as a binary classifier and retrained from scratch using the **Lion optimizer** with `BCEWithLogitsLoss`. This experiment tested whether optimizer choice ‚Äî without altering model architecture ‚Äî could boost performance beyond the already strong results from Step 8.\n",
        "\n",
        "#### üîç Final Metrics\n",
        "| Metric         | Value     |\n",
        "|----------------|-----------|\n",
        "| **Test Accuracy**   | **98.16%** |\n",
        "| **Test F1 Score**   | **98.22%** |\n",
        "\n",
        "#### üìÑ Classification Report\n",
        "- **Flip class:** Precision = 0.98, Recall = 0.97, F1 = 0.98  \n",
        "- **NotFlip class:** Precision = 0.97, Recall = 0.99, F1 = 0.98  \n",
        "\n",
        "#### üìä Confusion Matrix Highlights\n",
        "- ‚úÖ **True Positives (flip):** 282  \n",
        "- ‚úÖ **True Negatives (notflip):** 304  \n",
        "- ‚ùå **False Positives:** 8  \n",
        "- ‚ùå **False Negatives:** 3  \n",
        "> üîÅ Compared to the base AlvinNet (F1 = 0.9598), this reflects a **~50% drop in total misclassifications**.\n",
        "\n",
        "#### üß† Interpretation\n",
        "This confirms that:\n",
        "- **Optimizer choice is a powerful lever** for improving generalization and reducing noise.\n",
        "- Even with a lightweight custom CNN, **tuning the optimizer and loss function** unlocks top-tier performance.\n",
        "- **No architectural changes** were needed to achieve these gains ‚Äî just smarter training design.\n",
        "\n",
        "> ‚úÖ AlvinNet (Lion) now becomes the **default production model** for the MonReader Phase 1 pipeline. It sets the stage for reliable page flip detection, which will feed into text extraction and audio synthesis in upcoming phases.\n",
        "\n",
        "___"
      ],
      "metadata": {
        "id": "jDDNpJyCykUq"
      },
      "id": "jDDNpJyCykUq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìå Phase 1 Conclusion: Image Classification Pipeline\n",
        "\n",
        "### 1. Objective\n",
        "The primary goal of this phase was successfully met: to develop a high-performance image classifier to detect \"flip\" vs. \"notflip\" states, enabling the core function of the MonReader application.\n",
        "\n",
        "### 2. Methodology & Comparative Strategy\n",
        "We employed a rigorous modeling workflow using PyTorch and evaluated:\n",
        "\n",
        "- **Transfer Learning** with EfficientNet-B0, ResNet18, and MobileNetV2.\n",
        "- A **custom-designed CNN** (AlvinNet) trained from scratch.\n",
        "- Optimizer experiments, including **Adam** and the newer **Lion** optimizer.\n",
        "- **Grad-CAM** and **Grad-CAM++** visualizations for interpretability.\n",
        "\n",
        "### 3. Test Performance Summary\n",
        "\n",
        "| Model                  | Optimizer | Test F1 Score |\n",
        "|------------------------|-----------|---------------|\n",
        "| EfficientNet-B0 (FT)   | Adam      | **0.9983**     |\n",
        "| ResNet18 (FT)          | Adam      | 0.9950         |\n",
        "| MobileNetV2 (FT)       | Adam      | 0.9933         |\n",
        "| AlvinNet               | Adam      | 0.9598         |\n",
        "| AlvinNet (Lion)        | Lion      | 0.9822         |\n",
        "\n",
        "ü¶Å The Lion optimizer **significantly boosted AlvinNet‚Äôs performance**, narrowing the gap with transfer learning models. This underscores the value of **optimizer tuning even for small custom architectures**.\n",
        "\n",
        "### 4. Final Recommendations\n",
        "- The fine-tuned **EfficientNet-B0** model is the top performer, achieving a near-perfect test **F1-score of >99%**. It is the recommended model for production. Grad-CAM analysis confirmed all models learned to focus on relevant visual cues like hand motion and page blur..\n",
        "- **AlvinNet (Lion)** offers a lightweight and surprisingly strong alternative when compute resources are limited.\n",
        "- **Optimizer choice matters**: Lion proved superior to Adam for AlvinNet ‚Äî a valuable insight for future training strategies.\n",
        "\n",
        "### 5. Next Steps\n",
        "With Phase 1 complete, the pipeline is now ready for **Phase 2: Text Recognition**. This will involve:\n",
        "- Extracting frames classified as `\"notflip\"`\n",
        "- Applying **OCR engines** (e.g., EasyOCR, Tesseract)\n",
        "- Enabling end-to-end document digitization for visually impaired users.\n",
        "\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "xrE4I18a8vQG"
      },
      "id": "xrE4I18a8vQG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìñ Phase 2: From Image to Experience ‚Äì Breathing Life into Scanned Text\n",
        "\n",
        "### üåç A New Frontier\n",
        "\n",
        "In **Phase 1**, we successfully engineered a critical piece of the MonReader pipeline: a high-performance image classifier capable of discerning when a page is ready for capture with near-perfect accuracy. This model acts as the **gatekeeper**, ensuring that only high-quality data proceeds down the assembly line.\n",
        "\n",
        "Now, we move beyond the gate.\n",
        "\n",
        "This next phase shifts from a purely visual task to a rich, multi-sensory challenge. The focus is no longer on what the image *is*, but on what the image *says*, *means*, and ultimately, *sounds like*.\n",
        "\n",
        "Our objective here is not merely to build a model ‚Äî but to build an **experience**.\n",
        "\n",
        "Rooted in the MonReader mission to create a **mobile document digitization experience for the blind**, this phase begins the journey of transforming static, silent text into accessible, meaningful, and even artistic content.\n",
        "\n",
        "\n",
        "### üé∂ The Shona Hymnal Challenge: A Test Case\n",
        "\n",
        "To guide this phase, we introduce a unique and culturally rich test case: **scanned pages from a Shona hymn book** from the Evangelical Lutheran Church in Zimbabwe.\n",
        "\n",
        "This use case enables a sophisticated, multi-stage AI pipeline:\n",
        "\n",
        "1. **üßæ Optical Character Recognition (OCR)**  \n",
        "   Using OCR engines like **EasyOCR** and **Tesseract**, we will extract raw Shona text from scanned images.\n",
        "\n",
        "2. **üåê Interpretation & Translation Analysis**  \n",
        "   With the help of **LLMs**, we will interpret the hymns, trace them back to potential original **English versions**, and evaluate the **translation quality and nuance**.\n",
        "\n",
        "3. **üó£Ô∏è Text-to-Speech (TTS)**  \n",
        "   We will convert the extracted Shona text into clear, audible speech to serve the project's accessibility goals.\n",
        "\n",
        "4. **üé§ Generative Audio (Stretch Goal)**  \n",
        "   Finally, we will explore whether an LLM can be prompted not just to **speak**, but to **sing** ‚Äî bringing the hymns to life in a way that bridges **cultural and linguistic divides**.\n",
        "\n",
        "\n",
        "This phase will take us to the **cutting edge** of what's possible when **computer vision**, **natural language processing**, and **generative AI** converge.\n",
        "\n",
        "Let‚Äôs begin.\n",
        "\n",
        "---\n",
        "\n",
        "## üîß 2.1: Install OCR & Image Libraries\n",
        "\n",
        "Before we can read text from scanned hymn pages, we need to install several key tools:\n",
        "\n",
        "- **pyheif** and **Pillow** ‚Äì for converting `.HEIC` images from iPhones into `.PNG`\n",
        "- **easyocr** ‚Äì for lightweight, multilingual OCR with bounding box support\n",
        "- **pytesseract** ‚Äì Python wrapper for Google's Tesseract OCR engine\n",
        "- **python-Levenshtein** - for calculating Levenshtein distance (OCR comparison)\n",
        "- **tesseract-ocr** ‚Äì the actual OCR engine (system package)\n",
        "- **opencv-python-headless** and **matplotlib** ‚Äì for image processing and visualization\n",
        "\n",
        "> These libraries enable us to work with real-world document images and extract text for interpretation and accessibility."
      ],
      "metadata": {
        "id": "41N1t4FMHbQp"
      },
      "id": "41N1t4FMHbQp"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- üõ†Ô∏è Corrected Installation Cell ---\n",
        "# Run this block ONLY ONCE. Then, RESTART the runtime before running any other cell.\n",
        "\n",
        "print(\"üîß Installing primary dependencies (EasyOCR, PyTorch, etc.)...\")\n",
        "\n",
        "# Install PyTorch, EasyOCR, and other libraries first.\n",
        "# This might temporarily install an incorrect NumPy version, but we will fix it in the next step.\n",
        "!pip install torch==2.2.2+cu121 torchvision==0.17.2+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html --user\n",
        "!pip install easyocr==1.7.1 pytesseract opencv-python-headless matplotlib pyheif pillow python-Levenshtein deep_translator --user\n",
        "\n",
        "print(\"\\nüîß Downgrading NumPy to the correct compatible version...\")\n",
        "# This is the crucial step. We force-reinstall the required version of NumPy LAST.\n",
        "!pip install numpy==1.26.4 --force-reinstall --user\n",
        "\n",
        "print(\"\\n‚úÖ All dependencies should now be correctly installed.\")\n",
        "print(\"üîÅ VERY IMPORTANT: NOW RESTART THE RUNTIME. Go to 'Runtime' > 'Restart session', then run your OCR code cell.\")"
      ],
      "metadata": {
        "id": "meiiEjUJMv2l"
      },
      "id": "meiiEjUJMv2l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üñºÔ∏è 2.2: Convert HEIC Images to PNG\n",
        "\n",
        "Since many users capture document photos on iPhones, `.HEIC` is a common format.  \n",
        "However, most OCR tools (including EasyOCR and Tesseract) don't support `.HEIC` directly.\n",
        "\n",
        "In this step, we:\n",
        "- Read all `.HEIC` files from your current Colab session\n",
        "- Convert them to `.PNG` using `pyheif` and `Pillow`\n",
        "- Save them under the same name with `.png` extension\n",
        "\n",
        "> This ensures the images are OCR-ready for the next phase."
      ],
      "metadata": {
        "id": "AaW230ofQVhc"
      },
      "id": "AaW230ofQVhc"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- üìÇ Setup: Mount Google Drive and Access Hymn Images ---\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "print(\"üîó Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"üìÇ Changing directory to HymnImages...\")\n",
        "image_folder_path = '/content/drive/MyDrive/Colab_Notebooks/HymnImages'\n",
        "os.chdir(image_folder_path)\n",
        "\n",
        "print(\"‚úÖ Current working directory set to:\", os.getcwd())\n",
        "print(\"üì∏ Files available:\", os.listdir())\n"
      ],
      "metadata": {
        "id": "oUVM6Whtbxh4"
      },
      "id": "oUVM6Whtbxh4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîÑ Convert all HEIC files found in the current directory to PNG\n",
        "import os\n",
        "import pyheif\n",
        "from PIL import Image\n",
        "\n",
        "image_directory = '.'  # This is where your files are already located\n",
        "\n",
        "print(\"\\nüìÇ Starting HEIC to PNG Conversion...\\n\")\n",
        "\n",
        "# Loop through all files in /content/\n",
        "for filename in os.listdir(image_directory):\n",
        "    if filename.lower().endswith(\".heic\"):\n",
        "        heic_path = os.path.join(image_directory, filename)\n",
        "        print(f\"üîç Found HEIC file: {filename}\")\n",
        "\n",
        "        try:\n",
        "            # Read HEIC file\n",
        "            heif_file = pyheif.read(heic_path)\n",
        "\n",
        "            # Convert to PNG using Pillow\n",
        "            image = Image.frombytes(\n",
        "                heif_file.mode,\n",
        "                heif_file.size,\n",
        "                heif_file.data,\n",
        "                \"raw\",\n",
        "                heif_file.mode,\n",
        "                heif_file.stride,\n",
        "            )\n",
        "\n",
        "            # Save as PNG with the same base name\n",
        "            png_filename = os.path.splitext(filename)[0] + \".png\"\n",
        "            png_path = os.path.join(image_directory, png_filename)\n",
        "            image.save(png_path, \"PNG\")\n",
        "\n",
        "            print(f\"‚úÖ Converted and saved: {png_filename}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Could not convert {filename}. Error: {e}\")\n",
        "\n",
        "print(\"\\nüéâ Conversion complete! PNGs are ready for OCR.\")"
      ],
      "metadata": {
        "id": "I3t0AtmOQyNM"
      },
      "id": "I3t0AtmOQyNM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üëÅÔ∏è 2.3: OCR with EasyOCR\n",
        "\n",
        "Now that our `.HEIC` images have been converted to `.PNG`, we use **EasyOCR** to:\n",
        "\n",
        "- üß† Detect and extract text **line-by-line**  \n",
        "- üìè Print each detected line with **confidence scores**  \n",
        "- üñºÔ∏è Visualize bounding boxes using **OpenCV + Matplotlib**\n",
        "\n",
        "This gives us a **fast, multilingual preview** of what EasyOCR can \"see\" in our hymn scans.  \n",
        "We configure it with `['en', 'af']` to improve recognition of Shona-style Latin text, leveraging phonetic overlap with Afrikaans.\n",
        "\n",
        "---\n",
        "\n",
        "### üßπ OCR Output Handling\n",
        "\n",
        "Raw OCR output often includes:\n",
        "\n",
        "- ‚úÇÔ∏è Line fragments, overlapping regions, or repeated symbols  \n",
        "- ‚ùå Low-confidence words (e.g. garbled characters, misread glyphs)  \n",
        "- ‚¨ú Irregular spacing and punctuation\n",
        "\n",
        "To prepare this for downstream tasks like hymn recognition or audio synthesis, we apply a structured **post-processing routine**:\n",
        "\n",
        "- ‚úÖ Filter lines by **confidence threshold** (e.g. ‚â• 0.5)  \n",
        "- üîß Normalize **spacing, punctuation, and casing**  \n",
        "- üß© Reconstruct **stanzas** where possible using line grouping logic\n",
        "\n",
        "This cleaning phase bridges the gap between **raw OCR output** and **usable structured text**, and sets the stage for hymn segmentation, hymn number detection, and later TTS (text-to-singing) synthesis.\n",
        "\n",
        "> üîÑ Once the OCR pipeline is stable, we‚Äôll layer in hymn indexing, segment recognition, and voice synthesis ‚Äî turning scanned pages into structured, searchable audio-ready hymns."
      ],
      "metadata": {
        "id": "gGKpy2jEMw1A"
      },
      "id": "gGKpy2jEMw1A"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Optimized EasyOCR with Enhanced Parameters and Structured Output ---\n",
        "import easyocr\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os # Import os to list files\n",
        "\n",
        "# ‚úÖ Initialize EasyOCR reader with ['en', 'af'] for better support of Shona-style hymn text\n",
        "reader = easyocr.Reader(['en', 'af'])   # Afrikaans improves recognition of historical Shona spellings,\n",
        "                                        # Optionally try ['en', 'sw'] sw is Swahili\n",
        "\n",
        "# Get all PNG files in the current directory\n",
        "image_files = sorted([f for f in os.listdir('.') if f.lower().endswith('.png')])\n",
        "ocr_results = {}  # To store results per image\n",
        "\n",
        "if not image_files:\n",
        "    print(\"‚ùå No PNG images found in the current directory.\")\n",
        "else:\n",
        "    for img in image_files:\n",
        "        print(f\"\\nüîç OCR on: {img}\")\n",
        "\n",
        "        # Use the image path relative to the current directory\n",
        "        results = reader.readtext(\n",
        "            img,\n",
        "            detail=1,\n",
        "            paragraph=False,\n",
        "            text_threshold=0.7,\n",
        "            low_text=0.4,\n",
        "            link_threshold=0.4\n",
        "        )\n",
        "\n",
        "        # üß™ Retain only high-confidence text\n",
        "        results = [(bbox, text, prob) for (bbox, text, prob) in results if prob >= 0.5 and text.strip()]\n",
        "\n",
        "        # üìù Print retained lines with confidence\n",
        "        for (bbox, text, prob) in results:\n",
        "            print(f'üìù \"{text}\" (Confidence: {prob:.2f})')\n",
        "\n",
        "        # üíæ Save to dictionary using the same filtered results\n",
        "        ocr_results[img] = [text.strip() for (_, text, _) in results]\n",
        "\n",
        "        # üì¶ Draw bounding boxes\n",
        "        # Read the image using the image path relative to the current directory\n",
        "        image = cv2.imread(img)\n",
        "        if image is None:\n",
        "            print(f\"‚ùå Could not load image {img} with OpenCV. Skipping visualization.\")\n",
        "            continue # Skip visualization if image loading failed\n",
        "\n",
        "        for (bbox, text, prob) in results:\n",
        "            top_left = tuple(map(int, bbox[0]))\n",
        "            bottom_right = tuple(map(int, bbox[2]))\n",
        "            image = cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)\n",
        "\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        # Convert BGR to RGB for matplotlib display\n",
        "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"üß† EasyOCR Detection ‚Äì {img}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "Fbnls8MpYi-G"
      },
      "id": "Fbnls8MpYi-G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Visual Overlay OCR Preview with EasyOCR ---\n",
        "import os\n",
        "from PIL import Image\n",
        "import easyocr\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ‚úÖ Initialize EasyOCR Reader with ['en', 'af'] for better handling of historical Shona text\n",
        "reader = easyocr.Reader(['en', 'af'])\n",
        "\n",
        "# üîç Collect all PNGs in the current directory\n",
        "png_files = sorted([f for f in os.listdir('.') if f.lower().endswith('.png')])\n",
        "\n",
        "ocr_results = {}  # To store filtered text per image\n",
        "\n",
        "for img_file in png_files:\n",
        "    print(f\"\\nüîç Reading text from {img_file}...\")\n",
        "\n",
        "    # ‚úÖ Use enhanced OCR parameters for better stanza handling\n",
        "    result = reader.readtext(\n",
        "        img_file,\n",
        "        detail=1,\n",
        "        paragraph=False,\n",
        "        text_threshold=0.7,\n",
        "        low_text=0.4,\n",
        "        link_threshold=0.4\n",
        "    )\n",
        "\n",
        "    # üß™ Filter: retain only high-confidence results\n",
        "    result = [(bbox, text, conf) for (bbox, text, conf) in result if conf >= 0.5 and text.strip()]\n",
        "\n",
        "    # üñºÔ∏è Plot image with bounding boxes\n",
        "    image = Image.open(img_file)\n",
        "    fig, ax = plt.subplots(figsize=(10, 12))\n",
        "    ax.imshow(image)\n",
        "\n",
        "    for (bbox, text, confidence) in result:\n",
        "        (top_left, top_right, bottom_right, bottom_left) = bbox\n",
        "        ax.plot(\n",
        "            [top_left[0], top_right[0], bottom_right[0], bottom_left[0], top_left[0]],\n",
        "            [top_left[1], top_right[1], bottom_right[1], bottom_left[1], top_left[1]],\n",
        "            color='lime'\n",
        "        )\n",
        "        ax.text(top_left[0], top_left[1] - 10, text, color='green', fontsize=10)\n",
        "\n",
        "    ax.set_title(f\"üß† EasyOCR Detection ‚Äì {img_file}\")\n",
        "    ax.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # üíæ Store clean text only (for downstream tasks)\n",
        "    ocr_results[img_file] = [text.strip() for (_, text, _) in result]"
      ],
      "metadata": {
        "id": "WZAXNCzoZfIO"
      },
      "id": "WZAXNCzoZfIO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cleaned & Structured OCR Extraction with EasyOCR ---\n",
        "import easyocr\n",
        "import os\n",
        "import re\n",
        "\n",
        "reader = easyocr.Reader(['en', 'af'])  # multilingual for better Shona coverage\n",
        "ocr_results = {}\n",
        "\n",
        "# üßº Basic cleaning before merging\n",
        "def basic_clean(line):\n",
        "    line = line.strip()\n",
        "    line = re.sub(r'[^\\w\\s.,!?\\'\\\"-]', '', line)  # Remove stray symbols, keep basic punctuation\n",
        "    line = re.sub(r'\\s+', ' ', line)  # Normalize spaces\n",
        "    return line\n",
        "\n",
        "# üß© Merge fragmented sentence lines (heuristic)\n",
        "def merge_lines(logical_lines):\n",
        "    merged = []\n",
        "    buffer = \"\"\n",
        "\n",
        "    for line in logical_lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        if buffer:\n",
        "            if line[0].islower() and not buffer.endswith(('.', '!', '?', ':', ';')):\n",
        "                buffer += ' ' + line\n",
        "            else:\n",
        "                merged.append(buffer)\n",
        "                buffer = line\n",
        "        else:\n",
        "            buffer = line\n",
        "\n",
        "    if buffer:\n",
        "        merged.append(buffer)\n",
        "\n",
        "    return merged\n",
        "\n",
        "# üìÇ Process all image files\n",
        "for filename in sorted(os.listdir()):\n",
        "    if filename.endswith('.png'):\n",
        "        result = reader.readtext(\n",
        "            filename,\n",
        "            detail=1,\n",
        "            paragraph=False,\n",
        "            text_threshold=0.7,\n",
        "            low_text=0.4,\n",
        "            link_threshold=0.4\n",
        "        )\n",
        "\n",
        "        # Step 1: Filter by confidence\n",
        "        filtered = [text for (_, text, prob) in result if prob >= 0.5 and text.strip()]\n",
        "\n",
        "        # Step 2: Clean each line\n",
        "        cleaned = [basic_clean(text) for text in filtered if len(text) >= 2]\n",
        "\n",
        "        # Step 3: Merge into logical stanzas\n",
        "        merged_lines = merge_lines(cleaned)\n",
        "\n",
        "        ocr_results[filename] = merged_lines"
      ],
      "metadata": {
        "id": "un0oMlBFaen-"
      },
      "id": "un0oMlBFaen-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üíæ Save final EasyOCR output to .txt files\n",
        "for filename, lines in ocr_results.items():\n",
        "    base_name = filename.replace('.png', '')\n",
        "    with open(f\"{base_name}.txt\", \"w\", encoding='utf-8') as f:\n",
        "        f.write(\"\\n\".join(lines))\n",
        "    print(f\"üíæ Saved {len(lines)} lines to {base_name}.txt\")"
      ],
      "metadata": {
        "id": "P6tsRONpbHTL"
      },
      "id": "P6tsRONpbHTL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìÑ Display cleaned EasyOCR output\n",
        "for filename in sorted(ocr_results.keys()):\n",
        "    print(f\"\\nüñºÔ∏è Cleaned OCR Output for {filename}:\\n\" + \"-\" * 50)\n",
        "    lines = ocr_results[filename]\n",
        "    for line in lines:\n",
        "        print(line)"
      ],
      "metadata": {
        "id": "gk3LfsVX_GtT"
      },
      "id": "gk3LfsVX_GtT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úÖ 2.3 Summary: üëÅÔ∏è EasyOCR\n",
        "\n",
        "EasyOCR was tested as the first OCR engine. While it demonstrated fast and user-friendly line-level extraction, it **exhibited critical structural failures**. Specifically, it processed each scanned image as a single continuous block ‚Äî failing to recognize the two-column layout and stanza breaks common in hymnbook formatting. As a result, the output was **visually coherent but structurally jumbled**, limiting its usability for downstream analysis or translation.\n",
        "\n",
        "Initially, EasyOCR was tested using English-only recognition (`['en']`). This baseline setup struggled with several Shona-specific phonetic patterns, leading to garbled words and frequent misreads. A second pass using a multilingual configuration (`['en', 'af']`) led to **noticeable improvements in character recognition and phonetic clarity**. Afrikaans ‚Äî with its orthographic overlap with Shona ‚Äî helped resolve ambiguous consonant-vowel sequences and reduced hallucinated substitutions.\n",
        "\n",
        "> üß† This experiment confirmed that **adding Afrikaans to the language model significantly improves EasyOCR‚Äôs accuracy for Shona-style hymn text**, even without native Shona language support. The enhanced model produced fewer character-level errors and better preserved word shapes.\n",
        "\n",
        "Despite these gains, EasyOCR still hallucinated several non-existent words, skipped valid lines, and failed to preserve stanza boundaries ‚Äî making it **unsuitable as a stand-alone solution for hymn digitization**. Nonetheless, it provides a useful **character-level benchmark** and reinforces the importance of multilingual model configurations.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "4wDJsISEpmYK"
      },
      "id": "4wDJsISEpmYK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üßä 2.4: Full-Page OCR with Tesseract\n",
        "\n",
        "While EasyOCR gave us structured, line-by-line outputs, we now use **Tesseract** to extract **full-page raw text**. This serves as a complementary OCR strategy that better captures verse-style hymn layouts and fills in gaps missed by line-based models.\n",
        "\n",
        "### üîÑ Why Use Tesseract?\n",
        "\n",
        "- üß± Handles full-page blocks with minimal layout assumptions  \n",
        "- üîç Recovers **stanza-like verse structures** and long lines that may get split or dropped by line-level OCR  \n",
        "- üß¨ Enables hybrid OCR strategies by **combining** Tesseract‚Äôs broad coverage with EasyOCR‚Äôs precision  \n",
        "- üì¶ Outputs are saved as `*_tesseract_raw.txt` for every scanned `.png`\n",
        "\n",
        "### üßπ Structuring & Cleaning\n",
        "\n",
        "Tesseract outputs are **noisy and unstructured**, so we introduce a cleaning pipeline that:\n",
        "- ‚úÇÔ∏è Strips random symbols and broken line fragments  \n",
        "- ‚¨ú Normalizes line breaks and spacing  \n",
        "- üß© Segments blocks into **semantic chunks** (verses, stanzas)\n",
        "\n",
        "Each raw `.txt` file is transformed into a cleaner format:\n",
        "- `IMG_8589_tesseract_raw.txt`  \n",
        "- `IMG_8589_tesseract_cleaned.txt`\n",
        "\n",
        "This setup ensures easier comparison with EasyOCR and sets the stage for **hymn parsing, structure recovery**, and downstream tasks like **text-to-speech (TTS)** or **segment tagging**."
      ],
      "metadata": {
        "id": "JFKZuHhWM2CY"
      },
      "id": "JFKZuHhWM2CY"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- üßä Step 4: Full-Page OCR with Tesseract ---\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Path to Tesseract binary (already installed in Colab)\n",
        "pytesseract.tesseract_cmd = r'/usr/bin/tesseract'\n",
        "\n",
        "# Find all PNGs\n",
        "png_files = sorted([f for f in os.listdir('.') if f.lower().endswith('.png')])\n",
        "\n",
        "tesseract_results = {}  # Store output\n",
        "\n",
        "for img_file in png_files:\n",
        "    print(f\"\\nüîç Extracting full text from {img_file} using Tesseract...\")\n",
        "    try:\n",
        "        img = Image.open(img_file)\n",
        "        text = pytesseract.image_to_string(img)\n",
        "        tesseract_results[img_file] = text.strip()\n",
        "\n",
        "        # Save to text file\n",
        "        out_path = img_file.replace('.png', '_tesseract_raw.txt')\n",
        "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(text.strip())\n",
        "        print(f\"‚úÖ Saved Tesseract output: {out_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error processing {img_file}: {e}\")"
      ],
      "metadata": {
        "id": "RZ5Bvd08M4FM"
      },
      "id": "RZ5Bvd08M4FM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- üßπ Cleaning for Tesseract Raw Output Files (Hymn-Sensitive) ---\n",
        "import re\n",
        "\n",
        "def is_valid_line(line):\n",
        "    line = line.strip()\n",
        "    if not line or len(line) < 2:\n",
        "        return False\n",
        "\n",
        "    # Remove clearly broken characters but preserve key hymn symbols\n",
        "    line = re.sub(r\"[^\\w\\s.,!?':;|/-]\", '', line)\n",
        "\n",
        "    # Preserve line if it matches common hymn patterns\n",
        "    hymn_keywords = r\"(Jesu|KRISTU|SHE|KORO|KUMURUMBIDZA|Bambo|Izita|Muponesi|Hareruya|Nd[a-z]+|Rwiyo|Pakudenga|Mufaro)\"\n",
        "\n",
        "    if re.search(hymn_keywords, line, re.IGNORECASE):\n",
        "        return True\n",
        "\n",
        "    words = line.split()\n",
        "    alpha_ratio = sum(c.isalpha() for c in line) / max(len(line), 1)\n",
        "\n",
        "    # Retain short but likely valid lines\n",
        "    return (\n",
        "        len(words) >= 2\n",
        "        or (line[0].isupper() and len(line) > 5)\n",
        "        or (alpha_ratio > 0.6 and len(line) >= 6)\n",
        "    )\n",
        "\n",
        "for base in [\"IMG_8587\", \"IMG_8588\", \"IMG_8589\"]:\n",
        "    with open(f\"{base}_tesseract_raw.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "        raw_lines = f.readlines()\n",
        "\n",
        "    cleaned_lines = []\n",
        "    for line in raw_lines:\n",
        "        if is_valid_line(line):\n",
        "            cleaned_lines.append(line.strip())\n",
        "\n",
        "    with open(f\"{base}_tesseract_cleaned.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\\n\".join(cleaned_lines))\n",
        "\n",
        "    print(f\"‚úÖ Cleaned {base}_tesseract_raw.txt ‚Üí {base}_tesseract_cleaned.txt ({len(cleaned_lines)} lines saved)\")"
      ],
      "metadata": {
        "id": "bjUJgcndLp-S"
      },
      "id": "bjUJgcndLp-S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- üìñ Final Cleaned OCR Output from Tesseract ---\n",
        "for base in [\"IMG_8587\", \"IMG_8588\", \"IMG_8589\"]:\n",
        "    cleaned_path = f\"{base}_tesseract_cleaned.txt\"\n",
        "    print(f\"\\nüìñ Final Tesseract OCR Output ‚Äì {base}\\n{'-'*60}\")\n",
        "    with open(cleaned_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        print(f.read())"
      ],
      "metadata": {
        "id": "lHfuB6xwoPBy"
      },
      "id": "lHfuB6xwoPBy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üßä 2.4 Summary: Tesseract OCR Performance\n",
        "\n",
        "Tesseract offered a contrasting experience to EasyOCR. It demonstrated a stronger **understanding of layout**, particularly in preserving stanza breaks, detecting two-column flows (in many instances), and maintaining consistent line breaks. This made it significantly better at capturing hymn structure and flow.\n",
        "\n",
        "However, its **character-level fidelity was mixed**. Some sections ‚Äî like Hymn 66 ‚Äî were captured almost verbatim, while others showed spacing errors, character noise, or jumbled segments (e.g., ‚ÄúRwa'civinga oo -ss0ee rwo, aeietae Jesu‚Äù). These issues were most common in regions with decorative fonts, shadows, or poor contrast.\n",
        "\n",
        "Still, Tesseract **rarely hallucinated entire words** ‚Äî and when it did err, the errors were localized and the overall stanza structure remained intact. This made its output easier to clean and more predictable for downstream processing.\n",
        "\n",
        "> ‚úÖ Despite occasional garbling, Tesseract proved more faithful to the original hymnbook layout and more consistent in preserving complete line structures than EasyOCR.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "jY9QS2m-vvf2"
      },
      "id": "jY9QS2m-vvf2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß™ 2.5: Compare OCR Outputs\n",
        "\n",
        "In this step, we compare the **raw text extracted by EasyOCR and Tesseract** to evaluate how effectively each engine digitizes content from the Shona hymnbook scans.\n",
        "\n",
        "We assess both OCRs based on:\n",
        "\n",
        "- üìÑ **Text Quality**  \n",
        "  Are the extracted words accurate, complete, and faithful to the original?\n",
        "\n",
        "- üß± **Structural Preservation**  \n",
        "  Does the OCR maintain layout features like stanza numbers, line breaks, and column flow?\n",
        "\n",
        "- ‚ùå **Common Errors**  \n",
        "  Includes hallucinated words, dropped lines, misread characters, or broken syntax.\n",
        "\n",
        "> This analysis helps us decide which engine is better suited for future pipeline phases like **hymn identification**, **translation**, and **text-to-speech synthesis**."
      ],
      "metadata": {
        "id": "aByvtmnaM5Ih"
      },
      "id": "aByvtmnaM5Ih"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import Levenshtein\n",
        "import Levenshtein\n",
        "\n",
        "# Step 2: Define your Ground Truth text.\n",
        "# This is the \"perfect\" text typed out by hand for one of the hymns.\n",
        "# We use Hymn 66 as an example.\n",
        "ground_truth_hymn66 = \"\"\"\n",
        "1 Ndichamugamuchira\n",
        "Nokuchingura nei?\n",
        "Ndichamunamati-ra\n",
        "Nokubatira sei?\n",
        "SHE, mundiudze kwazvo,\n",
        "Muchanakirwa nei?\n",
        "Zvomunotenda nazvo,\n",
        "Ndingamufadza sei?\n",
        "\n",
        "2 VeZion vakawadza\n",
        "Mashizha kareko;\n",
        "Neni handingaregi\n",
        "Kumuchingurawo;\n",
        "Nomwoyo wangu wose\n",
        "Ndichamuimbirai,\n",
        "Ndinoda kumukudza,\n",
        "Nokumurumbidzai!\n",
        "\n",
        "3 Ndakanga ndakasungwa,\n",
        "Madzikunure‚Äôni:\n",
        "Ndakanga ndakanyadzwa,\n",
        "Ndamutswa, SHE, nemi;\n",
        "Mandivigire fuma\n",
        "Yabva kudenga‚Äôko;\n",
        "Ndiyo yokusaora,\n",
        "Nokusaperawo.\n",
        "\n",
        "4 SHE JESU uchauya\n",
        "Kuzotongesazve;\n",
        "Bva avo vakatenda\n",
        "Havangazomutyi;\n",
        "Uya-i Tenzi Jesu!\n",
        "Kudenga tiisei,\n",
        "Kwatichafara isu,\n",
        "Tichinakirwa sei!\n",
        "\"\"\"\n",
        "\n",
        "# Step 3: Get the OCR outputs.\n",
        "# --- Get EasyOCR Output ---\n",
        "# (Text extracted from easyocr_results variable)\n",
        "easyocr_output_hymn66 = \"\"\"\n",
        "Ndichamugamuchira\n",
        "Nokuchingura nei?\n",
        "Ndichamunamati-ra\n",
        "Nokubatira sei?\n",
        "SHE mundiudze kwazvo,\n",
        "Muchanakirwa nei?\n",
        "Zvomunotenda nazvo,\n",
        "Ndingamufadza sei?\n",
        "\n",
        "VeZion vakawadza\n",
        "Mashizha kareko;\n",
        "Neni handingaregi\n",
        "Kumuchingurawo;\n",
        "Nomwoyo wangu wose\n",
        "Ndichamuimbirai,\n",
        "Ndinoda kumukudza,\n",
        "Nokumurumbidzai!\n",
        "\n",
        "ndakasungwa;\n",
        "Madzikunure ni:\n",
        "ndakanyadzwa,\n",
        "Ndamutswa,\n",
        "Mandivigire\n",
        "SHE, nemi;\n",
        "Yabva fuma\n",
        "Ndiyo yokusaora,\n",
        "\n",
        "SHE JESU\n",
        "Kuzotongesazve;\n",
        "avo vakatenda\n",
        "Jesu!\n",
        "tiisei,\n",
        "Kwatichafara\n",
        "Tichinakirwa\n",
        "sei!\n",
        "Nokusaperawo.\n",
        "Bva\n",
        "Kudenga\n",
        "isu,\n",
        "\"\"\"\n",
        "\n",
        "# --- Get Tesseract Output ---\n",
        "# (Text from your tesseract_text variable)\n",
        "tesseract_output_hymn66 = \"\"\"\n",
        "| Ndichamugamuchira\n",
        "Nokuchingura nei?\n",
        "Ndichamunamati-ra\n",
        "Nokubatira sei?\n",
        "SHE, mundiudze kwazvo,\n",
        "Muchanakirwa nei?\n",
        "Zvomunotenda nazvo,\n",
        "Ndingamufadza sei?\n",
        "\n",
        "2 VeZion vakawadza\n",
        "Mashizha kareko;\n",
        "Kumuchingurawo:\n",
        "Nomwoyo wangu wose\n",
        "Ndichamuimbirai,\n",
        "Ndinoda kumukudza,\n",
        "Nokumurumbidzai!\n",
        "\n",
        "3 Ndakanga ndakasungwa,\n",
        "Madzikunure‚Äô ni:\n",
        "Ndakanga ndakanyadzwa,\n",
        "Ndamutswa, SHE, nemi:;\n",
        "Mandivigire fuma\n",
        "Yabva kudenga‚Äôko:\n",
        "Ndiyo yokusaora,\n",
        "okusaperawo.\n",
        "\n",
        "4 SHE JESU uchauya\n",
        "Kuzotongesazve:\n",
        "Bvya avo vakatenda\n",
        "‚Äòvangazomutyi;\n",
        "Uya-i Tenzi Jesu!\n",
        "Kudenga tiisei,\n",
        "Kwatichafara isu,\n",
        "Tichinakirwa sei!\n",
        "\"\"\"\n",
        "\n",
        "# Step 4: Clean up the text for a fair comparison\n",
        "# (Remove newlines, extra spaces, and convert to lowercase)\n",
        "def clean_text(text):\n",
        "    return \" \".join(text.strip().lower().split())\n",
        "\n",
        "cleaned_ground_truth = clean_text(ground_truth_hymn66)\n",
        "cleaned_easyocr = clean_text(easyocr_output_hymn66)\n",
        "cleaned_tesseract = clean_text(tesseract_output_hymn66)\n",
        "\n",
        "\n",
        "# Step 5: Calculate and Compare Levenshtein Distances\n",
        "distance_easyocr = Levenshtein.distance(cleaned_ground_truth, cleaned_easyocr)\n",
        "distance_tesseract = Levenshtein.distance(cleaned_ground_truth, cleaned_tesseract)\n",
        "\n",
        "# Step 6: Compute error rates\n",
        "error_rate_easy = round(100 * distance_easyocr / len(cleaned_ground_truth), 2)\n",
        "error_rate_tess = round(100 * distance_tesseract / len(cleaned_ground_truth), 2)\n",
        "\n",
        "# Step 7: Compute word-level similarity\n",
        "gt_words = set(cleaned_ground_truth.split())\n",
        "easy_words = set(cleaned_easyocr.split())\n",
        "tess_words = set(cleaned_tesseract.split())\n",
        "\n",
        "word_sim_easy = round(100 * len(gt_words & easy_words) / len(gt_words), 2)\n",
        "word_sim_tess = round(100 * len(gt_words & tess_words) / len(gt_words), 2)\n",
        "\n",
        "# Step 8: Display results\n",
        "print('--- üß™ OCR Performance Comparison (Levenshtein Distance) ---')\n",
        "print('üí° Lower score is better (fewer errors).\\n')\n",
        "print(f'‚úÖ EasyOCR Distance: {distance_easyocr} | Error Rate: {error_rate_easy}%')\n",
        "print(f'‚úÖ Tesseract Distance: {distance_tesseract} | Error Rate: {error_rate_tess}%\\n')\n",
        "print(f'üëÅÔ∏è EasyOCR Word-Level Similarity: {word_sim_easy}%')\n",
        "print(f'üßä Tesseract Word-Level Similarity: {word_sim_tess}%')\n",
        "\n",
        "if distance_easyocr < distance_tesseract:\n",
        "    print('\\nüéØ Conclusion: EasyOCR produced a more accurate transcription.')\n",
        "else:\n",
        "    print('\\nüéØ Conclusion: Tesseract produced a more accurate transcription.')"
      ],
      "metadata": {
        "id": "-0cvOY_kk3QU"
      },
      "id": "-0cvOY_kk3QU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß™ 2.5 Summary: OCR Performance Comparison\n",
        "\n",
        "We evaluated EasyOCR and Tesseract against manually typed ground truth using two metrics: **Levenshtein distance** (edit distance) and **word-level similarity**.\n",
        "\n",
        "| Metric                        | üëÅÔ∏è EasyOCR         | üßä Tesseract       |\n",
        "|------------------------------|--------------------|--------------------|\n",
        "| Levenshtein Distance         | 153                | **28**             |\n",
        "| Character-Level Error Rate   | 26.24%             | **4.8%**           |\n",
        "| Word-Level Similarity        | 80.33%             | **81.97%**         |\n",
        "\n",
        "\n",
        "\n",
        "### üéØ Interpretation\n",
        "\n",
        "Tesseract significantly outperformed EasyOCR on this hymn sample, with **lower error rates and higher word-level accuracy**. It was especially strong in recovering **short function words** and correctly handling **punctuation** ‚Äî areas where EasyOCR often struggled.\n",
        "\n",
        "While EasyOCR did a better job at **preserving stanza formatting and visual spacing**, its recognition accuracy was lower, particularly on faint or overlapping text.\n",
        "\n",
        "> ‚úÖ **Conclusion:** Tesseract is better suited for tasks requiring high transcription accuracy, such as downstream NLP or translation. EasyOCR remains valuable where **layout fidelity** or **line-by-line overlays** are needed.\n",
        "\n",
        "\n",
        "### üî≠ Next Steps\n",
        "\n",
        "Neither engine, in its default configuration, fully meets the **MonReader project's** standards for structured hymn digitization. This benchmark confirms the need for a more advanced solution:\n",
        "\n",
        "- **Adopt a layout-aware OCR API** such as **Google Vision AI**, **Amazon Textract**, or **TrOCR**, which are better equipped to preserve both **content fidelity** and **document structure**.\n",
        "\n",
        "This lays the groundwork for our upcoming work in **hymn segmentation, tagging**, and **text-to-speech synthesis**.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "OH86e5th7hi5"
      },
      "id": "OH86e5th7hi5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìï Phase 3: Hybrid AI Pipeline for Hymn Transcription and Analysis\n",
        "\n",
        "### üìñ Objective:\n",
        "Having established the limitations of baseline open-source OCR engines in Phase 2, this phase evaluates if modern AI models can solve the complex \"translation traceback\" challenge.\n",
        "\n",
        "### üë®üèæ‚Äçüç≥ Methodology:\n",
        "A systematic, multi-phase process was designed to test competing AI pipelines and produce a final, structured data asset. The workflow is executed in the following order:\n",
        "\n",
        "**1. Setup and Ground Truth Generation (`Sub-phase 3.1`):** The environment is prepared by installing all necessary libraries and configuring all API keys. The source images are converted, and a high-fidelity, \"ground-truth\" transcription of Hymn 66 is generated using the **Google Cloud Vision API** and saved for later use.\n",
        "\n",
        "**2. Pipeline A - VLM Bake-Off (`Sub-phase 3.2`):** Advanced Vision-Language Models (VLMs) like **IDEFICS**, **LLaVA**, and **BakLlava** are tested to see if they can reliably perform both OCR and reasoning directly from the hymnbook image.\n",
        "\n",
        "**3. Pipeline B - PLM Bake-Off (`Sub-phase 3.3`):** Powerful Pure Language Models (PLMs) like **Gemma**, **Mistral**, and **Gemini** are tested to see if they can take the perfect ground-truth transcription (generated in Step 1) and correctly identify the original hymn.\n",
        "\n",
        "**4. Adjudication (`Sub-phase 3.4`):** The outputs from all models in both pipelines are formally evaluated. The analysis includes a **quantitative** review using **BLEU** and **Levenshtein** scores, and a **qualitative** ranking performed by a frontier model (GPT-4o or Gemini 1.5 Pro) to provide a final verdict.\n",
        "\n",
        "**5. Post-Adjudication Structuring (`Sub-phase 3.5`):** The final, \"winning\" data (the ground-truth transcription) is processed into a structured JSON format, with stanzas segmented and enriched with AI-generated thematic tags, making it ready for downstream applications.\n",
        "\n",
        "> *To ensure a fair comparison, a standardized, advanced prompt is used for all models within the same category.*"
      ],
      "metadata": {
        "id": "_-4fdYpM9Q6h"
      },
      "id": "_-4fdYpM9Q6h"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üåç 3.1:  Environment Setup & Ground Truth Establishment\n",
        "**Objective:** To prepare the full environment and generate a single, high-fidelity \"ground-truth\" transcription of Hymn 66. Each cell below handles one distinct task: installation, data preparation, and the one-time API call."
      ],
      "metadata": {
        "id": "PKbeso5t9i_p"
      },
      "id": "PKbeso5t9i_p"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3.1.1: Install All Libraries, Logins & API Keys ---\n",
        "\n",
        "print(\"Installing all necessary libraries for the project...\")\n",
        "# Consolidated all pip installs into one block for efficiency\n",
        "!pip install -q transformers accelerate bitsandbytes sacrebleu pyheif pillow google-cloud-vision openai\n",
        "\n",
        "# --- Imports for Authentication ---\n",
        "from huggingface_hub import login\n",
        "import openai\n",
        "from google.colab import userdata, auth\n",
        "import os\n",
        "\n",
        "# --- Hugging Face Login (Using Secret Key) ---\n",
        "print(\"\\nüîë Authenticating with Hugging Face using secret token...\")\n",
        "try:\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\"‚úÖ Hugging Face authentication successful.\")\n",
        "except Exception as e:\n",
        "    print(f\"üö® Hugging Face authentication failed. Please ensure 'HF_TOKEN' is set correctly. Error: {e}\")\n",
        "\n",
        "# --- OpenAI API Key Configuration ---\n",
        "# NOTE for OpenAI API users:\n",
        "print(\"\\nüîê Reminder: Set up your OpenAI API key securely.\")\n",
        "print(\"üëâ Go to the left sidebar ‚Üí üîë Secrets tab ‚Üí Add a secret named 'OPENAI_API_KEY'\")\n",
        "try:\n",
        "    openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "    print(\"‚úÖ OpenAI API key configured.\")\n",
        "except Exception as e:\n",
        "    print(\"üö® OpenAI API key not found or invalid.\")\n",
        "\n",
        "\n",
        "# --- Google Cloud Authentication (for Vision API) ---\n",
        "print(\"\\n‚òÅÔ∏è Authenticating for Google Cloud...\")\n",
        "# This will prompt you to log in to your Google account for this session.\n",
        "auth.authenticate_user()\n",
        "print(\"‚úÖ Google Cloud authentication complete.\")\n",
        "print(\"\\n--- Environment Setup is Finished ---\")"
      ],
      "metadata": {
        "id": "hcUmi4To7z-b"
      },
      "id": "hcUmi4To7z-b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üõ†Ô∏è 3.2: Data Preparation\n",
        "After restarting runtime, we mount the Google Drive and convert .HEIC hymn images into the .png format that the models can use."
      ],
      "metadata": {
        "id": "HTIqXAryHgoq"
      },
      "id": "HTIqXAryHgoq"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3.1.2: Mount Drive & Prepare Image Data ---\n",
        "import os\n",
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "import pyheif\n",
        "\n",
        "# Mount your Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define file paths\n",
        "gdrive_image_folder = '/content/drive/MyDrive/Colab_Notebooks/HymnImages/'\n",
        "output_folder = '/content/converted_images/'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "print(f\"Converted images will be saved to: {output_folder}\")\n",
        "\n",
        "# Find all .HEIC files and convert them to .png\n",
        "print(\"\\nStarting image conversion...\")\n",
        "try:\n",
        "    files_in_directory = os.listdir(gdrive_image_folder)\n",
        "    for filename in files_in_directory:\n",
        "        if filename.lower().endswith(\".heic\"):\n",
        "            heic_file_path = os.path.join(gdrive_image_folder, filename)\n",
        "            png_filename = os.path.splitext(filename)[0] + \".png\"\n",
        "            png_file_path = os.path.join(output_folder, png_filename)\n",
        "\n",
        "            # Read and convert the image\n",
        "            heif_file = pyheif.read(heic_file_path)\n",
        "            image = Image.frombytes(\n",
        "                heif_file.mode, heif_file.size, heif_file.data, \"raw\",\n",
        "                heif_file.mode, heif_file.stride,\n",
        "            )\n",
        "            image.save(png_file_path, \"PNG\")\n",
        "            print(f\"  -> Converted {filename} to {png_filename}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: The folder was not found. Please check the path: {gdrive_image_folder}\")\n",
        "\n",
        "print(\"\\nSetup and conversion process complete.\")"
      ],
      "metadata": {
        "id": "MdPk-ED6b4fy"
      },
      "id": "MdPk-ED6b4fy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìú 3.1.3: High-Fidelity OCR: The Cloud Vision API Solution\n",
        "**Establishing a Ground Truth:** A production-grade tool was used to establish a high-quality baseline for later stages."
      ],
      "metadata": {
        "id": "Vx5Rk6fLznS1"
      },
      "id": "Vx5Rk6fLznS1"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3.1.3: Generate Ground-Truth Transcription for Hymn 66 (with Cost-Saving) ---\n",
        "\n",
        "from google.colab import auth\n",
        "from google.cloud import vision\n",
        "import io\n",
        "\n",
        "# --- Define the specific target image and output file ---\n",
        "image_to_process = '/content/converted_images/IMG_8588.png' # Image with Hymn 66\n",
        "transcription_output_path = \"google_vision_hymn66.txt\"\n",
        "ground_truth_text = \"\"\n",
        "\n",
        "# --- COST-SAVING CHECK ---\n",
        "if os.path.exists(transcription_output_path):\n",
        "    # If the file exists, load it directly for FREE\n",
        "    print(f\"‚úÖ Transcription file '{transcription_output_path}' found. Loading from local disk.\")\n",
        "    with open(transcription_output_path, 'r', encoding='utf-8') as f:\n",
        "        ground_truth_text = f.read()\n",
        "else:\n",
        "    # If the file does NOT exist, run the authentication and ONE-TIME API call\n",
        "    print(f\"‚ö†Ô∏è Transcription file not found. Authenticating and calling Google Vision API for {image_to_process}...\")\n",
        "    try:\n",
        "        # Authenticate and set the project\n",
        "        project_id = \"monreader-project-465414\"\n",
        "        !gcloud config set project {project_id}\n",
        "        auth.authenticate_user(project_id=project_id)\n",
        "        print(f\"\\n‚úÖ Successfully authenticated for project: {project_id}\")\n",
        "\n",
        "        # Define the function to call the API\n",
        "        def get_text_from_google_vision(path):\n",
        "            client = vision.ImageAnnotatorClient()\n",
        "            with io.open(path, 'rb') as image_file:\n",
        "                content = image_file.read()\n",
        "            image = vision.Image(content=content)\n",
        "            response = client.document_text_detection(image=image)\n",
        "            if response.error.message:\n",
        "                raise Exception(response.error.message)\n",
        "            return response.full_text_annotation.text\n",
        "\n",
        "        # --- Run the OCR on image ---\n",
        "        print(\"\\n--- Calling Google Vision AI (One-Time Cost) ---\")\n",
        "        ground_truth_text = get_text_from_google_vision(image_to_process)\n",
        "\n",
        "         # Save the high-quality text to a file\n",
        "        with open(transcription_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(ground_truth_text)\n",
        "        print(f\"\\n‚úÖ Successfully saved transcription to {transcription_output_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå An error occurred: {e}\")\n",
        "\n",
        "# Display a snippet of the final text to confirm it's loaded\n",
        "print(\"\\n--- Ground-Truth Transcription Loaded ---\")\n",
        "print(ground_truth_text)"
      ],
      "metadata": {
        "id": "FoYjMoQQjOWn"
      },
      "id": "FoYjMoQQjOWn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2: üëÅÔ∏è Pipeline A - The End-to-End Visual Reasoning Bake-Off\n",
        "Objective: To evaluate the ability of modern Vision-Language Models (VLMs) like LLaVA, IDEFICS, and BakLlava to perform the full \"translation traceback\" task directly from an image.\n",
        "\n",
        "---\n",
        "### 3.2.1: Testing LLaVA (VLM)"
      ],
      "metadata": {
        "id": "R47LNFn8quWM"
      },
      "id": "R47LNFn8quWM"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3.2.1: VLM Execution - LLaVA ---\n",
        "import torch\n",
        "from transformers import BitsAndBytesConfig, LlavaForConditionalGeneration, AutoProcessor\n",
        "from PIL import Image\n",
        "\n",
        "# --- Step 1: Configure the Model ---\n",
        "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
        "print(f\"Loading model: {model_id}\")\n",
        "\n",
        "# a. Define the quantization configuration object\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "# b. Pass this config object to the 'quantization_config' argument\n",
        "model = LlavaForConditionalGeneration.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=quantization_config,\n",
        "    low_cpu_mem_usage=True,\n",
        ")\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "print(\"‚úÖ Model and processor loaded.\")\n",
        "\n",
        "\n",
        "# --- Step 2: Prepare Inputs ---\n",
        "\n",
        "# --- This is the NEW, revised prompt for the VLM bake-off ---\n",
        "prompt = \"USER: <image>\\nTranscribe Hymn 66, which begins 'Ndichamugamuchira', from this image and then identify its original title and author. ASSISTANT:\"\n",
        "\n",
        "# Load the target image from the previous step\n",
        "image_path = '/content/converted_images/IMG_8588.png'\n",
        "try:\n",
        "    image = Image.open(image_path)\n",
        "    print(f\"‚úÖ Image '{image_path}' loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå ERROR: Image not found at {image_path}. Please check the path.\")\n",
        "    # Stop execution if the image isn't found\n",
        "    image = None\n",
        "\n",
        "# Process the prompt and image\n",
        "if image:\n",
        "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(\"cuda:0\", torch.float16)\n",
        "\n",
        "\n",
        "    # --- Step 3: Generate and Decode the Output ---\n",
        "    print(\"\\nGenerating response from VLM...\")\n",
        "    output = model.generate(**inputs, max_new_tokens=512)\n",
        "    decoded_output = processor.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "    # --- Step 4: Display the Result ---\n",
        "    print(\"\\n--- VLM Model Output ---\")\n",
        "    # We slice the output to remove the original prompt text for clarity\n",
        "    assistant_response = decoded_output.split(\"ASSISTANT:\")[-1].strip()\n",
        "    print(assistant_response)\n",
        "\n",
        "    # --- Step 5: Save the Result ---\n",
        "    # It's crucial to save each model's output for the final comparison in Sub-phase 3.4\n",
        "    vlm_output_filename = f\"output_{model_id.split('/')[-1]}.txt\"\n",
        "    with open(vlm_output_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(assistant_response)\n",
        "    print(f\"\\n‚úÖ Saved VLM output to {vlm_output_filename}\")"
      ],
      "metadata": {
        "id": "D8ugIqXF0nZ9"
      },
      "id": "D8ugIqXF0nZ9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summary of LLaVA Performance\n",
        "**Result: Failure.** The model's performance has improved since earlier tests. It no longer simply repeats the prompt's clue. It now correctly identifies the hymn title (\"Ndichamugamuchira\") from the image. However, it still fails the primary task of transcribing the full hymn. Instead of performing the reasoning task, it gives a \"meta-response,\" explaining *how* one would find the author rather than attempting to do so itself.\n",
        "\n",
        "**Conclusion:** LLaVA still fails the core multi-step task. While it has overcome the simple \"prompt over-fitting\" issue, it now exhibits a form of \"task avoidance\" or \"soft refusal.\" It understands the request but is unable or unwilling to execute it fully, making it unreliable for this project.\n",
        "\n",
        "---\n",
        "### 3.2.2: Testing IDEFICS (VLM)"
      ],
      "metadata": {
        "id": "Fn5eHeqikKkQ"
      },
      "id": "Fn5eHeqikKkQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3.2.2: VLM Execution - IDEFICS ---\n",
        "import torch\n",
        "from transformers import BitsAndBytesConfig, IdeficsForVisionText2Text, AutoProcessor\n",
        "from PIL import Image\n",
        "\n",
        "# --- Step 1: Configure the Model ---\n",
        "model_id = \"HuggingFaceM4/idefics-9b-instruct\"\n",
        "print(f\"Loading model: {model_id}\")\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "model = IdeficsForVisionText2Text.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=quantization_config,\n",
        "    low_cpu_mem_usage=True,\n",
        ")\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "print(\"‚úÖ Model and processor loaded.\")\n",
        "\n",
        "\n",
        "# --- Step 2: Prepare Inputs (with Advanced CoT Prompt for IDEFICS) ---\n",
        "image_path = '/content/converted_images/IMG_8588.png'\n",
        "try:\n",
        "    image = Image.open(image_path)\n",
        "    print(f\"‚úÖ Image '{image_path}' loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå ERROR: Image not found at {image_path}. Please check the path.\")\n",
        "    image = None\n",
        "\n",
        "if image:\n",
        "    # First, define new, more advanced prompt text\n",
        "    idefics_cot_prompt = \"USER: <image>\\nTranscribe Hymn 66, which begins 'Ndichamugamuchira', from this image and then identify its original title and author. ASSISTANT:\"\n",
        "\n",
        "    # Place advanced prompt into the special list format that IDEFICS requires.\n",
        "    prompts = [\n",
        "        \"User:\",\n",
        "        image,\n",
        "        idefics_cot_prompt,\n",
        "        \"<end_of_utterance>\\n\",\n",
        "        \"Assistant:\"\n",
        "    ]\n",
        "\n",
        "    # Process the prompt and image\n",
        "    inputs = processor(prompts, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "\n",
        "    # --- Step 3: Generate and Decode the Output ---\n",
        "    print(\"\\nGenerating response from VLM...\")\n",
        "\n",
        "    # Wrap the function call in square brackets [...]\n",
        "    bad_words_ids = [processor.tokenizer.convert_tokens_to_ids([\"<end_of_utterance>\"])]\n",
        "\n",
        "    output = model.generate(**inputs, max_new_tokens=512, bad_words_ids=bad_words_ids)\n",
        "    decoded_output = processor.batch_decode(output, skip_special_tokens=True)[0]\n",
        "\n",
        "\n",
        "    # --- Step 4: Display the Result ---\n",
        "    print(\"\\n--- VLM Model Output ---\")\n",
        "    assistant_response = decoded_output.split(\"Assistant:\")[-1].strip()\n",
        "    print(assistant_response)\n",
        "\n",
        "    # --- Step 5: Save the Result ---\n",
        "    vlm_output_filename = f\"output_{model_id.split('/')[-1]}.txt\"\n",
        "    with open(vlm_output_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(assistant_response)\n",
        "    print(f\"\\n‚úÖ Saved VLM output to {vlm_output_filename}\")"
      ],
      "metadata": {
        "id": "6bXoYl43q-9z"
      },
      "id": "6bXoYl43q-9z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summary of IDEFICS Performance\n",
        "**Result: Failure.** The model exhibited a \"soft refusal,\" correctly stating that it cannot perform visual tasks. However, it then proceeded to hallucinate a conversation where it prompted the user for the text and then \"transcribed\" it by repeating the first word of the hymn title over and over.\n",
        "\n",
        "**Conclusion:** IDEFICS is not a viable tool for this project. It fails the primary OCR task and then enters a hallucinatory state, making its output completely unreliable.\n",
        "\n",
        "---\n",
        "### 3.2.3: Testing BakLlava (VLM)"
      ],
      "metadata": {
        "id": "_FZtKiatkYi1"
      },
      "id": "_FZtKiatkYi1"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3.2.3: VLM Execution - Alternative: BakLlava (with a simpler prompt) ---\n",
        "import torch\n",
        "from transformers import AutoProcessor, LlavaForConditionalGeneration, BitsAndBytesConfig\n",
        "from PIL import Image\n",
        "\n",
        "# --- Step 1: Configure the Model ---\n",
        "model_id = \"llava-hf/bakLlava-v1-hf\"\n",
        "print(f\"Loading model: {model_id}\")\n",
        "\n",
        "# Quantization config and model loading.\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "model = LlavaForConditionalGeneration.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=quantization_config,\n",
        "    low_cpu_mem_usage=True,\n",
        ")\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "print(\"‚úÖ Model and processor loaded.\")\n",
        "\n",
        "\n",
        "# --- Step 2: Prepare Inputs with a Simpler Prompt ---\n",
        "prompt = \"USER: <image>\\nTranscribe Hymn 66, which begins 'Ndichamugamuchira', from this image and then identify its original title and author. ASSISTANT:\"\n",
        "# Load the target image\n",
        "image_path = '/content/converted_images/IMG_8588.png'\n",
        "try:\n",
        "    image = Image.open(image_path)\n",
        "    print(f\"‚úÖ Image '{image_path}' loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå ERROR: Image not found at {image_path}. Please check the path.\")\n",
        "    image = None\n",
        "\n",
        "# Process the prompt and image\n",
        "if image:\n",
        "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(\"cuda:0\", torch.float16)\n",
        "\n",
        "    # --- Step 3: Generate and Decode the Output ---\n",
        "    print(\"\\nGenerating response from VLM...\")\n",
        "    output = model.generate(**inputs, max_new_tokens=512)\n",
        "    decoded_output = processor.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    # --- Step 4: Display the Result ---\n",
        "    print(\"\\n--- VLM Model Output ---\")\n",
        "    assistant_response = decoded_output.split(\"ASSISTANT:\")[-1].strip()\n",
        "    print(assistant_response)\n",
        "\n",
        "    # --- Step 5: Save the Result ---\n",
        "    vlm_output_filename = f\"output_{model_id.split('/')[-1]}.txt\"\n",
        "    with open(vlm_output_filename, \"w\", encoding=\"utf-8\") as f: f.write(assistant_response)\n",
        "    print(f\"\\n‚úÖ Saved VLM output to {vlm_output_filename}\")"
      ],
      "metadata": {
        "id": "aN8WRB37rF93"
      },
      "id": "aN8WRB37rF93",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summary of BakLlava Performance\n",
        "**Result: Failure.** The model's performance was similar to that of LLaVA. It demonstrated a partial ability to read from the image by correctly identifying the hymn's title, \"Ndichamugamuchira.\" However, it failed both the primary transcription and reasoning tasks. Instead of executing the request, it gave a \"meta-response,\" describing the value of finding the original author without actually attempting to do so.\n",
        "\n",
        "**Conclusion:** BakLlava also exhibits a form of \"task avoidance.\" It understands the request but is unable to execute it fully, making it an unreliable tool for this multi-step project.\n",
        "\n",
        "---\n",
        "## 3.3: Pipeline B - The Modular Specialist Bake-Off\n",
        "\n",
        "#### PLM Prompt:"
      ],
      "metadata": {
        "id": "yQkzN4QMki-Y"
      },
      "id": "yQkzN4QMki-Y"
    },
    {
      "cell_type": "code",
      "source": [
        " # The \"Ultimate\" Hybrid Prompt Template for all PLMs\n",
        "\n",
        "advanced_prompt = f\"\"\"You are an AI expert in Christian hymnology, specializing in analyzing translations in the ELCZ Shona hymnbook, which often have German Lutheran hymn origins.\n",
        "I will provide text from the Shona hymnbook and you must identify the original, or equivalent English hymn.\n",
        "First, here is an example of a correct identification to show you the expected output format:\n",
        "- Shona Hymn Text Snippet: 'Hymn 69. 1. Toonga Ba......mbo Nemwoyo yedu yose;'\n",
        "- Correct Original English Title: 'Now Thank We All Our God' (German: 'Nun danket alle Gott')\n",
        "- Author: 'Martin Rinckart'\n",
        "Now, apply a similar deep analysis to the text below.\n",
        "\n",
        "---\n",
        "\n",
        "FULL SHONA TEXT:\n",
        "{ground_truth_text}\n",
        "\n",
        "---\n",
        "\n",
        "Based on the ground truth text for Hymn 66 which begins 'Ndichamugamuchira Nokuchingura nei?', Please perform the following steps to identify the Hymn:\n",
        "1. ¬†**Thematic Analysis:** First, what are the most significant themes and unique images in the text of Hymn 66?\n",
        "2. ¬†**Liturgical Context:** Based on the imagery in the first part of the second stanza of Hymn 66, what specific event in the Gospels does this stanza most likely refer to?\n",
        "3. ¬†**English Translation:** Generate the complete first stanza of that original English hymn.\n",
        "4. ¬†**Conclusion:** Based your translation, and all the stanzas of Hymn 66, what is the most likely English (or German) title for this hymn, and it's author?\n",
        "Provide a final, and confident answer with the Title, and Author clearly labeled.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vuhXSwFZW4eg"
      },
      "id": "vuhXSwFZW4eg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.1: Testing Mistral-7B-Instruct (PLM)"
      ],
      "metadata": {
        "id": "CK9lbvQzWUhu"
      },
      "id": "CK9lbvQzWUhu"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3.3.1a: PLM Setup (Mistral-7B-Instruct) ---\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "# --- Step 1: Configure the Model ---\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        " # a. Define the modern quantization configuration\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "mistral_model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=quantization_config, low_cpu_mem_usage=True)\n",
        "mistral_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "print(\"‚úÖ Mistral model and tokenizer loaded.\")\n",
        "\n",
        "\n",
        "# b. Load the base model (CausalLM) with the new config\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=quantization_config,\n",
        "    low_cpu_mem_usage=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "print(\"‚úÖ PLM Model and tokenizer loaded.\")\n",
        "\n",
        "# --- Step 2: Load the Ground-Truth Text ---\n",
        "# We load the perfect transcription that we created back in Sub-phase 3.1\n",
        "transcription_path = \"google_vision_hymn66.txt\"\n",
        "try:\n",
        "    with open(transcription_path, 'r', encoding='utf-8') as f:\n",
        "        ground_truth_text = f.read()\n",
        "    print(f\"‚úÖ Successfully loaded ground-truth text from '{transcription_path}'\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå ERROR: Ground-truth text file not found at '{transcription_path}'.\")\n",
        "    ground_truth_text = None\n",
        "\n",
        "# Display a snippet to confirm\n",
        "if ground_truth_text:\n",
        "    print(\"\\n--- Snippet of Ground-Truth Text ---\")\n",
        "    print(ground_truth_text[:500] + \"...\")"
      ],
      "metadata": {
        "id": "KiV4W8Va_UNv"
      },
      "id": "KiV4W8Va_UNv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3.3.1b: PLM Prompting and Generation (Mistral - Advanced Prompt) ---\n",
        "\n",
        "if ground_truth_text:\n",
        "    # Use the advanced prompt inside Mistral's instruction format\n",
        "    prompt = f\"<s>[INST] {advanced_prompt} [/INST]\"\n",
        "    inputs = mistral_tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    print(\"Generating response from PLM (Mistral)...\")\n",
        "    output = mistral_model.generate(**inputs, max_new_tokens=512, pad_token_id=mistral_tokenizer.eos_token_id)\n",
        "    decoded_output = mistral_tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    assistant_response = decoded_output.split(\"[/INST]\")[-1].strip()\n",
        "    print(\"\\n--- PLM Model Output ---\")\n",
        "    print(assistant_response)\n",
        "\n",
        "    # Save the output\n",
        "    plm_output_filename = f\"output_advanced_{model_id.split('/')[-1]}.txt\"\n",
        "    with open(plm_output_filename, \"w\", encoding=\"utf-8\") as f: f.write(assistant_response)\n",
        "    print(f\"\\n‚úÖ Saved PLM output to {plm_output_filename}\")"
      ],
      "metadata": {
        "id": "LfC-L34j_0z0"
      },
      "id": "LfC-L34j_0z0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summary of Mistral Performance\n",
        "**Result: Failure.** Despite being provided with a perfect transcription from the Google Vision API, the Mistral model failed the reasoning task. It produced a plausible-sounding but entirely incorrect answer, hallucinating a connection to the hymn \"At the Cross.\"\n",
        "\n",
        "**Conclusion:** Mistral demonstrates the \"knowledge gap\" perfectly. While it can process the text, it lacks the specific, niche hymnological knowledge required to make the correct cross-lingual connection.\n",
        "\n",
        "---\n",
        "### 3.3.2: Testing Gemma (PLM)"
      ],
      "metadata": {
        "id": "O3xgT0dyaHeY"
      },
      "id": "O3xgT0dyaHeY"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3.3.2a: PLM Setup (Gemma-7b-it)\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "# --- Step 1: Configure the Model ---\n",
        "model_id = \"google/gemma-7b-it\"\n",
        "# a. Define the modern quantization configuration\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "gemma_model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=quantization_config, low_cpu_mem_usage=True)\n",
        "gemma_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "print(\"‚úÖ Gemma model and tokenizer loaded.\")\n",
        "\n",
        "\n",
        "\n",
        "# b. Load the base model (CausalLM) with the new config\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=quantization_config,\n",
        "    low_cpu_mem_usage=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "print(\"‚úÖ PLM Model and tokenizer loaded.\")\n",
        "\n",
        "# --- Step 2: Load the Ground-Truth Text ---\n",
        "# We load the perfect transcription that we created back in Sub-phase 3.1\n",
        "transcription_path = \"google_vision_hymn66.txt\"\n",
        "try:\n",
        "    with open(transcription_path, 'r', encoding='utf-8') as f:\n",
        "        ground_truth_text = f.read()\n",
        "    print(f\"‚úÖ Successfully loaded ground-truth text from '{transcription_path}'\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå ERROR: Ground-truth text file not found at '{transcription_path}'.\")\n",
        "    ground_truth_text = None\n",
        "\n",
        "# Display a snippet to confirm\n",
        "if ground_truth_text:\n",
        "    print(\"\\n--- Snippet of Ground-Truth Text ---\")\n",
        "    print(ground_truth_text[:500] + \"...\")"
      ],
      "metadata": {
        "id": "JFt0sQblARH5"
      },
      "id": "JFt0sQblARH5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3.3.2b: PLM Prompting and Generation (Gemma - Advanced Prompt) ---\n",
        "if ground_truth_text:\n",
        "    # Use the advanced prompt inside Gemma's chat template\n",
        "    chat = [{\"role\": \"user\", \"content\": advanced_prompt}]\n",
        "    prompt = gemma_tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = gemma_tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    print(\"Generating response from PLM (Gemma)...\")\n",
        "    output = gemma_model.generate(input_ids=inputs, max_new_tokens=512)\n",
        "    decoded_output = gemma_tokenizer.decode(output[0])\n",
        "\n",
        "    assistant_response = decoded_output.split(\"<start_of_turn>model\\n\")[-1].strip()\n",
        "    print(\"\\n--- PLM Model Output ---\")\n",
        "    print(assistant_response)\n",
        "\n",
        "    # Save the output\n",
        "    plm_output_filename = f\"output_advanced_{model_id.split('/')[-1]}.txt\"\n",
        "    with open(plm_output_filename, \"w\", encoding=\"utf-8\") as f: f.write(assistant_response)\n",
        "    print(f\"\\n‚úÖ Saved PLM output to {plm_output_filename}\")"
      ],
      "metadata": {
        "id": "9W_3oLu6DcIJ"
      },
      "id": "9W_3oLu6DcIJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summary of Gemma Performance\n",
        "**Result: Failure.** The smaller Gemma-2B model was largely overwhelmed by complex prompts. The larger Gemma-7B model performed similarly to Mistral, correctly following the prompt structure but ultimately hallucinating and defaulting to the one-shot example (\"Now Thank We All Our God.\"), another common but incorrect hymn. It incorrectly linked the liturgical context to the Last Supper and gave a wrong interpretation of the first stanza.\n",
        "\n",
        "**Conclusion:** Gemma also suffers from the \"knowledge gap\" and is not capable of performing the high-level reasoning required for this project.\n",
        "\n",
        "---\n",
        "### 3.3.3: Testing Gemini (PLM)"
      ],
      "metadata": {
        "id": "5GAsQh9Dl0uB"
      },
      "id": "5GAsQh9Dl0uB"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3.3.3a: PLM API Setup (Gemini) ---\n",
        "\n",
        "# Step 1: Install the Google AI library for Python\n",
        "!pip install -q google-generativeai\n",
        "\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# Step 2: Configure the API Key from Colab secrets\n",
        "from google.colab import userdata\n",
        "try:\n",
        "    api_key = userdata.get('GEMINI_API_KEY')\n",
        "    genai.configure(api_key=api_key)\n",
        "    print(\"‚úÖ Gemini API key configured successfully.\")\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"‚ùå Secret 'GEMINI_API_KEY' not found. Please create it in your Colab secrets manager.\")\n",
        "    api_key = None\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    api_key = None\n",
        "\n",
        "# Step 3: Load the Ground-Truth Text\n",
        "if api_key:\n",
        "    transcription_path = \"google_vision_hymn66.txt\"\n",
        "    try:\n",
        "        with open(transcription_path, 'r', encoding='utf-8') as f:\n",
        "            ground_truth_text = f.read()\n",
        "        print(f\"‚úÖ Successfully loaded ground-truth text from '{transcription_path}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå ERROR: Ground-truth text file not found at '{transcription_path}'.\")\n",
        "        ground_truth_text = None\n",
        "\n",
        "    # THIS IS THE NEW PART: Echo the hymn text snippet to match the other cells\n",
        "    if ground_truth_text:\n",
        "        print(\"\\n--- Snippet of Ground-Truth Text ---\")\n",
        "        print(ground_truth_text[:500] + \"...\")"
      ],
      "metadata": {
        "id": "NWIZj5xTIBMi"
      },
      "id": "NWIZj5xTIBMi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3.3.3b: PLM Prompting and Generation (Gemini - Advanced Prompt) ---\n",
        "if api_key and ground_truth_text:\n",
        "    print(\"\\nüöÄ Generating response from Gemini with advanced prompt...\")\n",
        "    gemini_model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "    try:\n",
        "        # We pass the advanced_prompt directly to Gemini\n",
        "        response = gemini_model.generate_content(advanced_prompt)\n",
        "        gemini_response = response.text\n",
        "        print(\"‚úÖ Response generated.\")\n",
        "    except Exception as e:\n",
        "        gemini_response = f\"An error occurred during generation: {e}\"\n",
        "\n",
        "    print(\"\\n--- PLM Model Output (Gemini) ---\")\n",
        "    print(gemini_response)\n",
        "\n",
        "    # Save the output\n",
        "    plm_output_filename = \"output_advanced_gemini-1.5-flash.txt\"\n",
        "    with open(plm_output_filename, \"w\", encoding=\"utf-8\") as f: f.write(gemini_response)\n",
        "    print(f\"\\n‚úÖ Saved PLM output to {plm_output_filename}\")"
      ],
      "metadata": {
        "id": "PYgOweb8IJa_"
      },
      "id": "PYgOweb8IJa_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summary of Gemini Performance\n",
        "**Result: Success.** Using the final, refined prompt, Gemini was the only model to almost successfully solve the problem. It correctly analyzed the Shona text, understood the context, and correctly identified the crucial liturgical context of \"Palm Sunday.\" While it ultimately named the wrong song title, it correctly identified **Paul Gerhardt** as the author. Crucially, it demonstrated advanced reasoning by acknowledging its uncertainty, suggesting its answer was a **\"close variant,\"** which correctly signals that it identified the author and thematic style even if it missed the exact hymn.\n",
        "\n",
        "**Conclusion:** Gemini proves that the \"knowledge gap\" is not universal. With a high-quality transcription and a well-engineered prompt, a top-tier model like Gemini possesses the necessary reasoning power and niche knowledge to perform this complex cross-lingual attribution task. Its ability to express nuanced uncertainty, rather than simply hallucinating, further validates the entire PLM pipeline.\n",
        "\n",
        "---\n",
        "## 3.4: Adjudication & Final Verdict\n",
        "\n",
        "---\n",
        "### 3.4.1: Introduction to Adjudication\n",
        "With the experimental data from both Pipeline A and Pipeline B collected, this sub-phase formally evaluates the results. The analysis is broken into two parts: a quantitative scoring of transcription accuracy and keyword matching, followed by a qualitative report generated by a frontier \"judge\" model to synthesize all findings."
      ],
      "metadata": {
        "id": "HU7gfntqmFRi"
      },
      "id": "HU7gfntqmFRi"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3.4a: Quantitative Analysis (BLEU & Levenshtein) ---\n",
        "\n",
        "# First, ensure the necessary libraries are installed\n",
        "!pip install -q sacrebleu python-levenshtein\n",
        "\n",
        "import sacrebleu\n",
        "import Levenshtein\n",
        "import os\n",
        "import json # To store results\n",
        "\n",
        "# --- Step 1: Define Ground Truth ---\n",
        "ground_truth_title = \"O Lord, How Shall I Meet You\"\n",
        "ground_truth_author = \"Paul Gerhardt\"\n",
        "ground_truth_transcription_path = \"google_vision_hymn66.txt\"\n",
        "\n",
        "try:\n",
        "    with open(ground_truth_transcription_path, 'r', encoding='utf-8') as f:\n",
        "        # We only take the part of the text for Hymn 66 for a fair comparison\n",
        "        ground_truth_transcription = f.read().split('67')[0].strip()\n",
        "    print(\"‚úÖ Ground truth transcription for Hymn 66 loaded.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå Ground truth file not found at {ground_truth_transcription_path}\")\n",
        "    ground_truth_transcription = None\n",
        "\n",
        "# --- Step 2: Load and Score Each Model's Output ---\n",
        "model_outputs_folder = \"/content/\" # Assuming output files are in the main Colab directory\n",
        "output_files = [f for f in os.listdir(model_outputs_folder) if f.startswith('output_') and f.endswith('.txt')]\n",
        "\n",
        "results = []\n",
        "\n",
        "if ground_truth_transcription:\n",
        "    print(\"\\n--- Calculating Scores ---\")\n",
        "    for file in output_files:\n",
        "        model_name = os.path.splitext(file)[0].replace(\"output_advanced_\", \"\").replace(\"output_\", \"\")\n",
        "        with open(os.path.join(model_outputs_folder, file), 'r', encoding='utf-8') as f:\n",
        "            model_output_text = f.read()\n",
        "\n",
        "        # a. Calculate Levenshtein Distance (lower is better)\n",
        "        # Measures the number of edits needed to match the ground truth.\n",
        "        lev_distance = Levenshtein.distance(model_output_text, ground_truth_transcription)\n",
        "\n",
        "        # b. Calculate BLEU Score (higher is better)\n",
        "        # Measures how much of the output matches the n-grams of the ground truth.\n",
        "        bleu_score = sacrebleu.corpus_bleu([model_output_text], [[ground_truth_transcription]]).score\n",
        "\n",
        "        # c. Check for Keyword Matches in reasoning\n",
        "        found_title = ground_truth_title.lower() in model_output_text.lower()\n",
        "        found_author = ground_truth_author.lower() in model_output_text.lower()\n",
        "\n",
        "        print(f\"\\nModel: {model_name}\")\n",
        "        print(f\"  -> Levenshtein Distance: {lev_distance} (lower is better)\")\n",
        "        print(f\"  -> BLEU Score: {bleu_score:.2f} (higher is better)\")\n",
        "        print(f\"  -> Found Correct Title: {found_title}\")\n",
        "        print(f\"  -> Found Correct Author: {found_author}\")\n",
        "\n",
        "        results.append({\n",
        "            \"model\": model_name,\n",
        "            \"levenshtein\": lev_distance,\n",
        "            \"bleu\": round(bleu_score, 2),\n",
        "            \"found_title\": found_title,\n",
        "            \"found_author\": found_author\n",
        "        })\n",
        "\n",
        "    # Save structured results for later use\n",
        "    with open(\"quantitative_results.json\", \"w\") as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    print(\"\\n‚úÖ Saved quantitative results to quantitative_results.json\")"
      ],
      "metadata": {
        "id": "CYRnGhuLOoLf"
      },
      "id": "CYRnGhuLOoLf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4.2: Final Analysis of Results\n",
        "The quantitative and qualitative results tell a clear and consistent story. The adjudication confirms that no model successfully identified the correct original title and author. The VLM models (Pipeline A) failed quantitatively on transcription metrics (BLEU/Levenshtein), while the PLM models (Pipeline B), though given perfect text, failed on the final reasoning task. The \"judge\" model's final report synthesizes these individual failures into a cohesive project conclusion."
      ],
      "metadata": {
        "id": "zFEtS--fm9rV"
      },
      "id": "zFEtS--fm9rV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Secure Setup for GPT-4o Adjudication"
      ],
      "metadata": {
        "id": "aDNiRSe_d1xL"
      },
      "id": "aDNiRSe_d1xL"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3.4b: Secure Setup for the \"Judge\" Model ---\n",
        "\n",
        "# Step 1: Install the OpenAI library\n",
        "!pip install -q openai\n",
        "\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Step 2: Securely configure the API Key\n",
        "# IMPORTANT: First, create a new secret in Colab named 'OPENAI_API_KEY' and paste your new key there.\n",
        "try:\n",
        "    openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "    print(\"‚úÖ OpenAI API key configured successfully.\")\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"‚ùå Secret 'OPENAI_API_KEY' not found. Please create it in your Colab secrets manager.\")\n",
        "    openai.api_key = None\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    openai.api_key = None"
      ],
      "metadata": {
        "id": "wyMDtoKyRbQ2"
      },
      "id": "wyMDtoKyRbQ2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load All Experimental Results"
      ],
      "metadata": {
        "id": "bJnTnJpEdrfM"
      },
      "id": "bJnTnJpEdrfM"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3.4c: Load All Experimental Results ---\n",
        "\n",
        "import os\n",
        "\n",
        "# Helper function to read files safely\n",
        "def read_file_content(filename):\n",
        "    \"\"\"Reads content from a file if it exists, otherwise returns an error message.\"\"\"\n",
        "    try:\n",
        "        with open(filename, 'r', encoding='utf-8') as f:\n",
        "            return f.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Output file not found: {filename}\"\n",
        "\n",
        "# Load the ground truth transcription\n",
        "google_ocr_text = read_file_content(\"google_vision_hymn66.txt\")\n",
        "\n",
        "# Load the outputs from all VLM and PLM tests you ran\n",
        "# Using the final simplified prompt outputs for VLMs\n",
        "idefics_transcription = read_file_content(\"output_idefics-9b-instruct.txt\")\n",
        "llava_transcription = read_file_content(\"output_llava-1.5-7b-hf.txt\")\n",
        "shikra_response = read_file_content(\"output_bakLlava-v1-hf.txt\") # We used BakLlava as the replacement\n",
        "\n",
        "# Using one of the advanced prompt outputs for PLMs\n",
        "full_response = read_file_content(\"output_advanced_gemma-7b-it.txt\") # Assuming this is the final Gemma 7B output\n",
        "mistral_response = read_file_content(\"output_advanced_Mistral-7B-Instruct-v0.2.txt\")\n",
        "gemini_response = read_file_content(\"output_advanced_gemini-1.5-flash.txt\")\n",
        "\n",
        "print(\"‚úÖ All model outputs loaded into memory.\")"
      ],
      "metadata": {
        "id": "3pSldOGfWGcl"
      },
      "id": "3pSldOGfWGcl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run Final Judgement via GPT-4o"
      ],
      "metadata": {
        "id": "I_3i-qkCdiPD"
      },
      "id": "I_3i-qkCdiPD"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3.4d: The Final Judgement (with full prompt context) ---\n",
        "\n",
        "# First, check if the API key was loaded correctly\n",
        "if openai.api_key:\n",
        "    # Optional: Provide a public image link to the scanned Shona hymn page\n",
        "    image_url = \"/content/converted_images/IMG_8588.png\"\n",
        "\n",
        "    # Prompt context recap for fairness\n",
        "    prompt_context = f\"\"\"\n",
        "--- Prompt Contexts Used for Each Model Type ---\n",
        "\n",
        "üì∏ Shared Image: {image_url if image_url else '[Not provided]'}\n",
        "\n",
        "üßæ Prompt to Vision-Language Models (VLMs like IDEFICS, LLaVA, BakLlava):\n",
        "USER: <image>\n",
        "Transcribe Hymn 66, which begins 'Ndichamugamuchira', from this image and then identify its original title and author.\n",
        "ASSISTANT:\n",
        "\n",
        "üßæ Prompt to Pretrained Language Models (PLMs like Gemma, Gemini, Mistral):\n",
        "\n",
        "You are an AI expert in Christian hymnology, specializing in analyzing translations in the ELCZ Shona hymnbook, which often have German Lutheran hymn origins.\n",
        "I will provide text from the Shona hymnbook and you must identify the original, or equivalent English hymn.\n",
        "\n",
        "Example:\n",
        "- Shona Hymn Text Snippet: 'Hymn 69. 1. Toonga Ba......mbo Nemwoyo yedu yose;'\n",
        "- Correct Original English Title: 'Now Thank We All Our God' (German: 'Nun danket alle Gott')\n",
        "- Author: 'Martin Rinckart'\n",
        "\n",
        "Now analyze the ground truth for Hymn 66 ('Ndichamugamuchira Nokuchingura nei?') and:\n",
        "1. Thematic analysis\n",
        "2. Liturgical reference\n",
        "3. Translate first stanza\n",
        "4. Conclude with Title and Author.\n",
        "\"\"\"\n",
        "\n",
        "    # Compose the judge prompt with all model outputs\n",
        "    judge_prompt = f\"\"\"\n",
        "You are a multilingual hymnologist and AI evaluator.\n",
        "\n",
        "{prompt_context}\n",
        "\n",
        "Your task is to analyze the following AI-generated responses. Each one was produced by a different model attempting to identify the English hymn that corresponds to a scanned Shona hymn page (Hymn 66, beginning with 'Ndichamugamuchira').\n",
        "\n",
        "Before you begin, here is the ground truth for reference:\n",
        "\n",
        "üìå **Ground Truth Reference**:\n",
        "- **Original English Title**: \"O Lord, How Shall I Meet You\"\n",
        "- **Author**: Paul Gerhardt (1653); English translation by Catherine Winkworth\n",
        "- **First Stanza**:\n",
        "  O Lord, how shall I meet You,\n",
        "  How welcome You aright?\n",
        "  Your people long to greet You,\n",
        "  My hope, my heart's delight!\n",
        "  O kindle, Lord most holy,\n",
        "  Your lamp within my breast,\n",
        "  To do in spirit lowly\n",
        "  All that may please You best.\n",
        "\n",
        "Use this ground truth to guide your evaluation.\n",
        "\n",
        "Here are the model responses:\n",
        "\n",
        "1. **IDEFICS (VLM)**:\n",
        "{idefics_transcription}\n",
        "\n",
        "2. **LLaVA (VLM)**:\n",
        "{llava_transcription}\n",
        "\n",
        "3. **BakLlava (VLM - replacing Shikra)**:\n",
        "{shikra_response}\n",
        "\n",
        "4. **GoogleOCR (Ground Truth Text)**:\n",
        "{google_ocr_text}\n",
        "\n",
        "5. **Gemma-7B (PLM)**:\n",
        "{full_response}\n",
        "\n",
        "6. **Mistral-7B (PLM)**:\n",
        "{mistral_response}\n",
        "\n",
        "7. **Gemini-1.5-Flash (PLM)**:\n",
        "{gemini_response}\n",
        "\n",
        "---\n",
        "\n",
        "Your job:\n",
        "\n",
        "- üèÜ Rank the responses from best to worst based on their accuracy and reasoning quality.\n",
        "- ‚úÖ Justify your ranking ‚Äî focus on how closely each matches the **true hymn title, author, and meaning**.\n",
        "- üß† If needed, suggest a **merged final version** or definitive conclusion.\n",
        "\n",
        "Respond in this format:\n",
        "\n",
        "Final Ranking:\n",
        "1. Model Name ‚Äî justification\n",
        "2. Model Name ‚Äî justification\n",
        "...\n",
        "\n",
        "Best Match: <Model Name>\n",
        "\n",
        "Suggested Synthesized Hymn (Optional):\n",
        "<Your version>\n",
        "\"\"\"\n",
        "\n",
        "    # üöÄ Send to GPT-4o and receive verdict\n",
        "    print(\"üöÄ Sending request to GPT-4o for final adjudication...\")\n",
        "    try:\n",
        "        client = openai.OpenAI(api_key=openai.api_key)\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[{\"role\": \"user\", \"content\": judge_prompt}],\n",
        "            temperature=0.2,\n",
        "            max_tokens=800\n",
        "        )\n",
        "\n",
        "        print(\"\\n--- üìú Final Judgement by GPT-4o (LLARA) ---\\n\")\n",
        "        print(response.choices[0].message.content)\n",
        "\n",
        "        # Save the final report\n",
        "        with open(\"FINAL_PROJECT_REPORT.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(response.choices[0].message.content)\n",
        "        print(\"\\n‚úÖ Saved final judgement report to FINAL_PROJECT_REPORT.txt\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå An error occurred: {e}\")\n",
        "else:\n",
        "    print(\"‚ùå OpenAI API key not configured. Cannot run final adjudication.\")\n"
      ],
      "metadata": {
        "id": "KsvD9W_dWUYY"
      },
      "id": "KsvD9W_dWUYY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5: Post-Adjudication Structuring & Enrichment\n",
        "\n",
        "---\n",
        "### 3.5.1: Introduction to Structuring\n",
        "With the analysis complete, the final step in this phase is to take our best data‚Äîthe ground-truth transcription from Google Vision‚Äîand process it into a production-ready, structured format. This involves segmenting the text into stanzas, enriching each stanza with AI-generated thematic tags, and packaging the result in a clean JSON format for downstream consumption by an application or voice synthesis engine."
      ],
      "metadata": {
        "id": "JfeiuSnyml9l"
      },
      "id": "JfeiuSnyml9l"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3.5.1: Post-Adjudication Structuring & Enrichment (Corrected) ---\n",
        "\n",
        "import re\n",
        "import json\n",
        "import google.generativeai as genai\n",
        "from IPython.display import JSON, display # Import display here\n",
        "\n",
        "# --- Step 1: Load the Ground-Truth Transcription ---\n",
        "ground_truth_file = \"google_vision_hymn66.txt\"\n",
        "try:\n",
        "    with open(ground_truth_file, 'r', encoding='utf-8') as f:\n",
        "        full_hymn_text = f.read()\n",
        "    print(f\"‚úÖ Successfully loaded ground truth text from '{ground_truth_file}'.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå Ground truth file not found. This cell cannot run without it.\")\n",
        "    full_hymn_text = None\n",
        "\n",
        "# --- Step 2: Robust Stanza Segmentation ---\n",
        "structured_hymn = {\n",
        "    \"hymn_number\": 66,\n",
        "    \"title\": \"Ndichamugamuchira\",\n",
        "    \"stanzas\": []\n",
        "}\n",
        "\n",
        "if full_hymn_text:\n",
        "    # First, isolate the text block belonging only to Hymn 66\n",
        "    # It starts after \"66\" and ends before \"67\"\n",
        "    match = re.search(r'\\b66\\b(.*?)\\n\\s*\\b67\\b', full_hymn_text, re.DOTALL)\n",
        "    if match:\n",
        "        hymn_66_content = match.group(1).strip()\n",
        "\n",
        "        # Now, split the isolated text by the stanza numbers (e.g., \"1 \", \"2 \")\n",
        "        # This regex looks for a number at the beginning of a line.\n",
        "        # We add a dummy delimiter at the start to make splitting easier.\n",
        "        stanzas_with_delimiters = re.split(r'(\\n\\s*[1-9]\\s)', \"\\n\" + hymn_66_content)\n",
        "\n",
        "        # The split results in a list like ['', '\\n1 ', 'stanza 1 text', '\\n2 ', 'stanza 2 text', ...]\n",
        "        # We iterate through this list to build our clean stanza objects.\n",
        "        for i in range(1, len(stanzas_with_delimiters), 2):\n",
        "            try:\n",
        "                stanza_number = int(stanzas_with_delimiters[i].strip())\n",
        "                stanza_text = stanzas_with_delimiters[i+1].strip()\n",
        "                # Clean up any leftover hymn titles\n",
        "                stanza_text = re.sub(r'JESU KRISTU\\.', '', stanza_text, flags=re.IGNORECASE).strip()\n",
        "\n",
        "                if stanza_text:\n",
        "                    structured_hymn[\"stanzas\"].append({\n",
        "                        \"stanza_number\": stanza_number,\n",
        "                        \"text\": stanza_text,\n",
        "                        \"tags\": [] # We will populate this next\n",
        "                    })\n",
        "            except (ValueError, IndexError):\n",
        "                # This handles any stray parts from the split that aren't valid stanzas\n",
        "                continue\n",
        "        print(f\"‚úÖ Correctly segmented Hymn 66 into {len(structured_hymn['stanzas'])} stanzas.\")\n",
        "    else:\n",
        "        print(\"‚ùå Could not isolate the text for Hymn 66.\")\n",
        "\n",
        "\n",
        "# --- Step 3: Metadata Tagging using Gemini API ---\n",
        "# Ensure API key is available for tagging\n",
        "from google.colab import userdata\n",
        "try:\n",
        "    api_key = userdata.get('GEMINI_API_KEY')\n",
        "    genai.configure(api_key=api_key)\n",
        "    print(\"‚úÖ Gemini API key configured for tagging.\")\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"‚ùå Secret 'GEMINI_API_KEY' not found. Cannot perform tagging.\")\n",
        "    api_key = None\n",
        "\n",
        "def get_tags_for_stanza(stanza_text):\n",
        "    # Check if the API key exists in the current session\n",
        "    if 'api_key' not in globals() or not api_key:\n",
        "        return [\"Error: API Key not configured. Please run setup cell.\"]\n",
        "\n",
        "    tagging_model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "    prompt = f\"\"\"Analyze the following Shona hymn stanza. Based on its content, provide a few relevant tags for its primary theme, mood, and imagery. Respond with only a comma-separated list of 3-5 keywords.\n",
        "\n",
        "Stanza:\n",
        "---\n",
        "{stanza_text}\n",
        "---\n",
        "\"\"\"\n",
        "    try:\n",
        "        response = tagging_model.generate_content(prompt)\n",
        "        tags = [tag.strip() for tag in response.text.split(',')]\n",
        "        return tags\n",
        "    except Exception as e:\n",
        "        return [f\"Error during tagging: {e}\"]\n",
        "\n",
        "print(\"\\nü§ñ Generating thematic tags for each stanza...\")\n",
        "if structured_hymn[\"stanzas\"]:\n",
        "    # Check if api_key is available before attempting to tag\n",
        "    if api_key:\n",
        "        for stanza in structured_hymn[\"stanzas\"]:\n",
        "            stanza_tags = get_tags_for_stanza(stanza[\"text\"])\n",
        "            stanza[\"tags\"] = stanza_tags\n",
        "            print(f\"  -> Stanza {stanza['stanza_number']} tags: {stanza_tags}\")\n",
        "    else:\n",
        "        print(\"Skipping tagging due to missing API key.\")\n",
        "else:\n",
        "    print(\"No stanzas found to tag.\")\n",
        "\n",
        "\n",
        "# --- Step 4: Final JSON Packaging and Display ---\n",
        "# Save the structured data to a JSON file\n",
        "output_json_file = \"hymn_66_structured.json\"\n",
        "with open(output_json_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(structured_hymn, f, indent=2)\n",
        "print(f\"\\nüíæ Saved structured hymn data to '{output_json_file}'.\")\n",
        "\n",
        "# Display the structured data as JSON output in Colab\n",
        "print(\"\\n--- Structured Hymn Data (JSON Output) ---\")\n",
        "display(JSON(structured_hymn)) # Use display(JSON(...)) for rich output"
      ],
      "metadata": {
        "id": "c6LCBKexbEay"
      },
      "id": "c6LCBKexbEay",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.5.2: Final Formatted Report for Hymn 66"
      ],
      "metadata": {
        "id": "iVIOfNDe2zYA"
      },
      "id": "iVIOfNDe2zYA"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3.5.2: Formatted Report from Structured Data ---\n",
        "\n",
        "import json\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Define the path to your final JSON file\n",
        "json_file_path = \"hymn_66_structured.json\"\n",
        "\n",
        "# --- Load the Structured Data ---\n",
        "try:\n",
        "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
        "        hymn_data = json.load(f)\n",
        "    print(f\"‚úÖ Successfully loaded structured data from '{json_file_path}'.\\n\")\n",
        "\n",
        "    # --- Generate the Formatted Report ---\n",
        "\n",
        "    # Main Hymn Heading\n",
        "    display(Markdown(f\"# Hymn {hymn_data.get('hymn_number', 'N/A')}: {hymn_data.get('title', 'No Title')}\"))\n",
        "    display(Markdown(\"---\"))\n",
        "\n",
        "    # Loop through each stanza to display its details\n",
        "    for stanza in hymn_data.get('stanzas', []):\n",
        "        stanza_num = stanza.get('stanza_number', 'N/A')\n",
        "        stanza_text = stanza.get('text', 'No text available.')\n",
        "        stanza_tags = stanza.get('tags', [])\n",
        "\n",
        "        # Stanza Subheading\n",
        "        display(Markdown(f\"### Stanza {stanza_num}\"))\n",
        "\n",
        "        # Stanza Text\n",
        "        # The .replace() makes the newlines display correctly in Colab's print output\n",
        "        print(stanza_text.replace('\\\\n', '\\n'))\n",
        "\n",
        "        # Tags Subheading and list\n",
        "        display(Markdown(\"--- \\n**AI-Generated Thematic Tags:**\"))\n",
        "        # We join the list of tags into a nice comma-separated string\n",
        "        print(\", \".join(stanza_tags))\n",
        "\n",
        "        # Add a clear separator between stanzas\n",
        "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå ERROR: The file '{json_file_path}' was not found. Please ensure the previous cell was run successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "k4mKp6fi2283"
      },
      "id": "k4mKp6fi2283",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JSON Formatted Report for Hymn 66 with Thematic Tags\n",
        "This formatted report, presenting the fully segmented and thematically enriched hymn, represents the final deliverable of our data processing pipeline. With this clean and structured asset created, the experimental analysis of Phase 3 is now complete.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "O2zinjg5g7nt"
      },
      "id": "O2zinjg5g7nt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Summary for Phase 3\n",
        "\n",
        ">This phase successfully executed a rigorous comparison between two AI methodologies for a complex \"translation traceback\" task.\n",
        "\n",
        "The key finding is that **neither pipeline could reliably solve the problem end-to-end, but they failed for different, informative reasons.**\n",
        "\n",
        "\n",
        "### Pipeline A: The VLM Bake-Off - A Study in Failure\n",
        "\n",
        "The first pipeline tested if advanced Vision-Language Models (VLMs) like **LLaVA**, **IDEFICS**, and **BakLlava** could perform both OCR and reasoning directly from the hymnbook image.\n",
        "\n",
        "#### Summary of Findings:\n",
        "This approach was **conclusively proven to be not viable.**\n",
        "* **Root Cause:** A consistent and fundamental failure to perform accurate Optical Character Recognition (OCR) on the specialized, non-English text.\n",
        "* **Evidence:** Across all models and even with advanced \"Chain-of-Thought\" prompts, the models failed to produce a correct transcription. Instead, they produced a variety of critical errors, including:\n",
        "    * Hallucinating unrelated English poems (LLaVA).\n",
        "    * Incorrectly identifying the language and transcribing in Greek (IDEFICS).\n",
        "    * Inventing non-existent Swahili phrases (BakLlava).\n",
        "* **Conclusion:** Without a correct transcription, all subsequent reasoning was ungrounded and resulted in complete hallucinations. The quantitative BLEU and Levenshtein scores confirmed that the VLM outputs had no statistical similarity to the ground-truth text.\n",
        "\n",
        "### Pipeline B: The PLM Bake-Off - A Journey into a Knowledge Gap\n",
        "\n",
        "This pipeline provided the models with a perfect, high-fidelity transcription from Google Vision API to test their pure reasoning ability. The bake-off included **Mistral-7B**, **Gemma (2B & 7B)**, and **Gemini 1.5 Flash**.\n",
        "\n",
        "#### Summary of Findings:\n",
        "This approach, while superior to Pipeline A, also failed to produce the correct answer, but the journey revealed the true nature of the problem.\n",
        "* **Iterative Prompting:** A series of increasingly sophisticated prompts were engineered, from simple zero-shot to advanced \"Chain-of-Thought\" and \"One-Shot Hybrid\" prompts.\n",
        "* **Revealed Failure Modes:** This iterative process proved that the models were not failing due to poor prompting, but due to inherent limitations:\n",
        "    * **Overfitting:** Less capable models like Gemma consistently over-fit to the examples provided in the prompt, ignoring the actual hymn text.\n",
        "    * **Plausible Hallucination:** Models like Mistral were easily biased by contextual hints, leading them to hallucinate plausible but incorrect authors and titles.\n",
        "    * **The Knowledge Gap:** The most capable model, Gemini, successfully performed complex reasoning (e.g., identifying the \"Palm Sunday\" context). However, it still concluded it could not be certain of the answer. This proved that the failure was not in reasoning, but in a **fundamental knowledge gap** in its training data regarding the specific origins of the ELCZ hymnbook.\n",
        "\n",
        "\n",
        "> The project successfully mapped the capabilities and limitations of several state-of-the-art models and concluded by creating a valuable, structured data asset from the ground-truth text, setting the stage for future work.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "## üìñ Phase 4: Cross-Lingual Alignment via Semantic Similarity\n",
        "\n",
        "\n",
        "### üìö From Analysis to Automation\n",
        "Having proven that text-based prompting alone was insufficient, the project now seeks to leverage new methodology designed to bypass the \"knowledge gap.\"\n",
        "\n",
        "Phase 4, therefore, pivots from individual hymn analysis to a more scalable, programmatic approach. The objective of this phase is to build and evaluate an automated system for **Cross-Lingual Hymn Alignment**‚Äîa method to automatically match Shona hymns to their likely English or German source texts from a large corpus, based on semantic meaning rather than prior knowledge.\n",
        "\n",
        "\n",
        "### üèóÔ∏è Methodology: Sentence Embeddings\n",
        "To achieve this, we will move beyond prompting and into the domain of **Semantic Similarity** and **Sentence Embeddings**. This is a powerful NLP technique that allows us to compare the *meaning* of sentences, even across different languages.\n",
        "\n",
        "The workflow will be as follows:\n",
        "\n",
        "**1. Data Corpus Creation:** We will create two text corpuses: one containing the Shona hymns from your hymnbook, and another containing the lyrics of potential source hymns in English and German.\n",
        "\n",
        "**2. Vectorization with LaBSE:** We will use a powerful multilingual model like **LaBSE (Language-Agnostic BERT Sentence Embedding)** to convert each line or stanza of every hymn into a high-dimensional vector‚Äîa mathematical representation of its meaning. The key feature of LaBSE is that sentences with similar meanings will have similar vectors, regardless of the language.\n",
        "\n",
        "**3. Cosine Similarity Matching:** We will then programmatically calculate the **cosine similarity** between the vectors of the Shona hymns and the vectors of the source hymns. Hymn pairs with the highest similarity score are the most likely matches.\n",
        "\n",
        "**4. Validation:** The system's output will be a ranked list of potential matches for any given Shona hymn, which can then be manually verified for accuracy.\n",
        "\n",
        "This phase represents a significant step up in technical complexity, aiming to create a powerful and reusable tool for hymnological research.\n",
        "\n",
        "---\n",
        "### 4.1: Setup for Semantic Similarity"
      ],
      "metadata": {
        "id": "OuIMbVdFndbO"
      },
      "id": "OuIMbVdFndbO"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4.1: LaBSE Setup (Safe with Current NumPy) ---\n",
        "\n",
        "!pip install -q torch==2.2.2+cu121 torchvision==0.17.2+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html\n",
        "!pip install -q sentence-transformers==2.7.0 transformers==4.40.1\n",
        "\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\"‚úÖ Hugging Face login successful.\")\n",
        "except:\n",
        "    print(\"üîì Skipped login (no token set).\")\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "print(\"üîÅ Loading SentenceTransformer model: LaBSE...\")\n",
        "semantic_model = SentenceTransformer(\"sentence-transformers/LaBSE\")\n",
        "print(f\"‚úÖ Model loaded on device: {semantic_model.device}\")"
      ],
      "metadata": {
        "id": "CMNwZjSjb7x6"
      },
      "id": "CMNwZjSjb7x6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4.2: Reinstate Ground Truth Text File ---\n",
        "\n",
        "# Define the full text content for Hymn 66\n",
        "# This is the text you provided from the successful Google Vision API run.\n",
        "ground_truth_text = \"\"\"\n",
        "66\n",
        "1 Ndichamugamuchira\n",
        "Nokuchingura nei?\n",
        "Ndichamunamati-ra\n",
        "Nokubatira sei?\n",
        "JESU KRISTU.\n",
        "SHE, mundiudze kwazvo,\n",
        "Muchanakirwa nei?\n",
        "Zvomunotenda nazvo,\n",
        "Ndingamufadza sei?\n",
        "2 VeZion vakawadza\n",
        "Mashizha kareko;\n",
        "Neni handingaregi\n",
        "Kumuchingurawo;\n",
        "Nomwoyo wangu wose\n",
        "Ndichamuimbirai,\n",
        "Ndinoda kumukudza,\n",
        "Nokumurumbidzai!\n",
        "3 Ndakanga ndakasungwa,\n",
        "Madzikunure'ni:\n",
        "Ndakanga ndakanyadzwa,\n",
        "Ndamutswa, SHE, nemi;\n",
        "Mandivigire fuma\n",
        "Yabva kudenga'ko;\n",
        "Ndiyo yokusaora,\n",
        "Nokusaperawo.\n",
        "4 SHE JESU uchauya\n",
        "Kuzotongesazve;\n",
        "Bva avo vakatenda\n",
        "Havangazomutyi;\n",
        "Uya-i Tenzi Jesu!\n",
        "Kudenga tiisei,\n",
        "Kwatichafara isu,\n",
        "Tichinakirwa sei!\"\"\"\n",
        "\n",
        "# Write the text to the file\n",
        "file_name = \"google_vision_hymn66.txt\"\n",
        "with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(ground_truth_text)\n",
        "\n",
        "print(f\"‚úÖ Ground truth file '{file_name}' has been successfully reinstated.\")"
      ],
      "metadata": {
        "id": "wFpiUaZuGbfe"
      },
      "id": "wFpiUaZuGbfe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2: Data Corpus Preparation"
      ],
      "metadata": {
        "id": "VmMmStuB3o5Y"
      },
      "id": "VmMmStuB3o5Y"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4.3: Prepare Shona and English Data Corpuses ---\n",
        "\n",
        "import re\n",
        "\n",
        "# --- Step 1: Load and Prepare the Shona Hymn Stanzas ---\n",
        "shona_stanzas = []\n",
        "\n",
        "try:\n",
        "    # Use in-memory string from 4.2 (ground_truth_text)\n",
        "    full_hymn_text = ground_truth_text\n",
        "\n",
        "    # Extract everything after \"66\"\n",
        "    match = re.search(r'\\b66\\b(.*)', full_hymn_text, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        hymn_66_content = match.group(1).strip()\n",
        "\n",
        "        # Split stanzas by numbered markers like '\\n 1', '\\n 2', etc.\n",
        "        stanzas_with_delimiters = re.split(r'(\\n\\s*\\d+\\s)', \"\\n\" + hymn_66_content)\n",
        "\n",
        "        for i in range(1, len(stanzas_with_delimiters), 2):\n",
        "            try:\n",
        "                stanza_text = stanzas_with_delimiters[i+1].strip()\n",
        "                stanza_text = re.sub(r'JESU KRISTU\\.', '', stanza_text, flags=re.IGNORECASE).strip()\n",
        "                if stanza_text:\n",
        "                    shona_stanzas.append(stanza_text)\n",
        "            except (ValueError, IndexError):\n",
        "                continue\n",
        "\n",
        "    if shona_stanzas:\n",
        "        print(f\"‚úÖ Prepared {len(shona_stanzas)} stanzas from Shona Hymn 66.\")\n",
        "    else:\n",
        "        print(\"‚ùå Failed to extract any stanzas. Please check the regex and input.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå An unexpected error occurred: {e}\")\n",
        "    shona_stanzas = None\n",
        "\n",
        "# --- Step 2: Create a Corpus of Potential English Source Hymns ---\n",
        "english_hymn_corpus = [\n",
        "    # Correct match for Hymn 66\n",
        "    \"O Lord, how shall I meet You, How welcome You aright? Your people long to greet You, My hope, my heart's delight! O kindle, Lord most holy, Your lamp within my breast, To do in spirit lowly All that may please You best.\",\n",
        "\n",
        "    # Distractor 1 (From Hymn 67's origin)\n",
        "    \"All hail the power of Jesus' name! Let angels prostrate fall; Bring forth the royal diadem, And crown Him Lord of all.\",\n",
        "\n",
        "    # Distractor 2 (From Hymn 69's origin)\n",
        "    \"Now thank we all our God, With heart and hands and voices, Who wondrous things hath done, In whom His world rejoices.\",\n",
        "\n",
        "    # Distractor 3 (Different famous hymn)\n",
        "    \"Amazing grace! how sweet the sound, That saved a wretch like me! I once was lost, but now am found, Was blind, but now I see.\"\n",
        "]\n",
        "\n",
        "english_hymn_titles = [\n",
        "    \"O Lord, How Shall I Meet You\",\n",
        "    \"All Hail the Power of Jesus' Name\",\n",
        "    \"Now Thank We All Our God\",\n",
        "    \"Amazing Grace\"\n",
        "]\n",
        "\n",
        "print(f\"‚úÖ Created an English corpus with {len(english_hymn_corpus)} potential hymn stanzas.\")"
      ],
      "metadata": {
        "id": "6bzgaO_I3qDr"
      },
      "id": "6bzgaO_I3qDr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3: Generate Embeddings & Find Best Match"
      ],
      "metadata": {
        "id": "4cm3x7V5l1dR"
      },
      "id": "4cm3x7V5l1dR"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4.4: Generate Embeddings and Calculate Similarity ---\n",
        "\n",
        "from sentence_transformers import util\n",
        "import torch\n",
        "\n",
        "# --- Step 1: Generate Embeddings ---\n",
        "# The .encode() method turns each stanza into a high-dimensional vector.\n",
        "# This runs on GPU if available, making it fast.\n",
        "\n",
        "print(\"Generating embeddings for Shona and English corpuses...\")\n",
        "\n",
        "if shona_stanzas and english_hymn_corpus:\n",
        "    shona_embeddings = semantic_model.encode(shona_stanzas, convert_to_tensor=True)\n",
        "    english_embeddings = semantic_model.encode(english_hymn_corpus, convert_to_tensor=True)\n",
        "    print(\"‚úÖ Embeddings generated successfully.\")\n",
        "\n",
        "    # --- Step 2: Calculate Cosine Similarity ---\n",
        "    # Result is a matrix: scores[i][j] = similarity between Shona[i] and English[j]\n",
        "    cosine_scores = util.cos_sim(shona_embeddings, english_embeddings)\n",
        "    print(\"‚úÖ Cosine similarity scores calculated.\")\n",
        "\n",
        "    # --- Step 3: Find and Display the Best Match for Each Stanza ---\n",
        "    print(\"\\n--- Semantic Search Results ---\")\n",
        "\n",
        "    for i, shona_stanza in enumerate(shona_stanzas):\n",
        "        best_match_index = torch.argmax(cosine_scores[i])\n",
        "        best_match_score = cosine_scores[i][best_match_index]\n",
        "        best_matching_hymn_title = english_hymn_titles[best_match_index]\n",
        "\n",
        "        print(f\"\\nProcessing Shona Stanza {i + 1}:\")\n",
        "        print(f\"  -> Best English Match: '{best_matching_hymn_title}'\")\n",
        "        print(f\"  -> Similarity Score: {best_match_score:.4f}\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Cannot proceed. Shona stanzas or English corpus not loaded correctly.\")"
      ],
      "metadata": {
        "id": "F53iq0Vy4OHM"
      },
      "id": "F53iq0Vy4OHM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìñ Final Summary for Phase 4\n",
        "\n",
        "###  From Analysis to a Working Solution\n",
        "We concluded by designing and validating an alternative, successful methodology using semantic search, providing a clear and robust path forward for solving the \"translation traceback\" problem at scale.\n",
        "\n",
        "### Final Result: A Definitive Success\n",
        "\n",
        "The semantic search approach was **100% successful.**\n",
        "* For every single stanza of Hymn 66, the system correctly and unambiguously identified **\"O Lord, How Shall I Meet You\"** as the closest semantic match.\n",
        "* This proves that by comparing meaning directly, the AI can successfully \"align\" the translated text with its source, a task it was unable to perform using prompting-based reasoning alone.\n",
        "\n",
        "---\n",
        "\n",
        "## **Project Conclusion**\n",
        "\n",
        "This project successfully designed, executed, and analyzed a rigorous, multi-phase experiment to test the limits of modern AI on a specialized, real-world task. It has demonstrated that while generative AI models possess powerful reasoning capabilities, they are limited by the contents of their training data and can fail on niche knowledge tasks.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "HyTgVmhy5V-0"
      },
      "id": "HyTgVmhy5V-0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## üîä Phase 5: Exploring Text-to-Speech (TTS) Technologies\n",
        "\n",
        "\n",
        "### üìñ Objective:\n",
        "Having successfully created structured text data, this phase explores the practical implementation of converting that data into high-quality audio. This will be a series of **independent case studies** into different state-of-the-art TTS technologies, documenting the process and outcome for each.\n",
        "\n",
        "The exploration will cover three distinct approaches:\n",
        "\n",
        "1.  **An Open-Source Model (Coqui XTTS):** To establish a baseline of what is achievable with well-documented, open-source tools and to evaluate its general voice cloning quality.\n",
        "\n",
        "2.  **A High-Performance Generative Model (Sesame/CSM):** To evaluate the quality and workflow of a more advanced, in-context learning model. This represents a different architectural approach to voice cloning and will be compared against the Coqui baseline.\n",
        "\n",
        "3.  **A Third Alternative (Dier):** As a placeholder for further research into other emerging or proprietary TTS solutions.\n",
        "\n",
        "### Future Work (Phase 6): Fine-Tuning\n",
        "\n",
        "Based on the results of these case studies, a future phase will focus on **fine-tuning** the most promising model. This will involve preparing a larger, dedicated dataset of a single speaker to create a truly custom, high-fidelity voice for the MonReader project."
      ],
      "metadata": {
        "id": "rooEPNXmv3V9"
      },
      "id": "rooEPNXmv3V9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## üéôÔ∏è 5.1: Case Study - Open-Source Model (Coqui XTTS)\n",
        "\n",
        "### Foundational Understanding & Experimental Design\n",
        "\n",
        "This first case study explores the implementation of a leading open-source solution: **Coqui TTS**, and its flagship multilingual model, **XTTS**.\n",
        "\n",
        "Unlike a proprietary API, Coqui TTS provides a full toolkit and access to the underlying model architecture, which is based on the highly specialized **VITS (Variational Inference with a Normalizing Flow-based Text-to-Speech)** system. This approach uses a multi-stage process to generate high-quality, natural-sounding audio.\n",
        "\n",
        "Our experiments will focus on leveraging its primary capability: high-fidelity, **zero-shot voice cloning** from a minimal audio sample.\n",
        "\n",
        "Critically, our research has confirmed that while powerful, the pre-trained XTTS model does not have native support for the Shona language. Therefore, the goal of this case study is twofold:\n",
        "1.  Benchmark its ability to generate high-quality speech for a supported language (English).\n",
        "2.  Document its behavior when processing an unsupported language (Shona) to establish a baseline for a future fine-tuning project.\n",
        "\n",
        "This exploration will serve as a comprehensive evaluation of the capabilities and limitations of a state-of-the-art open-source TTS system.\n",
        "\n",
        "---\n",
        "### ‚öôÔ∏è 5.1.1: Environment Setup for Coqui XTTS\n",
        "\n",
        "Installs required dependencies, handles Hugging Face authentication, and mounts Google Drive to enable voice cloning with Coqui XTTS."
      ],
      "metadata": {
        "id": "CponzOR4v3Rm"
      },
      "id": "CponzOR4v3Rm"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.1.1a: INSTALLATION ONLY ---\n",
        "\n",
        "# 1. Install the specific, stable version of the Coqui TTS library and pydub\n",
        "print(\"Installing Coqui TTS v0.22.0 and pydub...\")\n",
        "!pip install -q TTS==0.22.0 pydub --user\n",
        "\n",
        "# 2. Downgrade the 'transformers' library to the last known compatible version\n",
        "print(\"\\nDowngrading 'transformers' library for compatibility...\")\n",
        "!pip install -q transformers==4.35.2 --user  # Using a known stable version\n",
        "\n",
        "# 3. Reinstall torch and torchaudio to ensure compatibility after other installs\n",
        "# This is crucial for resolving potential conflicts.\n",
        "print(\"\\nReinstalling torch and torchaudio...\")\n",
        "!pip install -q torch==2.2.2+cu121 torchaudio==2.2.2+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html --user\n",
        "\n",
        "print(\"\\n‚úÖ Installations complete. IMPORTANT: Please restart the runtime now.\")"
      ],
      "metadata": {
        "id": "vvifoOBisweL"
      },
      "id": "vvifoOBisweL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.1.1b: Environment Setup (Run AFTER Restart) ---\n",
        "\n",
        "# 1. Import all necessary components\n",
        "import os\n",
        "import torch\n",
        "from google.colab import drive, userdata\n",
        "from huggingface_hub import login\n",
        "from TTS.api import TTS\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "# 2. Log in to Hugging Face NON-INTERACTIVELY using the secret token\n",
        "# This is the correct way to get rid of the pop-up.\n",
        "print(\"üîë Authenticating with Hugging Face using secret token...\")\n",
        "try:\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\"‚úÖ Authentication successful.\")\n",
        "except Exception as e:\n",
        "    print(f\"üö® Authentication failed. Please ensure 'HF_TOKEN' is set correctly in Colab Secrets. Error: {e}\")\n",
        "\n",
        "# 3. Mount your Google Drive\n",
        "print(\"\\nüóÇÔ∏è Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"\\n‚úÖ Environment is fully ready for model loading and synthesis.\")"
      ],
      "metadata": {
        "id": "Zyh8OtAC8r0J"
      },
      "id": "Zyh8OtAC8r0J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéôÔ∏è 5.1.2: Load XTTS Model for Hymn 66 Synthesis\n",
        "\n",
        "Initializes the multilingual XTTS model with PyTorch-safe components and prepares it for GPU-accelerated voice generation."
      ],
      "metadata": {
        "id": "uSLUxjBCv3Ni"
      },
      "id": "uSLUxjBCv3Ni"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.1.2: Load the XTTS Model ---\n",
        "\n",
        "import torch\n",
        "from TTS.api import TTS\n",
        "\n",
        "\n",
        "# We import ALL FOUR required classes that PyTorch needs to approve.\n",
        "# from TTS.tts.configs.xtts_config import XttsConfig, XttsAudioConfig\n",
        "# from TTS.config.shared_configs import BaseDatasetConfig\n",
        "# from TTS.tts.models.xtts import XttsArgs\n",
        "\n",
        "# Step 1: Set the device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Step 2: Grant permission to PyTorch to load ALL necessary classes\n",
        "# This is the complete \"allowlist\" for PyTorch's security feature.\n",
        "# torch.serialization.add_safe_globals([\n",
        "#     XttsConfig,\n",
        "#     XttsAudioConfig,\n",
        "#     BaseDatasetConfig,\n",
        "#     XttsArgs\n",
        "# ])\n",
        "# print(\"‚úÖ PyTorch security permissions configured.\")\n",
        "\n",
        "# Step 3: Define the XTTS model path\n",
        "xtts_model_id = \"tts_models/multilingual/multi-dataset/xtts_v2\"\n",
        "print(f\"\\nLoading model: {xtts_model_id}...\")\n",
        "print(\"This will use the downloaded model weights...\")\n",
        "\n",
        "# Step 4: Load the TTS model into memory and move it to the GPU\n",
        "try:\n",
        "    tts_model = TTS(xtts_model_id).to(device)\n",
        "    print(\"\\n‚úÖ XTTS model loaded successfully and moved to GPU.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå An error occurred while loading the model: {e}\")\n",
        "    tts_model = None"
      ],
      "metadata": {
        "id": "CZfTCPdBxWTv"
      },
      "id": "CZfTCPdBxWTv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéôÔ∏è 5.1.3: Generate and Play Hymn 66 ‚Äì Intro + First Stanza\n",
        "\n",
        "Synthesizes a natural-sounding English voiceover of Hymn 66 using XTTS, combining the title, author, and first stanza into a single continuous narration."
      ],
      "metadata": {
        "id": "PrsLup_pNd2v"
      },
      "id": "PrsLup_pNd2v"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.1.3: Generate and Play the Final Audio ---\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "import os\n",
        "\n",
        "# --- Step 1: Define Inputs with More Natural Phrasing ---\n",
        "reference_voice_path = \"/content/drive/MyDrive/Colab_Notebooks/How_shall_I1.m4a\"\n",
        "output_audio_path = \"/content/hymn_66_english_tts.wav\"\n",
        "\n",
        "hymn_title = \"O Lord, How Shall I Meet You\"\n",
        "hymn_author = \"Paul Gerhardt\"\n",
        "stanza_1_text = \"O Lord, how shall I meet You, How welcome You aright? Your people long to greet You, My hope, my heart's delight! O kindle, Lord most holy, Your lamp within my breast, To do in spirit lowly All that may please You best.\"\n",
        "\n",
        "# THIS IS THE KEY CHANGE: We rephrase the text to be one continuous sentence.\n",
        "full_text_to_speak = f\"Hymn 66, titled {hymn_title}, by {hymn_author}. Now reading the first stanza: {stanza_1_text}\"\n",
        "\n",
        "# --- Step 2: Synthesize the Speech ---\n",
        "if 'tts_model' in locals() and tts_model is not None:\n",
        "    print(f\"üé§ Using reference voice: {reference_voice_path}\")\n",
        "    print(f\"üìÑ Text to be synthesized: '{full_text_to_speak}'\")\n",
        "    print(\"\\nüöÄ Generating speech... (This can take a moment)\")\n",
        "\n",
        "    try:\n",
        "        # Generate the speech using the corrected text\n",
        "        tts_model.tts_to_file(\n",
        "            text=full_text_to_speak,\n",
        "            speaker_wav=reference_voice_path,\n",
        "            file_path=output_audio_path,\n",
        "            language=\"en\"\n",
        "        )\n",
        "        print(f\"‚úÖ Successfully synthesized audio to '{output_audio_path}'.\")\n",
        "\n",
        "        # --- Step 3: Play the Generated Audio ---\n",
        "        print(\"\\n--- üîä Playing Generated Audio ---\")\n",
        "        display(Audio(output_audio_path, autoplay=False))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå An error occurred during speech synthesis: {e}\")\n",
        "else:\n",
        "    print(\"‚ùå TTS model object not found. Please ensure the model loading cell ran successfully.\")"
      ],
      "metadata": {
        "id": "ELOCVAHiRZ5D"
      },
      "id": "ELOCVAHiRZ5D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéº 5.1.4: Generate All Stanzas of Hymn 66 with XTTS\n",
        "\n",
        "Synthesizes each stanza of Hymn 66 separately using the same reference voice, enabling clean playback and structured evaluation of vocal continuity."
      ],
      "metadata": {
        "id": "AvE_C6MLOFZD"
      },
      "id": "AvE_C6MLOFZD"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.1.4: Generate Full Hymn (Stanza-by-Stanza) ---\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "import os\n",
        "\n",
        "# --- Step 1: Define All Stanzas ---\n",
        "reference_voice_path = \"/content/drive/MyDrive/Colab_Notebooks/How_shall_I1.m4a\"\n",
        "hymn_stanzas = [\n",
        "    \"O Lord, how shall I meet You, How welcome You aright? Your people long to greet You, My hope, my heart's delight! O kindle, Lord most holy, Your lamp within my breast, To do in spirit lowly All that may please You best.\",\n",
        "    \"Your Zion strews with palms The way before You paved, And sings her joyous psalms, From sin and death now saved. My heart shall be Your temple, Where You may find Your rest, And from the world's contagion Shall keep my spirit blessed.\",\n",
        "    \"I was a slave, corrupted, And nothing good could do. What did You see that prompted So great a love in You? That I might be translated And in your kingdom shine, You left Your throne and stated That You would make me Yours.\",\n",
        "    \"He comes to judge the nations, A terror to His foes, A light of revelations To hearts oppressed by woes. Come, O my Savior, Jesus, Our joy and peace restore, And make us Yours forever, Both now and evermore.\"\n",
        "]\n",
        "\n",
        "# --- Step 2: Loop and Synthesize Each Stanza ---\n",
        "if 'tts_model' in locals() and tts_model is not None:\n",
        "    print(f\"üé§ Using reference voice: {reference_voice_path}\")\n",
        "    print(f\"‚úÖ Preparing to generate {len(hymn_stanzas)} stanzas...\")\n",
        "\n",
        "    generated_files = []\n",
        "    for i, stanza_text in enumerate(hymn_stanzas):\n",
        "        stanza_num = i + 1\n",
        "        output_audio_path = f\"/content/hymn_66_stanza_{stanza_num}.wav\"\n",
        "        print(f\"\\nüöÄ Generating speech for Stanza {stanza_num}...\")\n",
        "\n",
        "        try:\n",
        "            tts_model.tts_to_file(\n",
        "                text=stanza_text,\n",
        "                speaker_wav=reference_voice_path,\n",
        "                file_path=output_audio_path,\n",
        "                language=\"en\"\n",
        "            )\n",
        "            print(f\"  -> ‚úÖ Successfully synthesized audio to '{output_audio_path}'.\")\n",
        "            generated_files.append(output_audio_path)\n",
        "        except Exception as e:\n",
        "            print(f\"  -> ‚ùå An error occurred for Stanza {stanza_num}: {e}\")\n",
        "\n",
        "    # --- Step 3: Display All Generated Audio Files ---\n",
        "    if generated_files:\n",
        "        print(\"\\n\\n--- üîä Final Audio Output ---\")\n",
        "        for file_path in generated_files:\n",
        "            stanza_num = file_path.split('_')[-1].split('.')[0]\n",
        "            print(f\"\\nStanza {stanza_num}:\")\n",
        "            display(Audio(file_path, autoplay=False))\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå TTS model object not found. Please ensure the model loading cell ran successfully.\")"
      ],
      "metadata": {
        "id": "oxMAkq2B4osN"
      },
      "id": "oxMAkq2B4osN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üßµ 5.1.5a: Stitch Hymn 66 into a Single Audio File\n",
        "\n",
        "Combines all previously generated English stanzas into one seamless hymn file with soft pauses between sections."
      ],
      "metadata": {
        "id": "BJHKTIyOOUI4"
      },
      "id": "BJHKTIyOOUI4"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.1.5a: Merge the Stanzas into a Single Hymn Audio ---\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Load each stanza\n",
        "s1 = AudioSegment.from_wav(\"/content/hymn_66_stanza_1.wav\")\n",
        "s2 = AudioSegment.from_wav(\"/content/hymn_66_stanza_2.wav\")\n",
        "s3 = AudioSegment.from_wav(\"/content/hymn_66_stanza_3.wav\")\n",
        "s4 = AudioSegment.from_wav(\"/content/hymn_66_stanza_4.wav\")\n",
        "\n",
        "# Optional: add 1-second pause between stanzas\n",
        "pause = AudioSegment.silent(duration=1000)\n",
        "\n",
        "# Concatenate all\n",
        "final_hymn = s1 + pause + s2 + pause + s3 + pause + s4\n",
        "\n",
        "# Export to a final file\n",
        "final_hymn.export(\"/content/hymn_66_full_audio.wav\", format=\"wav\")\n",
        "\n",
        "print(\"‚úÖ Final hymn audio saved as 'hymn_66_full_audio.wav'\")\n"
      ],
      "metadata": {
        "id": "4ltkkGstVSgR"
      },
      "id": "4ltkkGstVSgR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîä 5.1.5b: Preview Final Hymn Audio (English)\n",
        "\n",
        "Plays the fully stitched English hymn (Hymn 66) directly in the notebook for final review and quality check."
      ],
      "metadata": {
        "id": "Xj_YvfdmOf_T"
      },
      "id": "Xj_YvfdmOf_T"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- üîä 5.1.5b: Preview the Combined Audio in Colab ---\n",
        "from IPython.display import Audio\n",
        "Audio(\"/content/hymn_66_full_audio.wav\")"
      ],
      "metadata": {
        "id": "yIcZ2bjCVaSS"
      },
      "id": "yIcZ2bjCVaSS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üóÇÔ∏è 5.1.6: Create Structured JSON for Shona Hymn Generation\n",
        "\n",
        "Rebuilds the stanza structure of Hymn 66 in Shona from markdown into a JSON format, preparing it for structured synthesis."
      ],
      "metadata": {
        "id": "ybPexxfYv233"
      },
      "id": "ybPexxfYv233"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- # --- 5.1.6: Recreate 'hymn_66_structured.json' from Markdown output ---\n",
        "\n",
        "import json\n",
        "\n",
        "hymn_data = {\n",
        "    \"hymn_number\": \"66\",\n",
        "    \"title\": \"Ndichamugamuchira\",\n",
        "    \"stanzas\": [\n",
        "        {\n",
        "            \"stanza_number\": 1,\n",
        "            \"text\": \"Ndichamugamuchira\\nNokuchingura nei?\\nNdichamunamati-ra\\nNokubatira sei?\\n\\nSHE, mundiudze kwazvo,\\nMuchanakirwa nei?\\nZvomunotenda nazvo,\\nNdingamufadza sei?\",\n",
        "            \"tags\": [\"Worship\", \"Gratitude\", \"Questioning\", \"Seeking\", \"Devotion\"]\n",
        "        },\n",
        "        {\n",
        "            \"stanza_number\": 2,\n",
        "            \"text\": \"VeZion vakawadza\\nMashizha kareko;\\nNeni handingaregi\\nKumuchingurawo;\\nNomwoyo wangu wose\\nNdichamuimbirai,\\nNdinoda kumukudza,\\nNokumurumbidzai!\",\n",
        "            \"tags\": [\"Praise\", \"Joy\", \"Devotion\", \"Zion\", \"Worship\"]\n",
        "        },\n",
        "        {\n",
        "            \"stanza_number\": 3,\n",
        "            \"text\": \"Ndakanga ndakasungwa,\\nMadzikunure'ni:\\nNdakanga ndakanyadzwa,\\nNdamutswa, SHE, nemi;\\nMandivigire fuma\\nYabva kudenga'ko;\\nNdiyo yokusaora,\\nNokusaperawo.\",\n",
        "            \"tags\": [\"Redemption\", \"Gratitude\", \"Hope\", \"Spiritual Liberation\", \"Divine Grace\"]\n",
        "        },\n",
        "        {\n",
        "            \"stanza_number\": 4,\n",
        "            \"text\": \"SHE JESU uchauya\\nKuzotongesazve;\\nBva avo vakatenda\\nHavangazomutyi;\\nUya-i Tenzi Jesu!\\nKudenga tiisei,\\nKwatichafara isu,\\nTichinakirwa sei!\",\n",
        "            \"tags\": [\"Second Coming\", \"Joyful Anticipation\", \"Heaven\", \"Hope\", \"Salvation\"]\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Save to JSON\n",
        "with open(\"hymn_66_structured.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(hymn_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(\"‚úÖ hymn_66_structured.json recreated and saved.\")\n"
      ],
      "metadata": {
        "id": "OovmliuFZAVd"
      },
      "id": "OovmliuFZAVd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üó£Ô∏è 5.1.7: Synthesize Shona Stanzas from JSON Using XTTS\n",
        "\n",
        "Uses the structured JSON and a Shona voice sample to synthesize all stanzas of Hymn 66 in ChiShona, with XTTS forced to run in English mode."
      ],
      "metadata": {
        "id": "oVElPDjDOzkp"
      },
      "id": "oVElPDjDOzkp"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.1.7: Generate Shona Hymn Stanzas from Structured JSON (Corrected Workaround) ---\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "import json\n",
        "import os\n",
        "\n",
        "# --- Step 1: Define Input JSON and Reference Voice ---\n",
        "json_file_path = \"hymn_66_structured.json\"\n",
        "reference_voice_path = \"/content/drive/MyDrive/Colab_Notebooks/Ndichamugamuchira_1.m4a\"\n",
        "# THE WORKAROUND: Use \"en\" as the language code to force synthesis\n",
        "language_code = \"en\"\n",
        "\n",
        "# --- Step 2: Load Shona Stanzas from JSON ---\n",
        "try:\n",
        "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
        "        hymn_data = json.load(f)\n",
        "    stanzas = hymn_data.get(\"stanzas\", [])\n",
        "    print(f\"‚úÖ Loaded {len(stanzas)} stanzas from '{json_file_path}'.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to load stanzas: {e}\")\n",
        "    stanzas = []\n",
        "\n",
        "# --- Step 3: Loop and Synthesize Each Shona Stanza ---\n",
        "generated_files = []\n",
        "if 'tts_model' in locals() and tts_model is not None and stanzas:\n",
        "    for stanza in stanzas:\n",
        "        i = stanza.get(\"stanza_number\", \"X\")\n",
        "        stanza_text = stanza.get(\"text\", \"\").replace('\\\\n', '\\n')\n",
        "        output_audio_path = f\"/content/hymn_66_shona_stanza_{i}.wav\"\n",
        "        print(f\"üé§ Using Shona reference voice: {reference_voice_path}\")\n",
        "        print(f\"\\nüöÄ Generating Shona stanza {i}...\")\n",
        "\n",
        "        try:\n",
        "            tts_model.tts_to_file(\n",
        "                text=stanza_text,\n",
        "                speaker_wav=reference_voice_path,\n",
        "                file_path=output_audio_path,\n",
        "                language=language_code\n",
        "            )\n",
        "            print(f\"   -> ‚úÖ Output saved to {output_audio_path}\")\n",
        "            generated_files.append(output_audio_path)\n",
        "        except Exception as e:\n",
        "            print(f\"   -> ‚ùå Error on stanza {i}: {e}\")\n",
        "\n",
        "    # --- Step 4: Playback ---\n",
        "    print(\"\\nüîä Shona Audio Output:\")\n",
        "    for path in generated_files:\n",
        "        display(Audio(path, autoplay=False))\n",
        "else:\n",
        "    print(\"‚ùå TTS model or stanzas missing. Please check previous cells.\")"
      ],
      "metadata": {
        "id": "shrLI0ARZFGB"
      },
      "id": "shrLI0ARZFGB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üßµ 5.1.8: Combine All Shona Stanzas into a Final Hymn\n",
        "\n",
        "Merges all generated Shona stanzas into one final hymn audio file, inserting 1-second pauses between each section."
      ],
      "metadata": {
        "id": "30nr4b9pO9BD"
      },
      "id": "30nr4b9pO9BD"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.1.8: Merge Shona Stanzas into a Single Hymn Audio ---\n",
        "\n",
        "from pydub import AudioSegment\n",
        "from IPython.display import Audio, display\n",
        "import os\n",
        "\n",
        "print(\"üîä Merging generated Shona stanzas into a single audio file...\")\n",
        "\n",
        "# Define the paths to the generated stanza files\n",
        "shona_files = [\n",
        "    \"/content/hymn_66_shona_stanza_1.wav\",\n",
        "    \"/content/hymn_66_shona_stanza_2.wav\",\n",
        "    \"/content/hymn_66_shona_stanza_3.wav\",\n",
        "    \"/content/hymn_66_shona_stanza_4.wav\"\n",
        "]\n",
        "\n",
        "# Check which files actually exist to avoid errors\n",
        "existing_files = [f for f in shona_files if os.path.exists(f)]\n",
        "\n",
        "if not existing_files:\n",
        "    print(\"‚ùå No Shona stanza audio files found to merge. Please run the previous cell (5.1.7) first.\")\n",
        "else:\n",
        "    print(f\"Found {len(existing_files)} audio files to merge.\")\n",
        "\n",
        "    # Load the first stanza to start the combined audio\n",
        "    final_shona_hymn = AudioSegment.from_wav(existing_files[0])\n",
        "\n",
        "    # Define a 1-second pause\n",
        "    pause = AudioSegment.silent(duration=1000)\n",
        "\n",
        "    # Loop through the rest of the files, adding a pause and the next stanza\n",
        "    for i in range(1, len(existing_files)):\n",
        "        stanza_audio = AudioSegment.from_wav(existing_files[i])\n",
        "        final_shona_hymn += pause + stanza_audio\n",
        "\n",
        "    # Export the final combined audio file\n",
        "    final_output_path = \"/content/hymn_66_shona_full_audio.wav\"\n",
        "    final_shona_hymn.export(final_output_path, format=\"wav\")\n",
        "    print(f\"‚úÖ Final Shona hymn audio saved as '{final_output_path}'\")\n",
        "\n",
        "    # Play the final merged audio in the notebook\n",
        "    print(\"\\n--- üîä Playing Final Combined Shona Hymn ---\")\n",
        "    display(Audio(final_output_path, autoplay=False))"
      ],
      "metadata": {
        "id": "qd0HfW8xM00h"
      },
      "id": "qd0HfW8xM00h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion: Coqui XTTS (The Reliable Baseline)\n",
        "- **Introduction:** `Coqui XTTS` is a well-supported, open-source model using a speaker-encoding architecture. As you noted, after initial setup hurdles, the final installation process was very straightforward.\n",
        "\n",
        "- **Successes:**\n",
        "  - **Stability:** The model was extremely stable. It generated all four English stanzas cleanly, in full, with no gaps or abrupt endings.\n",
        "  - Audio Quality: The output was consistently \"crisp\" and technically clean.    \n",
        "  - **Shona Performance:** It did a \"fairly good job\" with the Shona hymn, attempting to read all the words and completing the full text, albeit with some stutters.\n",
        "\n",
        "- **Failures:**\n",
        "  - **Voice Cloning:** This was its biggest weakness. You correctly observed that the cloned voice was \"not close to my voice,\" instead producing a generic, though eloquent, speaker. It failed to capture the unique characteristics of the reference audio.\n",
        "\n",
        "- **Final Note:** `Coqui XTTS` proved to be a reliable, easy-to-use baseline. It excels at producing clean speech but is not a top performer for high-fidelity voice cloning."
      ],
      "metadata": {
        "id": "ciiawexGgbQQ"
      },
      "id": "ciiawexGgbQQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## üéôÔ∏è 5.2: Case Study ‚Äì Open-Source Model (Sesame/CSM + LLaMA-3)\n",
        "\n",
        "###üß† **Foundational Understanding & Experimental Design**\n",
        "This case study investigates **Sesame**, an emerging open-source TTS framework implemented here as a **Composable Speech Model (CSM)**. The \"composable\" nature of this **1-billion-parameter model** is its key innovation: it is built by combining distinct, specialized components.\n",
        ">\n",
        "Specifically, it integrates **Meta‚Äôs LLaMA-3** as its primary **text encoder and prosody generator**. Unlike traditional TTS models that rely solely on phoneme-level conditioning, the CSM offloads the linguistic understanding to a powerful, general-purpose Large Language Model (LLM), with the final speech synthesis handled by a dedicated neural vocoder.\n",
        ">\n",
        "This hybrid architecture enables highly expressive, **context-aware voice synthesis**, leveraging the LLM‚Äôs ability to understand rhythm, tone, and semantic nuance. By decoupling language modeling from waveform generation, the Sesame/CSM framework sets itself apart from monolithic architectures and commercial black-box solutions.\n",
        ">\n",
        "Initially, this project had considered HeyGen‚Äôs commercial deployment of Sesame. However, the focus has since shifted to this **open-source CSM implementation**, in order to:\n",
        "\n",
        "- Study the internal workings and training flow,\n",
        "\n",
        "- Explore voice adaptation using custom audio samples, and\n",
        "\n",
        "- Evaluate potential paths for low-resource language fine-tuning (e.g., Shona).\n",
        "\n",
        "This case study benchmarks the CSM's ability to synthesize high-fidelity spoken-word audio‚Äîspecifically, **reading structured hymn text**‚Äîand serves as a comparative lens on hybrid LLM-powered TTS architectures versus traditional pipelines.\n",
        "\n",
        ">Note: Earlier drafts of this phase assumed Sesame could only be accessed via HeyGen‚Äôs API. However, deeper research revealed this community-supported, open-source Composable Speech Model, which this study adopts in order to gain greater control, transparency, and potential for customization.\n",
        "---"
      ],
      "metadata": {
        "id": "9f1Mw4CggkWr"
      },
      "id": "9f1Mw4CggkWr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2.1: üõ†Ô∏è Environment Setup and Baseline Verification ‚Äì Sesame + LLaMA-3\n",
        "\n",
        "> **Section Preamble:** This section documents the end-to-end process of configuring a functional environment for the `Sesame` text-to-speech model. The chosen platform was **Google Colab**, leveraging its GPU offerings from the standard **L4** to the premium **A100** to accommodate the varying memory requirements of the models tested. A significant portion of this phase involved troubleshooting access to the project's core components, which are hosted in two distinct, **gated Hugging Face repositories**: the primary `sesame/csm-1b` model and the foundational `meta-llama/Llama-3.2-1B` tokenizer.\n",
        ">\n",
        "> The setup included obtaining necessary permissions, managing authentication tokens via Colab's secret manager, and resolving dependency requirements. This section concludes with a successful baseline inference test, which validates the operational status of the entire toolchain.\n",
        "\n",
        "The process concluded with the successful execution of the `run_csm.py` script. Despite the script overriding custom input text with its internal default, it successfully generated the audio file `full_conversation.wav`, confirming that the environment and all model components are working correctly."
      ],
      "metadata": {
        "id": "_60QWwVh0JU9"
      },
      "id": "_60QWwVh0JU9"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.2.1: Setup and Authentication (Official Sesame/CSM Repo) ---\n",
        "\n",
        "# 1. Clean Slate and Setup\n",
        "print(\"Setting up the environment from the OFFICIAL Sesame/CSM repository...\")\n",
        "# Remove any old directories to ensure a fresh start\n",
        "!rm -rf /content/sesame*\n",
        "!rm -rf /content/csm*\n",
        "!rm -rf /content/main.zip\n",
        "\n",
        "# THIS IS THE KEY CHANGE: Clone the official repository\n",
        "!git clone https://github.com/SesameAILabs/csm.git\n",
        "%cd csm\n",
        "\n",
        "# 2. Install Dependencies from the official repository\n",
        "print(\"\\nInstalling dependencies from the official repository...\")\n",
        "# The official repo uses a setup file, which is a more robust method\n",
        "!pip install -q -e .\n",
        "\n",
        "# 3. Authenticate with Hugging Face using Colab Secrets\n",
        "print(\"\\nüîë Authenticating with Hugging Face using secret token...\")\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "try:\n",
        "    HF_TOKEN = userdata.get(\"HF_TOKEN\")\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\"‚úÖ Authentication successful. Environment is ready.\")\n",
        "except Exception as e:\n",
        "    print(f\"üö® Authentication failed. Please ensure 'HF_TOKEN' is set correctly in Colab Secrets. Error: {e}\")"
      ],
      "metadata": {
        "id": "XBI81GXhEmQ1"
      },
      "id": "XBI81GXhEmQ1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéß 5.2.2: Normalize Reference Voice for CSM Input\n",
        "\n",
        "Mounts Google Drive and prepares a clean mono 24kHz waveform from a reference audio sample."
      ],
      "metadata": {
        "id": "9pzlcVibtoAt"
      },
      "id": "9pzlcVibtoAt"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.2.2: Mount Drive & Prepare Audio ---\n",
        "from google.colab import drive\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "import os\n",
        "\n",
        "# --- 1. Mount Google Drive ---\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# --- 2. Define File Paths ---\n",
        "# Input file from your Google Drive\n",
        "reference_voice_path = \"/content/drive/MyDrive/Colab_Notebooks/How_shall_I1.m4a\"\n",
        "# Output file to be saved locally in the Colab environment for easy access\n",
        "normalized_path = \"normalized_voice.wav\"\n",
        "\n",
        "# --- 3. Load, Normalize, Resample, and Save ---\n",
        "try:\n",
        "    print(f\"Loading audio from: {reference_voice_path}\")\n",
        "    waveform, sample_rate = torchaudio.load(reference_voice_path)\n",
        "\n",
        "    # Step 1: Convert to mono\n",
        "    print(\"Converting to mono...\")\n",
        "    if waveform.shape[0] > 1:\n",
        "        waveform = waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "    # Step 2: Normalize volume\n",
        "    print(\"Normalizing waveform...\")\n",
        "    max_val = waveform.abs().max()\n",
        "    if max_val > 0:\n",
        "        waveform = waveform / max_val\n",
        "\n",
        "    # Step 3: Resample to 24kHz\n",
        "    print(\"Resampling to 24kHz...\")\n",
        "    if sample_rate != 24000:\n",
        "        resampler = T.Resample(orig_freq=sample_rate, new_freq=24000)\n",
        "        waveform = resampler(waveform)\n",
        "\n",
        "    # Step 4: Save to 'normalized_voice.wav'\n",
        "    print(f\"Saving normalized file to: {normalized_path}\")\n",
        "    torchaudio.save(normalized_path, waveform, 24000)\n",
        "\n",
        "    print(\"\\n‚úÖ Audio preparation complete.\")\n",
        "    print(f\"File '{normalized_path}' is ready to be used.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå An error occurred: {e}\")\n",
        "    print(\"Please ensure the file path is correct.\")"
      ],
      "metadata": {
        "id": "RO-VoPs6LrRf"
      },
      "id": "RO-VoPs6LrRf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß™ 5.2.3: Baseline Stanza Generation Using CSM (Sesame)\n",
        "\n",
        "Extracts a 10-second prompt from the reference voice, then uses Sesame‚Äôs CSM engine to synthesize a test English stanza with in-context conditioning."
      ],
      "metadata": {
        "id": "SltBvSkrEcfK"
      },
      "id": "SltBvSkrEcfK"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.2.3: Baseline Generation - Single English Stanza ---\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "from generator import Segment, load_csm_1b\n",
        "from IPython.display import Audio, display\n",
        "from google.colab import drive\n",
        "import torch # Import torch here\n",
        "\n",
        "# --- 1. Mount Drive and Create a SHORTER Voice Prompt ---\n",
        "print(\"üîä Preparing a shorter 10-second voice prompt...\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "reference_voice_path = \"/content/drive/MyDrive/Colab_Notebooks/How_shall_I1.m4a\"\n",
        "short_prompt_path = \"short_prompt_10s.wav\"\n",
        "\n",
        "# Load the original audio\n",
        "waveform, sample_rate = torchaudio.load(reference_voice_path)\n",
        "\n",
        "# Truncate to the first 10 seconds\n",
        "ten_seconds_in_samples = sample_rate * 10\n",
        "truncated_waveform = waveform[:, :ten_seconds_in_samples]\n",
        "\n",
        "# Convert to mono and resample to 24kHz\n",
        "mono_waveform = truncated_waveform.mean(dim=0, keepdim=True)\n",
        "resampler = T.Resample(orig_freq=sample_rate, new_freq=24000)\n",
        "resampled_waveform = resampler(mono_waveform)\n",
        "torchaudio.save(short_prompt_path, resampled_waveform, 24000)\n",
        "print(f\"‚úÖ Short 10-second prompt saved to: {short_prompt_path}\")\n",
        "\n",
        "# --- 2. Load Generator and Prepare Segment ---\n",
        "print(\"\\nüß† Loading the CSM model...\")\n",
        "generator = load_csm_1b(device=\"cuda\")\n",
        "\n",
        "prompt_audio, _ = torchaudio.load(short_prompt_path)\n",
        "segment = Segment(\n",
        "    speaker=0,\n",
        "    text=\"O Lord, how shall I meet You, How welcome You aright?\", # in-context text\n",
        "    audio=prompt_audio.squeeze(0)\n",
        ")\n",
        "\n",
        "# --- 3. Define the Hymn Stanza ---\n",
        "stanza = (\n",
        "    \"O Lord, how shall I meet You, How welcome You aright? \"\n",
        "    \"Your people long to greet You, My hope, my heart's delight\"\n",
        "    \"O kindle, Lord most holy, Your lamp within my breast,\"\n",
        "    \"To do in spirit lowly All that may please You best.\"\n",
        ")\n",
        "\n",
        "print(\"\\nüéôÔ∏è Generating a stanza...\")\n",
        "output = generator.generate(\n",
        "    text=stanza,\n",
        "    speaker=0,\n",
        "    context=[segment]\n",
        ")\n",
        "\n",
        "# --- 4. Normalize + Boost Volume ---\n",
        "print(\"\\nüîä Normalizing and boosting volume...\")\n",
        "output_tensor = output / torch.abs(output).max()       # Normalize\n",
        "gain_factor = 1.3\n",
        "boosted_output = output_tensor * gain_factor           # Boost volume\n",
        "boosted_output = boosted_output.clamp(-1.0, 1.0)       # Prevent distortion\n",
        "\n",
        "# --- 5. Save and Play ---\n",
        "output_path = \"stanza_output_boosted.wav\"\n",
        "torchaudio.save(output_path, boosted_output.unsqueeze(0).cpu(), 24000)\n",
        "print(f\"‚úÖ Test complete. Saved to: {output_path}\")\n",
        "\n",
        "print(\"\\n--- üîä Playing Boosted Test Audio ---\")\n",
        "display(Audio(output_path))"
      ],
      "metadata": {
        "id": "q9ruKPZlQvGk"
      },
      "id": "q9ruKPZlQvGk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üßµ 5.2.4: Final English Hymn Generation & Stitching with CSM\n",
        "\n",
        "Generates all English stanzas using Sesame‚Äôs CSM engine, then stitches them with silence to produce a complete, normalized hymn."
      ],
      "metadata": {
        "id": "rqSpUXv6E6D6"
      },
      "id": "rqSpUXv6E6D6"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.2.4: Final English Hymn Generation with Context Chaining ---\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "from generator import Segment, load_csm_1b\n",
        "from IPython.display import Audio, display\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# --- 1. Setup ---\n",
        "print(\"üîä Loading the prepared 10-second voice prompt...\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "# This is the initial \"seed\" prompt that starts the chain.\n",
        "initial_prompt_path = \"short_prompt_10s.wav\"\n",
        "# The text that corresponds to the initial prompt audio.\n",
        "initial_prompt_text = \"O Lord, how shall I meet You, How welcome You aright?\"\n",
        "\n",
        "# --- 2. Load Generator ---\n",
        "print(\"\\nüß† Loading the CSM model...\")\n",
        "generator = load_csm_1b(device=\"cuda\")\n",
        "\n",
        "# --- 3. Warm-up Generation ---\n",
        "# We do a quick warm-up using the initial prompt to stabilize the model.\n",
        "print(\"\\nüî• Performing a warm-up generation...\")\n",
        "initial_audio, _ = torchaudio.load(initial_prompt_path)\n",
        "initial_segment = Segment(\n",
        "    speaker=0,\n",
        "    text=initial_prompt_text,\n",
        "    audio=initial_audio.squeeze(0)\n",
        ")\n",
        "_ = generator.generate(text=\"Warming up.\", speaker=0, context=[initial_segment])\n",
        "print(\"‚úÖ Model is warm.\")\n",
        "\n",
        "# --- 4. Define Stanzas and Generate with Context Chaining ---\n",
        "stanzas = [\n",
        "    \"O Lord, how shall I meet You, How welcome You aright? Your people long to greet You, My hope, my heart's delight! O kindle, Lord most holy, Your lamp within my breast, To do in spirit lowly All that may please You best.\",\n",
        "    \"Your Zion strews with palms The way before You paved, And sings her joyous psalms, From sin and death now saved. My heart shall be Your temple, Where You may find Your rest, And from the world's contagion Shall keep my spirit blessed.\",\n",
        "    \"I was a slave, corrupted, And nothing good could do. What did You see that prompted So great a love in You? That I might be translated And in your kingdom shine, You left Your throne and stated That You would make me Yours.\",\n",
        "    \"He comes to judge the nations, A terror to His foes, A light of revelations To hearts oppressed by woes. Come, O my Savior, Jesus, Our joy and peace restore, And make us Yours forever, Both now and evermore.\"\n",
        "]\n",
        "all_speech_parts = []\n",
        "silence = np.zeros(int(1.5 * 24000)) # 1.5-second silence\n",
        "\n",
        "print(\"\\nüéôÔ∏è Generating hymn recitation with context chaining...\")\n",
        "\n",
        "# Initialize the context with our starting prompt\n",
        "current_prompt_path = initial_prompt_path\n",
        "current_prompt_text = initial_prompt_text\n",
        "\n",
        "for i, next_stanza_text in enumerate(stanzas):\n",
        "    print(f\"Generating stanza {i+1}/{len(stanzas)}...\")\n",
        "\n",
        "    # Load the audio for the CURRENT prompt\n",
        "    current_audio, _ = torchaudio.load(current_prompt_path)\n",
        "\n",
        "    # Create the segment using the CURRENT prompt's text and audio\n",
        "    segment = Segment(\n",
        "        speaker=0,\n",
        "        text=current_prompt_text,\n",
        "        audio=current_audio.squeeze(0)\n",
        "    )\n",
        "\n",
        "    # Generate the audio for the NEXT stanza\n",
        "    output = generator.generate(text=next_stanza_text, speaker=0, context=[segment])\n",
        "\n",
        "    all_speech_parts.append(output.cpu().numpy().squeeze())\n",
        "    if i < len(stanzas) - 1:\n",
        "        all_speech_parts.append(silence)\n",
        "\n",
        "    # --- THIS IS THE KEY: UPDATE THE CONTEXT FOR THE NEXT LOOP ---\n",
        "    # Save the generated audio to a temporary file\n",
        "    temp_output_path = f\"temp_stanza_{i+1}.wav\"\n",
        "    torchaudio.save(temp_output_path, output.unsqueeze(0).cpu(), 24000)\n",
        "\n",
        "    # The output of this loop becomes the input for the next one\n",
        "    current_prompt_path = temp_output_path\n",
        "    current_prompt_text = next_stanza_text\n",
        "\n",
        "# --- 5. Combine, Save, and Play ---\n",
        "print(\"\\nüîä Combining all parts...\")\n",
        "final_speech = np.concatenate(all_speech_parts)\n",
        "final_speech = final_speech / np.abs(final_speech).max() # Normalize final output\n",
        "\n",
        "output_path = \"/content/drive/MyDrive/Colab_Notebooks/hymn_final_chained.wav\"\n",
        "torchaudio.save(output_path, torch.tensor(final_speech).unsqueeze(0), 24000)\n",
        "print(f\"‚úÖ Full hymn synthesis complete. Audio saved to: {output_path}\")\n",
        "\n",
        "print(\"\\n--- üîä Playing Final Generated Hymn ---\")\n",
        "display(Audio(output_path))"
      ],
      "metadata": {
        "id": "PSiQgq9frHL-"
      },
      "id": "PSiQgq9frHL-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üó£Ô∏è 5.2.5: Shona Voice Orientation with CSM (Karanga Dialect)\n",
        "\n",
        "Generates a short free-form Shona speech sample using Alvin‚Äôs cloned voice, aimed at testing intelligibility and rhythm in Mberengwa Karanga ‚Äî outside typical written corpora or hymn structure."
      ],
      "metadata": {
        "id": "frjUXvtruC_2"
      },
      "id": "frjUXvtruC_2"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.2.5: High-Quality Shona Voice Prompt Generation ---\n",
        "import torch\n",
        "import torchaudio\n",
        "from generator import Segment, load_csm_1b\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "# --- 1. Load Shortened Voice Prompt ---\n",
        "context_audio, sr = torchaudio.load(\"short_prompt_10s.wav\")\n",
        "assert sr == 24000, \"Expected 24kHz sample rate for CSM model.\"\n",
        "\n",
        "# --- 2. Load the Generator ---\n",
        "print(\"üß† Loading the CSM model...\")\n",
        "generator = load_csm_1b(device=\"cuda\")\n",
        "\n",
        "# --- 3. Create Shona Segment ---\n",
        "segment = Segment(\n",
        "    speaker=0,\n",
        "    text=\"Uyu ndiAlvin achirava guyo gunohi 'Ndichamugamuchira'.\",\n",
        "    audio=context_audio.squeeze(0)\n",
        ")\n",
        "\n",
        "# --- 4. Shona Hymn Text (Simple Training Prompt) ---\n",
        "shona_text = (\n",
        "    \"Kwaziwayi, zita rangu ndinohi Alvin. \"\n",
        "    \"Ndiri kuedza muchina uyu kuvona kana uchigona kutaura ChiShona zvakanaka.\"\n",
        ")\n",
        "# (Translation: \"Hello, my name is Alvin. I am testing this machine to see if it can speak Shona well.\")\n",
        "\n",
        "# --- 5. Generate Speech ---\n",
        "print(\"üéôÔ∏è Generating Shona voice output...\")\n",
        "output = generator.generate(\n",
        "    text=shona_text,\n",
        "    speaker=0,\n",
        "    context=[segment],\n",
        "    max_audio_length_ms=21000\n",
        ")\n",
        "\n",
        "# --- 6. Normalize + Boost Volume ---\n",
        "print(\"üîä Normalizing and boosting volume...\")\n",
        "output_tensor = output / output.abs().max()\n",
        "gain_factor = 1.3\n",
        "boosted_output = output_tensor * gain_factor\n",
        "boosted_output = boosted_output.clamp(-1.0, 1.0)\n",
        "\n",
        "# --- 7. Save and Play ---\n",
        "output_path = \"alvin_shona_voice.wav\"\n",
        "torchaudio.save(output_path, boosted_output.unsqueeze(0).cpu(), 24000)\n",
        "print(f\"‚úÖ Saved: {output_path}\")\n",
        "\n",
        "print(\"\\n--- üîä Playing Shona Audio ---\")\n",
        "display(Audio(output_path))"
      ],
      "metadata": {
        "id": "OjcCXieJuN7v"
      },
      "id": "OjcCXieJuN7v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéº 5.2.6: Final Shona Hymn Generation with Context Chaining\n",
        "\n",
        "Synthesizes all four stanzas of ‚ÄúNdichamugamuchira‚Äù in Shona using context chaining, where each generated stanza becomes the conditioning prompt for the next ‚Äî preserving speaker identity and rhythm across the full hymn."
      ],
      "metadata": {
        "id": "_9uAvAZAHxMD"
      },
      "id": "_9uAvAZAHxMD"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.2.6: Final Shona Hymn Generation (with Correct Shona Prompt) ---\n",
        "import torch\n",
        "import torchaudio\n",
        "from generator import Segment, load_csm_1b\n",
        "from IPython.display import Audio, display\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# --- 1. Load Initial SHONA Voice Prompt & Model ---\n",
        "# THIS IS THE KEY CHANGE: We use the clean Shona audio from the previous cell as our starting point.\n",
        "initial_prompt_path = \"alvin_shona_voice.wav\"\n",
        "# The text that corresponds to our initial Shona prompt.\n",
        "initial_prompt_text = \"Kwaziwayi, zita rangu ndinohi Alvin. Ndiri kuedza muchina uyu kuvona kana uchigona kutaura ChiShona zvakanaka.\"\n",
        "\n",
        "print(\"üß† Loading CSM model...\")\n",
        "generator = load_csm_1b(device=\"cuda\")\n",
        "\n",
        "# --- 2. Define Full Hymn Text ---\n",
        "shona_stanzas = [\n",
        "    \"Ndichamugamuchira, Nokuchingura nei? Ndichamunamatira, Nokubatira sei? She, mundiudze kwazvo, Muchanakirwa nei? Zvomunotenda nazvo, Ndingamufadza sei?\",\n",
        "    \"VeZion vakawadza Mashizha kareko; Neni handingaregi Kumuchingurawo. Nomwoyo wangu wose Ndichamuimbirai, Ndinoda kumukudza, Nokumurumbidzai!\",\n",
        "    \"Ndakanga ndakasungwa, Madzikunureni. Ndakanga ndakanyadzwa, Ndamutswa, She, nemi. Mandivigire fuma Yabva kudenga ko; Ndiyo yokusaora, nokusaperawo.\",\n",
        "    \"She Jesu uchauya Kuzotongesazve. Bva avo vakatenda Havangazomutyi. Uyai Tenzi Jesu! Kudenga tiisei, Kwatichafara isu, Tichinakirwa sei!\"\n",
        "]\n",
        "\n",
        "# --- 3. Generate with Context Chaining ---\n",
        "print(\"üéôÔ∏è Generating longer Shona output with Context Chaining...\")\n",
        "\n",
        "all_speech_parts = []\n",
        "silence = np.zeros(int(1.0 * 24000)) # 1-second silence\n",
        "\n",
        "# Initialize the context with our starting prompt\n",
        "current_prompt_path = initial_prompt_path\n",
        "current_prompt_text = initial_prompt_text\n",
        "\n",
        "for i, next_stanza_text in enumerate(shona_stanzas):\n",
        "    print(f\"Generating stanza {i+1}/{len(shona_stanzas)}...\")\n",
        "\n",
        "    current_audio, _ = torchaudio.load(current_prompt_path)\n",
        "    segment = Segment(\n",
        "        speaker=0,\n",
        "        text=current_prompt_text,\n",
        "        audio=current_audio.squeeze(0)\n",
        "    )\n",
        "\n",
        "    output = generator.generate(\n",
        "        text=next_stanza_text,\n",
        "        speaker=0,\n",
        "        context=[segment],\n",
        "        temperature=0.9\n",
        "    )\n",
        "\n",
        "    all_speech_parts.append(output.cpu().numpy().squeeze())\n",
        "    if i < len(shona_stanzas) - 1:\n",
        "        all_speech_parts.append(silence)\n",
        "\n",
        "    temp_output_path = f\"temp_shona_stanza_{i+1}.wav\"\n",
        "    torchaudio.save(temp_output_path, output.unsqueeze(0).cpu(), 24000)\n",
        "\n",
        "    current_prompt_path = temp_output_path\n",
        "    current_prompt_text = next_stanza_text\n",
        "\n",
        "\n",
        "# --- 4. Combine, Save, and Play ---\n",
        "print(\"\\nüîä Combining all parts...\")\n",
        "final_speech = np.concatenate(all_speech_parts)\n",
        "final_speech = final_speech / np.abs(final_speech).max()\n",
        "\n",
        "output_path = \"alvin_shona_longer_chained.wav\"\n",
        "torchaudio.save(output_path, torch.tensor(final_speech).unsqueeze(0), 24000)\n",
        "print(f\"‚úÖ Saved: {output_path}\")\n",
        "display(Audio(output_path))"
      ],
      "metadata": {
        "id": "YzJQ2Yy1ar4h"
      },
      "id": "YzJQ2Yy1ar4h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion: Sesame/CSM (The High-Performer)\n",
        "- **Introduction:** `Sesame/CSM` is a high-performance generative model using an in-context learning architecture. After initial struggles, we successfully switched to the official repository.\n",
        "\n",
        "- **Successes:**\n",
        "  - **Voice Cloning:** This was the model's greatest strength. The initial single-stanza test produced a good voice clone.\n",
        "  - **English Generation:** Using the \"context chaining\" technique, the model produced a single, combined audio file for the full English hymn that \"flowed smoothly.\"\n",
        "  - **Shona Performance (Initial):** For a short, non-hymn statement, it read the Shona text \"fairly well.\"\n",
        "  \n",
        "- **Failures:** Long-Form Shona: This was its primary weakness. When generating the full Shona hymn, the model's performance degraded over time. It started strong but became \"fast-paced, and the words were fumbled towards the end.\" This indicates that while its voice cloning is strong, its ability to maintain phonetic accuracy in an unfamiliar language over a long duration is limited without fine-tuning.\n",
        "\n",
        "- **Final Note:** `Sesame/CSM` is the best model for high-fidelity voice cloning. Its \"context chaining\" ability is powerful, but it requires a strong underlying familiarity with the target language to maintain quality in long-form generations."
      ],
      "metadata": {
        "id": "j79xmXSB1x6u"
      },
      "id": "j79xmXSB1x6u"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 5.3: Case Study ‚Äì Expressive TTS with Dia\n",
        "\n",
        "### üß† Foundational Understanding & Experimental Design\n",
        "\n",
        "This third and final case study explores **Dia TTS**, a powerful, open-source speech synthesis model from the research group **Nari Labs**. Positioned as a strong competitor to commercial services like ElevenLabs, Dia TTS represents the cutting edge of expressive, conversational AI voice generation.\n",
        "\n",
        "Its architecture is notable for its scale and focus:\n",
        "\n",
        "* **Large Model:** At **1.6 billion parameters**, it is significantly larger than many other open-source TTS models, allowing it to capture more nuanced vocal details.\n",
        "* **Dialogue and Emotion:** The model was specifically designed to generate realistic dialogue, including non-verbal sounds (like laughter or sighs) and to convey emotion based on an audio prompt.\n",
        "* **In-Context Voice Cloning:** Like the Sesame/CSM model, it uses a short audio sample as a prompt to clone a voice and its speaking style on the fly.\n",
        "\n",
        "This case study will evaluate Dia TTS's performance on the same hymn-reading task, providing a final point of comparison against both the baseline Coqui XTTS and the generative Sesame/CSM models. The primary goal is to assess its quality, particularly its ability to handle the phonetic nuances of the Shona language through zero-shot voice cloning.\n",
        "\n",
        "> *Note on Origins:* It is important to distinguish this publicly available model from the **Google DeepMind research paper** of the same name. While Google's paper introduced similar concepts, the model we are testing is the open-source implementation developed and released by Nari Labs.\n",
        "\n",
        "---\n",
        "### ‚öôÔ∏è 5.3.1: Environment Setup for Dia TTS\n",
        "\n",
        "Clones the official Dia TTS repository, installs all required libraries, and authenticates with Hugging Face to prepare for model loading."
      ],
      "metadata": {
        "id": "-va_1nAqYI7s"
      },
      "id": "-va_1nAqYI7s"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.3.1a: Environment Setup for Dia TTS ---\n",
        "print(\"üöÄ Starting Case Study 3: Dia TTS\")\n",
        "\n",
        "# [1/3] Clone Dia repo\n",
        "!rm -rf /content/dia\n",
        "!git clone https://github.com/nari-labs/dia.git\n",
        "%cd dia\n",
        "print(\"‚úÖ Repository cloned successfully.\")\n",
        "\n",
        "# [2/3] Install via setup.py (editable mode)\n",
        "!pip install -q -e .\n",
        "print(\"‚úÖ Dependencies installed.\")\n",
        "\n",
        "# [3/3] Login with Hugging Face token (via secret)\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "try:\n",
        "    HF_TOKEN = userdata.get(\"HF_TOKEN\")\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\"‚úÖ Authentication successful.\")\n",
        "except Exception as e:\n",
        "    print(f\"üö® Authentication failed: {e}\")"
      ],
      "metadata": {
        "id": "63oNAoK0Yc30"
      },
      "id": "63oNAoK0Yc30",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.3.1b: Patch Import for Dia Model ---\n",
        "import sys\n",
        "dia_path = '/content/dia'\n",
        "if dia_path not in sys.path:\n",
        "    sys.path.append(dia_path)\n",
        "\n",
        "# ‚úÖ CORRECT IMPORT from dia.layers (not model.py!)\n",
        "print(\"üîß Attempting to import the Dia model class...\")\n",
        "try:\n",
        "    from dia.layers import DiaModel as Dia\n",
        "    print(\"‚úÖ Successfully imported Dia model class.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Could not import Dia model class. Error: {e}\")\n",
        "    Dia = None"
      ],
      "metadata": {
        "id": "oFd5Kc17CBYC"
      },
      "id": "oFd5Kc17CBYC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéôÔ∏è 5.3.2: Load Dia TTS Model and Generate Baseline Audio"
      ],
      "metadata": {
        "id": "F815j6vC1Zhq"
      },
      "id": "F815j6vC1Zhq"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.3.2: Final Dia TTS Generation with Tuned Parameters ---\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "from IPython.display import Audio, display\n",
        "from google.colab import drive\n",
        "import sys\n",
        "import importlib.util\n",
        "import os\n",
        "\n",
        "# --- Manually load the Dia model class ---\n",
        "print(\"üîß Attempting to manually load the Dia model class...\")\n",
        "try:\n",
        "    dia_model_path = '/content/dia/dia/model.py'\n",
        "    spec = importlib.util.spec_from_file_location(\"dia.model\", dia_model_path)\n",
        "    dia_model_module = importlib.util.module_from_spec(spec)\n",
        "    sys.modules[\"dia.model\"] = dia_model_module\n",
        "    spec.loader.exec_module(dia_model_module)\n",
        "    from dia.model import Dia\n",
        "    print(\"‚úÖ Successfully imported Dia model class.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Could not import Dia model class. Error: {e}\")\n",
        "    Dia = None\n",
        "\n",
        "# --- Mount Google Drive ---\n",
        "print(\"\\nüóÇÔ∏è Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Prepare a 5-second voice prompt at 48kHz ---\n",
        "print(\"\\nüîä Preparing a 5-second voice prompt...\")\n",
        "try:\n",
        "    reference_voice_path = \"/content/drive/MyDrive/Colab_Notebooks/How_shall_I1.m4a\"\n",
        "    prompt_output_path = \"dia_prompt_5s_48khz.wav\"\n",
        "\n",
        "    waveform, sample_rate = torchaudio.load(reference_voice_path)\n",
        "    prompt_duration_seconds = 5\n",
        "    prompt_duration_samples = sample_rate * prompt_duration_seconds\n",
        "    mono_waveform = waveform[:, :prompt_duration_samples].mean(dim=0, keepdim=True)\n",
        "\n",
        "    resampler = T.Resample(orig_freq=sample_rate, new_freq=48000)\n",
        "    resampled_waveform = resampler(mono_waveform)\n",
        "\n",
        "    torchaudio.save(prompt_output_path, resampled_waveform, 48000)\n",
        "    print(f\"‚úÖ 5-second prompt saved to: {prompt_output_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error preparing audio prompt: {e}\")\n",
        "    prompt_output_path = None\n",
        "\n",
        "# --- Load the Dia TTS Model ---\n",
        "if 'dia_model' not in locals() or dia_model is None:\n",
        "    if Dia and prompt_output_path:\n",
        "        model_id = \"nari-labs/Dia-1.6B-0626\"\n",
        "        print(f\"\\nüß† Loading the Dia TTS model: {model_id}...\")\n",
        "        try:\n",
        "            dia_model = Dia.from_pretrained(model_id, device=\"cuda\")\n",
        "            print(\"‚úÖ Dia TTS model loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading Dia TTS model: {e}\")\n",
        "            dia_model = None\n",
        "    else:\n",
        "        dia_model = None\n",
        "\n",
        "# --- Generate a Baseline Stanza with the \"Sweet Spot\" Parameters ---\n",
        "if dia_model:\n",
        "    print(\"\\nüéôÔ∏è Generating a baseline English stanza with tuned parameters...\")\n",
        "    try:\n",
        "        stanza_text = (\n",
        "            \"O Lord, how shall I meet You, How welcome You aright? \"\n",
        "            \"Your people long to greet You, My hope, my heart's delight!\"\n",
        "        )\n",
        "\n",
        "        # THIS IS THE KEY CHANGE: A balanced temperature\n",
        "        output_waveform = dia_model.generate(\n",
        "            text=stanza_text,\n",
        "            audio_prompt=prompt_output_path,\n",
        "            temperature=1.1,   # Creative, but not chaotic\n",
        "            top_p=0.95,\n",
        "            cfg_scale=4.0,\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        output_path = \"dia_final_cloned_output_48khz.wav\"\n",
        "        torchaudio.save(output_path, torch.tensor(output_waveform).unsqueeze(0), 48000)\n",
        "        print(f\"‚úÖ Baseline audio generated and saved to: {output_path}\")\n",
        "\n",
        "        print(\"\\n--- üîä Playing Generated Audio ---\")\n",
        "        display(Audio(output_path))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå An error occurred during speech generation: {e}\")"
      ],
      "metadata": {
        "id": "w1I0quir9IUm"
      },
      "id": "w1I0quir9IUm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéº 5.3.3: Final Hymn Generation with Context Chaining"
      ],
      "metadata": {
        "id": "yhA4d0olkTms"
      },
      "id": "yhA4d0olkTms"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.3.3: Final Hymn Generation (Self-Contained) ---\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "from IPython.display import Audio, display\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# --- Ensure the Dia model class is available ---\n",
        "if 'Dia' not in locals() or 'dia_model' not in locals() or dia_model is None:\n",
        "    print(\"‚ùå Dia model not found. Please run a previous cell successfully first.\")\n",
        "else:\n",
        "    print(\"‚úÖ Dia model found. Proceeding with full hymn generation.\")\n",
        "\n",
        "    # --- Step 1: Prepare a HIGH-QUALITY 5-second voice prompt ---\n",
        "    # This section is now integrated directly into this cell.\n",
        "    print(\"\\nüîä Preparing a high-quality 5-second voice prompt...\")\n",
        "    try:\n",
        "        original_path = \"/content/drive/MyDrive/Colab_Notebooks/How_shall_I1.m4a\"\n",
        "        cleaned_prompt_path = \"dia_cleaned_prompt_5s.wav\"\n",
        "\n",
        "        waveform, sample_rate = torchaudio.load(original_path)\n",
        "\n",
        "        if waveform.shape[0] > 1:\n",
        "            waveform = waveform.mean(dim=0, keepdim=True)\n",
        "        waveform = waveform / waveform.abs().max()\n",
        "\n",
        "        vad = T.Vad(sample_rate=sample_rate)\n",
        "        clean_waveform = vad(waveform)\n",
        "\n",
        "        target_samples = 5 * sample_rate\n",
        "        if clean_waveform.shape[1] > target_samples:\n",
        "            clean_waveform = clean_waveform[:, :target_samples]\n",
        "\n",
        "        resampler = T.Resample(orig_freq=sample_rate, new_freq=48000)\n",
        "        final_waveform = resampler(clean_waveform)\n",
        "\n",
        "        torchaudio.save(cleaned_prompt_path, final_waveform, 48000)\n",
        "        print(f\"‚úÖ High-quality 5-second prompt saved to: {cleaned_prompt_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error preparing audio prompt: {e}\")\n",
        "        cleaned_prompt_path = None\n",
        "\n",
        "    # --- Step 2: Generate and Display Each Stanza Independently ---\n",
        "    if cleaned_prompt_path:\n",
        "        print(\"\\nüéôÔ∏è Generating each stanza with the high-quality prompt...\")\n",
        "\n",
        "        hymn_stanzas = [\n",
        "            \"O Lord, how shall I meet You, How welcome You aright? Your people long to greet You, My hope, my heart's delight!\",\n",
        "            \"O kindle, Lord most holy, Your lamp within my breast, To do in spirit lowly All that may please You best.\",\n",
        "            \"Your Zion strews with palms The way before You paved, And sings her joyous psalms, From sin and death now saved.\",\n",
        "            \"My heart shall be Your temple, Where You may find Your rest, And from the world's contagion Shall keep my spirit blessed.\"\n",
        "        ]\n",
        "\n",
        "        generated_files = []\n",
        "        for i, stanza_text in enumerate(hymn_stanzas):\n",
        "            stanza_num = i + 1\n",
        "            print(f\"\\n   -> Generating stanza {stanza_num}/{len(hymn_stanzas)}...\")\n",
        "\n",
        "            try:\n",
        "                output_waveform = dia_model.generate(\n",
        "                    text=stanza_text,\n",
        "                    audio_prompt=cleaned_prompt_path,\n",
        "                    temperature=1.1,\n",
        "                    top_p=0.95,\n",
        "                    cfg_scale=4.0,\n",
        "                    verbose=False\n",
        "                )\n",
        "\n",
        "                output_path = f\"dia_cloned_voice_stanza_{stanza_num}.wav\"\n",
        "                torchaudio.save(output_path, torch.tensor(output_waveform).unsqueeze(0), 48000)\n",
        "                print(f\"      ... Stanza {stanza_num} complete. Saved to: {output_path}\")\n",
        "                generated_files.append(output_path)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"      ... ‚ùå Error on stanza {stanza_num}: {e}\")\n",
        "                break\n",
        "\n",
        "        # --- Step 3: Display All Generated Audio Files ---\n",
        "        if generated_files:\n",
        "            print(\"\\n\\n--- üîä Final Audio Output (Stanza-by-Stanza) ---\")\n",
        "            for file_path in generated_files:\n",
        "                stanza_num = file_path.split('_')[-1].split('.')[0]\n",
        "                print(f\"\\nStanza {stanza_num}:\")\n",
        "                display(Audio(file_path))\n",
        "\n",
        "        print(\"\\n‚úÖ Full hymn generation process complete.\")"
      ],
      "metadata": {
        "id": "Y37y1qvQkTPS"
      },
      "id": "Y37y1qvQkTPS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.3.4: Comparison - Full Hymn with Default Voice (Stanza-by-Stanza) ---\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "from IPython.display import Audio, display\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# --- Ensure the Dia model class is available ---\n",
        "if 'Dia' not in locals() or 'dia_model' not in locals() or dia_model is None:\n",
        "    print(\"‚ùå Dia model not found. Please run a previous cell successfully first.\")\n",
        "else:\n",
        "    print(\"‚úÖ Dia model found. Proceeding with full hymn generation using the default voice.\")\n",
        "\n",
        "    # --- Step 1: Define the Full Hymn Text ---\n",
        "    hymn_stanzas = [\n",
        "        \"O Lord, how shall I meet You, How welcome You aright? Your people long to greet You, My hope, my heart's delight!\",\n",
        "        \"O kindle, Lord most holy, Your lamp within my breast, To do in spirit lowly All that may please You best.\",\n",
        "        \"Your Zion strews with palms The way before You paved, And sings her joyous psalms, From sin and death now saved.\",\n",
        "        \"My heart shall be Your temple, Where You may find Your rest, And from the world's contagion Shall keep my spirit blessed.\"\n",
        "    ]\n",
        "\n",
        "    # --- Step 2: Generate and Display Each Stanza Independently ---\n",
        "    print(\"\\nüéôÔ∏è Generating each stanza with the model's default voice...\")\n",
        "\n",
        "    generated_files = []\n",
        "    for i, stanza_text in enumerate(hymn_stanzas):\n",
        "        stanza_num = i + 1\n",
        "        print(f\"\\n   -> Generating stanza {stanza_num}/{len(hymn_stanzas)}...\")\n",
        "\n",
        "        try:\n",
        "            # Generate the audio for the current stanza with NO audio prompt\n",
        "            output_waveform = dia_model.generate(\n",
        "                text=stanza_text,\n",
        "                temperature=1.1,\n",
        "                top_p=0.95,\n",
        "                cfg_scale=4.0,\n",
        "                verbose=False\n",
        "            )\n",
        "\n",
        "            output_path = f\"dia_default_voice_stanza_{stanza_num}.wav\"\n",
        "            torchaudio.save(output_path, torch.tensor(output_waveform).unsqueeze(0), 48000)\n",
        "            print(f\"      ... Stanza {stanza_num} complete. Saved to: {output_path}\")\n",
        "            generated_files.append(output_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      ... ‚ùå Error on stanza {stanza_num}: {e}\")\n",
        "            break\n",
        "\n",
        "    # --- Step 3: Display All Generated Audio Files ---\n",
        "    if generated_files:\n",
        "        print(\"\\n\\n--- üîä Final Audio Output (Default Voice, Stanza-by-Stanza) ---\")\n",
        "        for file_path in generated_files:\n",
        "            stanza_num = file_path.split('_')[-1].split('.')[0]\n",
        "            print(f\"\\nStanza {stanza_num}:\")\n",
        "            display(Audio(file_path))\n",
        "\n",
        "    print(\"\\n‚úÖ Full hymn generation process complete.\")"
      ],
      "metadata": {
        "id": "ofQAhs9q7rYd"
      },
      "id": "ofQAhs9q7rYd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.3.5: Final Shona Generation with Dia TTS ---\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "from IPython.display import Audio, display\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# --- Ensure the Dia model and class are available ---\n",
        "if 'Dia' not in locals() or 'dia_model' not in locals() or dia_model is None:\n",
        "    print(\"‚ùå Dia model not found. Please run a previous cell successfully first.\")\n",
        "else:\n",
        "    print(\"‚úÖ Dia model found. Proceeding with Shona generation.\")\n",
        "\n",
        "    # --- Step 1: Prepare a HIGH-QUALITY 5-second SHONA voice prompt ---\n",
        "    print(\"\\nüîä Preparing a high-quality 5-second Shona voice prompt...\")\n",
        "    try:\n",
        "        # Using your Shona audio file as the source\n",
        "        original_path = \"/content/drive/MyDrive/Colab_Notebooks/Ndichamugamuchira_1.m4a\"\n",
        "        cleaned_prompt_path = \"dia_cleaned_shona_prompt_5s.wav\"\n",
        "\n",
        "        print(f\"   - Loading original audio from: {original_path}\")\n",
        "        waveform, sample_rate = torchaudio.load(original_path)\n",
        "\n",
        "        # Run the same audio cleaning pipeline\n",
        "        if waveform.shape[0] > 1:\n",
        "            waveform = waveform.mean(dim=0, keepdim=True)\n",
        "        waveform = waveform / waveform.abs().max()\n",
        "        vad = T.Vad(sample_rate=sample_rate)\n",
        "        clean_waveform = vad(waveform)\n",
        "        target_samples = 5 * sample_rate\n",
        "        if clean_waveform.shape[1] > target_samples:\n",
        "            clean_waveform = clean_waveform[:, :target_samples]\n",
        "        resampler = T.Resample(orig_freq=sample_rate, new_freq=48000)\n",
        "        final_waveform = resampler(clean_waveform)\n",
        "\n",
        "        torchaudio.save(cleaned_prompt_path, final_waveform, 48000)\n",
        "        print(f\"‚úÖ High-quality 5-second Shona prompt saved to: {cleaned_prompt_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error preparing audio prompt: {e}\")\n",
        "        cleaned_prompt_path = None\n",
        "\n",
        "    # --- Step 2: Generate the Shona Hymn Stanza ---\n",
        "    if dia_model and cleaned_prompt_path:\n",
        "        print(\"\\nüéôÔ∏è Generating a baseline Shona stanza with the cloned voice...\")\n",
        "        try:\n",
        "            # The first stanza of the Shona hymn\n",
        "            stanza_text = \"Ndichamugamuchira, Nokuchingura nei? Ndichamunamati-ra, Nokubatira sei? SHE, mundiudze kwazvo, Muchanakirwa nei? Zvomunotenda nazvo, Ndingamufadza sei?\"\n",
        "\n",
        "            # Using the stable parameters we discovered\n",
        "            output_waveform = dia_model.generate(\n",
        "                text=stanza_text,\n",
        "                audio_prompt=cleaned_prompt_path,\n",
        "                temperature=1.1,\n",
        "                top_p=0.95,\n",
        "                cfg_scale=4.0,\n",
        "                verbose=True\n",
        "            )\n",
        "\n",
        "            output_path = \"dia_final_shona_output.wav\"\n",
        "            torchaudio.save(output_path, torch.tensor(output_waveform).unsqueeze(0), 48000)\n",
        "            print(f\"‚úÖ Shona audio generated and saved to: {output_path}\")\n",
        "\n",
        "            print(\"\\n--- üîä Playing Final Shona Audio ---\")\n",
        "            display(Audio(output_path))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå An error occurred during speech generation: {e}\")"
      ],
      "metadata": {
        "id": "zSMFA4VkSNlW"
      },
      "id": "zSMFA4VkSNlW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.3.6: Final Shona Hymn Generation (Stanza-by-Stanza) ---\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "from IPython.display import Audio, display\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# --- Ensure the Dia model and a clean prompt are available ---\n",
        "if 'Dia' not in locals() or 'dia_model' not in locals() or dia_model is None:\n",
        "    print(\"‚ùå Dia model not found. Please run a previous cell successfully first.\")\n",
        "else:\n",
        "    # Use the high-quality cleaned Shona prompt from the previous cell\n",
        "    cleaned_prompt_path = \"dia_cleaned_shona_prompt_5s.wav\"\n",
        "    if not os.path.exists(cleaned_prompt_path):\n",
        "        print(f\"‚ùå Cleaned Shona prompt file not found at '{cleaned_prompt_path}'. Please run the previous cell (5.3.5) first.\")\n",
        "    else:\n",
        "        print(\"‚úÖ Dia model and clean Shona prompt found. Proceeding with full hymn generation.\")\n",
        "\n",
        "        # --- Step 1: Define the Full Shona Hymn Text ---\n",
        "        shona_stanzas = [\n",
        "            \"Ndichamugamuchira, Nokuchingura nei? Ndichamunamati-ra, Nokubatira sei? SHE, mundiudze kwazvo, Muchanakirwa nei? Zvomunotenda nazvo, Ndingamufadza sei?\",\n",
        "            \"VeZion vakawadza Mashizha kareko; Neni handingaregi Kumuchingurawo. Nomwoyo wangu wose Ndichamuimbirai, Ndinoda kumukudza, Nokumurumbidzai!\",\n",
        "            \"Ndakanga ndakasungwa, Madzikunureni. Ndakanga ndakanyadzwa, Ndamutswa, She, nemi. Mandivigire fuma Yabva kudenga ko; Ndiyo yokusaora, nokusaperawo.\",\n",
        "            \"She Jesu uchauya Kuzotongesazve. Bva avo vakatenda Havangazomutyi. Uyai Tenzi Jesu! Kudenga tiisei, Kwatichafara isu, Tichinakirwa sei!\"\n",
        "        ]\n",
        "\n",
        "        # --- Step 2: Generate and Display Each Stanza Independently ---\n",
        "        print(\"\\nüéôÔ∏è Generating each Shona stanza with the high-quality prompt...\")\n",
        "\n",
        "        generated_files = []\n",
        "        for i, stanza_text in enumerate(shona_stanzas):\n",
        "            stanza_num = i + 1\n",
        "            print(f\"\\n   -> Generating stanza {stanza_num}/{len(shona_stanzas)}...\")\n",
        "\n",
        "            try:\n",
        "                # Generate the audio for the current stanza using the same clean prompt\n",
        "                output_waveform = dia_model.generate(\n",
        "                    text=stanza_text,\n",
        "                    audio_prompt=cleaned_prompt_path,\n",
        "                    temperature=1.1,\n",
        "                    top_p=0.95,\n",
        "                    cfg_scale=4.0,\n",
        "                    verbose=False\n",
        "                )\n",
        "\n",
        "                output_path = f\"dia_cloned_shona_stanza_{stanza_num}.wav\"\n",
        "                torchaudio.save(output_path, torch.tensor(output_waveform).unsqueeze(0), 48000)\n",
        "                print(f\"      ... Stanza {stanza_num} complete. Saved to: {output_path}\")\n",
        "                generated_files.append(output_path)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"      ... ‚ùå Error on stanza {stanza_num}: {e}\")\n",
        "                break\n",
        "\n",
        "        # --- Step 3: Display All Generated Audio Files ---\n",
        "        if generated_files:\n",
        "            print(\"\\n\\n--- üîä Final Shona Audio Output (Stanza-by-Stanza) ---\")\n",
        "            for file_path in generated_files:\n",
        "                stanza_num = file_path.split('_')[-1].split('.')[0]\n",
        "                print(f\"\\nStanza {stanza_num}:\")\n",
        "                display(Audio(file_path))\n",
        "\n",
        "        print(\"\\n‚úÖ Full Shona hymn generation process complete.\")"
      ],
      "metadata": {
        "id": "y8c9DoanotSQ"
      },
      "id": "y8c9DoanotSQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion: Dia TTS (The Unstable Powerhouse)\n",
        "- **Introduction:** `Dia TTS` is a large, expressive model also using in-context learning. It proved to be the most difficult and sensitive model to work with.\n",
        "\n",
        "- **Successes:**\n",
        " - Debugging Breakthroughs: The process of getting this model to work was a major research finding in itself. We successfully diagnosed and solved numerous issues, including the critical 48kHz sample rate requirement and the \"prompt contamination\" problem.\n",
        "\n",
        "- **Failures:**\n",
        "  - **Voice Cloning:** The cloned voice was \"not up to standard.\"\n",
        "  - **English Instability:** The model failed to consistently complete a single stanza in English. As observed, the output was erratic: it would start midway through the first line, end abruptly, and the clip lengths were inconsistent (8s, 22s, 7s, 5s). It never finished a full stanza.\n",
        " - **Shona Instability:** The performance on Shona was even worse. The model started deep into the stanzas, went silent, and in one case, produced \"high-pitched feedback.\" The output was fragmented and unusable.\n",
        " - **Default Voice:** Even with the default voice, the generation was unstable, producing a \"failed 1st clip with just a pss\" and a \"very animated and youthful female voice\" for the rest, which was inconsistent.\n",
        "\n",
        "- **Final Note:** `Dia TTS`, while powerful in theory, is too unstable and sensitive in its current state for this practical application. It requires a level of hyperparameter tuning and prompt engineering that is beyond the scope of a reliable workflow.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "BzGUEqwQ17NE"
      },
      "id": "BzGUEqwQ17NE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèÅ 5.4: Final Adjudication and TTS Model Recommendation\n",
        "\n",
        "### Evaluation Summary\n",
        "After conducting a series of case studies on three distinct Text-to-Speech models, a final evaluation was performed to determine the best candidate for the MonReader project. The models were compared on their ease of use, the quality of their English and Shona generation, and, most importantly, the accuracy of their voice cloning.\n",
        "\n",
        "The final audio outputs from each model were generated and are available for review in the preceding cells.\n",
        "\n",
        "### Final Ranking and Justification\n",
        "Based on a qualitative review of the final audio outputs, the models are ranked as follows:\n",
        "\n",
        "#### 1. ü•á Winner: Sesame/CSM\n",
        "\n",
        "- **Justification:** While its setup required cloning a specific repository, the Sesame/CSM model produced a significantly more natural and accurate clone of the target voice. The \"context chaining\" technique proved highly effective for generating a smooth, continuous English recitation. Although its performance on the full Shona hymn degraded towards the end, its initial Shona generation was strong, and its overall voice cloning quality was superior to the other models.\n",
        "\n",
        "#### 2. ü•à Runner-Up: Coqui XTTS\n",
        "\n",
        "- **Justification:** As noted, the Coqui XTTS setup was ultimately very easy. It produced consistently \"crisp\" and eloquent audio for the full hymn in both English and Shona without requiring any hyperparameter tuning. However, its primary weakness was in voice cloning; the output was clear but did not sound like the reference voice, instead producing a generic, default speaker.\n",
        "\n",
        "#### 3. ü•â Third Place: Dia TTS\n",
        "\n",
        "- **Justification:** Despite being a very powerful model, Dia TTS proved to be too unstable for this specific voice cloning task. As observed over many trials, it failed to consistently complete a single stanza in either English or Shona. The output was fragmented, often starting midway through a line, ending abruptly, and in the case of the full Shona hymn, degrading into high-pitched feedback. The extensive debugging required to produce even partial results makes it an unreliable choice for this project.\n",
        "\n",
        "### Final Recommendation\n",
        "The Sesame/CSM model is the recommended choice for all future work on the MonReader project. It provides the best balance of high-fidelity voice cloning and stable, high-quality audio generation, making it the best foundation for the final application and any subsequent fine-tuning work.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "MiagB4d6iU1J"
      },
      "id": "MiagB4d6iU1J"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéØ Phase 6: Enhanced Inference Conditioning for Shona Voice Cloning\n",
        "\n",
        "In this phase, instead of full LoRA fine-tuning, we enhance the CSM-1B inference process by **conditioning on a curated reference voice bank**.\n",
        "This method does not retrain the model or alter its weights.\n",
        "Instead, it uses:\n",
        "\n",
        "* A short prompt clip to set the initial voice characteristics.\n",
        "* A bank of multiple reference clips from the same speaker to **reinforce vocal timbre and accent** during generation.\n",
        "\n",
        "This approach allows us to:\n",
        "\n",
        "* Quickly test Shona pronunciation improvements without a lengthy training process.\n",
        "* Blend reference voice features into longer outputs like Hymn 66.\n",
        "* Experiment with prompt engineering, clip selection, and model temperature to control style.\n",
        "\n",
        "While this is **not LoRA fine-tuning** and does not adapt the model weights, it serves as a fast, low-cost method to approximate some benefits of training ‚Äî especially in scenarios where training code is unavailable or dataset preparation is still in progress."
      ],
      "metadata": {
        "id": "4ENQkzXSZPHP"
      },
      "id": "4ENQkzXSZPHP"
    },
    {
      "cell_type": "code",
      "source": [
        "# === 6.0 ‚Äî Normal Google Drive mount ===\n",
        "from google.colab import drive\n",
        "import time\n",
        "\n",
        "# if something is already mounted, unmount first\n",
        "try:\n",
        "    drive.flush_and_unmount()\n",
        "    time.sleep(1)\n",
        "except Exception:\n",
        "    pass  # fine if nothing was mounted\n",
        "\n",
        "# mount normally (you should see the Google login prompt)\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "print(\"‚úÖ Mounted at /content/drive\")"
      ],
      "metadata": {
        "id": "Ow0p5FUj20OG"
      },
      "id": "Ow0p5FUj20OG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6.1: Setup Sesame/CSM (official repo) + HF auth"
      ],
      "metadata": {
        "id": "vA7t__yZetpz"
      },
      "id": "vA7t__yZetpz"
    },
    {
      "cell_type": "code",
      "source": [
        "# === 6.1 Environment Setup ===\n",
        "# Clean start\n",
        "!rm -rf /content/csm\n",
        "!git clone https://github.com/SesameAILabs/csm.git\n",
        "%cd /content/csm\n",
        "\n",
        "# Install from the official repo (editable)\n",
        "!pip install -q -e .\n",
        "\n",
        "# Hugging Face login (put your token in Colab > Settings > Secrets > HF_TOKEN)\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "login(userdata.get(\"HF_TOKEN\"))\n",
        "\n",
        "# Pick device automatically (GPU if available)\n",
        "import torch\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)"
      ],
      "metadata": {
        "id": "7sRSDrj3WCoG"
      },
      "id": "7sRSDrj3WCoG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6.2 Prepare reference audio (10s, mono 24k) + Baseline (English)"
      ],
      "metadata": {
        "id": "vs4OFH7stpsL"
      },
      "id": "vs4OFH7stpsL"
    },
    {
      "cell_type": "code",
      "source": [
        "# === 6.2 ‚Äî Robust anchor discovery + fresh 24k mono prompt (Shona) ===\n",
        "import os, glob, subprocess, shlex, time\n",
        "from pathlib import Path\n",
        "\n",
        "# 0) Ensure Drive mounted (no-op if already mounted)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "except Exception:\n",
        "    pass\n",
        "time.sleep(0.3)\n",
        "\n",
        "def exists(p): return Path(p).exists()\n",
        "\n",
        "# 1) Prefer your Shona clip in Colab_Notebooks (m4a)\n",
        "SRC = \"/content/drive/MyDrive/Colab_Notebooks/Ndichamugamuchira_1.m4a\"\n",
        "candidates = [SRC] if exists(SRC) else []\n",
        "\n",
        "# 2) Fallbacks (optional): scan for any *ref*.wav in Drive\n",
        "candidates += sorted(glob.glob(\"/content/drive/MyDrive/**/*alvin*ref*.wav\", recursive=True))\n",
        "\n",
        "# 3) Pick a source\n",
        "if not candidates:\n",
        "    raise RuntimeError(\"No anchor candidate found. Upload a Shona clip (m4a/wav) to Drive.\")\n",
        "SRC = candidates[0]\n",
        "\n",
        "# 4) Paths that 6.3 & 6.6 will accept\n",
        "REF_WAV     = \"/content/alvin_voice_ref.wav\"          # 6.3 default\n",
        "REF_WAV_ALT = \"/content/alvin_voice_ref_shona.wav\"    # 6.6 alt default\n",
        "SHORT10     = \"/content/short_prompt_10s.wav\"         # legacy fallback\n",
        "\n",
        "# 5) Convert to 24k mono WAV (idempotent)\n",
        "cmd = f'ffmpeg -y -i \"{SRC}\" -ac 1 -ar 24000 -vn -map_metadata -1 \"{REF_WAV}\"'\n",
        "subprocess.run(shlex.split(cmd), check=True)\n",
        "\n",
        "# 6) Compatibility copy + short 10s\n",
        "import torchaudio, torch\n",
        "if not Path(REF_WAV_ALT).exists():\n",
        "    # copy without re-encoding\n",
        "    subprocess.run(shlex.split(f'cp \"{REF_WAV}\" \"{REF_WAV_ALT}\"'), check=True)\n",
        "\n",
        "wav, sr = torchaudio.load(REF_WAV)\n",
        "if wav.shape[0] > 1: wav = wav.mean(0, keepdim=True)\n",
        "if sr != 24000:\n",
        "    wav = torchaudio.transforms.Resample(sr, 24000)(wav); sr = 24000\n",
        "cut10 = wav[:, :min(wav.shape[-1], sr*10)]\n",
        "torchaudio.save(SHORT10, cut10, sr)\n",
        "\n",
        "# 7) Export globals for later cells\n",
        "REF_PROMPT = REF_WAV            # primary\n",
        "from pathlib import Path as _P\n",
        "BANK_DIR = _P(\"/content/ref_bank_shona\")  # this is what 6.4 will build\n",
        "BANK_COUNT = len(list(BANK_DIR.glob(\"*.wav\"))) if BANK_DIR.is_dir() else 0\n",
        "\n",
        "print(\"‚úÖ Prep ready\")\n",
        "print(f\"  ‚Ä¢ Anchor prompt (primary): {REF_PROMPT}\")\n",
        "print(f\"  ‚Ä¢ Compat alt: {REF_WAV_ALT}\")\n",
        "print(f\"  ‚Ä¢ Short 10s:  {SHORT10}\")\n",
        "print(f\"  ‚Ä¢ Bank (visible to 6.6): {BANK_DIR} ‚Äî {BANK_COUNT} clips\")"
      ],
      "metadata": {
        "id": "wcUBlM_ItzkZ"
      },
      "id": "wcUBlM_ItzkZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6.3 Shona probe + Hymn 66 (context chaining)"
      ],
      "metadata": {
        "id": "C2crFBlEt25L"
      },
      "id": "C2crFBlEt25L"
    },
    {
      "cell_type": "code",
      "source": [
        "# === 6.3 ‚Äî Shona probe + Hymn 66 (final: anchor-only, Shona guard, clause pacing) ===\n",
        "import re, unicodedata, numpy as np, torch, torchaudio\n",
        "from pathlib import Path\n",
        "from IPython.display import Audio, display\n",
        "from generator import Segment, load_csm_1b\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 3.1 Helpers\n",
        "# -------------------------------------------------\n",
        "WORDS_PER_SEC = 1.95   # ~117 wpm\n",
        "BUF_MS       = 600\n",
        "MIN_MS       = 3600\n",
        "SAFETY       = 1.20\n",
        "PAUSE_S      = 0.12    # 120 ms between clauses\n",
        "EDGE_TRIM_S  = 0.05\n",
        "TEMP         = 0.62    # steady diction\n",
        "GUARD_TXT    = \"Ndiri kutaura ChiShona.\"  # language lock (not chained)\n",
        "\n",
        "def to_24k_mono(wav, sr):\n",
        "    if wav.shape[0] > 1: wav = wav.mean(0, keepdim=True)\n",
        "    if sr != 24000: wav = torchaudio.transforms.Resample(sr, 24000)(wav)\n",
        "    return wav.squeeze(0)\n",
        "\n",
        "def trim_edges(wav, seconds=EDGE_TRIM_S):\n",
        "    n = int(seconds * 24000)\n",
        "    return wav[n:-n] if wav.numel() > 2*n else wav\n",
        "\n",
        "def peak_norm(w):\n",
        "    peak = float(w.abs().max());\n",
        "    return w if peak == 0 else w * (0.95/peak)\n",
        "\n",
        "def normalize_text(t: str) -> str:\n",
        "    t = unicodedata.normalize(\"NFKC\", t)\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    return t.replace(\"‚Äô\",\"'\").replace(\"‚Äú\",'\"').replace(\"‚Äù\",'\"')\n",
        "\n",
        "def calc_max_ms(text):\n",
        "    n = max(1, len(re.findall(r\"\\w+\", text)))\n",
        "    base = int(n / WORDS_PER_SEC * 1000 + BUF_MS)\n",
        "    return int(max(MIN_MS, base) * SAFETY)\n",
        "\n",
        "def split_clauses(text, max_words=14):\n",
        "    prim = re.split(r'([.!?;]+)\\s*', text.strip())\n",
        "    seq = []\n",
        "    for i in range(0, len(prim)-1, 2):\n",
        "        sent = (prim[i] + prim[i+1]).strip()\n",
        "        if not sent: continue\n",
        "        w = sent.split()\n",
        "        if len(w) <= max_words:\n",
        "            seq.append(sent); continue\n",
        "        parts = [p.strip() for p in sent.split(',') if p.strip()]\n",
        "        for p in parts:\n",
        "            ww = p.split()\n",
        "            if len(ww) <= max_words:\n",
        "                if not re.search(r'[.!?;]$', p): p += '.'\n",
        "                seq.append(p)\n",
        "            else:\n",
        "                for j in range(0, len(ww), max_words):\n",
        "                    chunk = ' '.join(ww[j:j+max_words]).strip()\n",
        "                    if chunk and not re.search(r'[.!?;]$', chunk): chunk += '.'\n",
        "                    if chunk: seq.append(chunk)\n",
        "    return [s for s in seq if s]\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 3.2 Device + Model\n",
        "# -------------------------------------------------\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "try:\n",
        "    del gen\n",
        "    torch.cuda.empty_cache()\n",
        "except:\n",
        "    pass\n",
        "gen = load_csm_1b(device=DEVICE)\n",
        "torch.manual_seed(1208)\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 3.3 Anchor prompt (robust to 6.2 outputs)\n",
        "# -------------------------------------------------\n",
        "from pathlib import Path\n",
        "REF_WAV     = \"/content/alvin_voice_ref.wav\"\n",
        "REF_WAV_ALT = \"/content/alvin_voice_ref_shona.wav\"\n",
        "SHORT10     = \"/content/short_prompt_10s.wav\"\n",
        "\n",
        "REF_PROMPT = globals().get(\"REF_PROMPT\", None)\n",
        "for cand in [REF_PROMPT, REF_WAV, SHORT10, REF_WAV_ALT]:\n",
        "    if isinstance(cand, str) and Path(cand).exists():\n",
        "        REF_PROMPT = cand\n",
        "        break\n",
        "assert REF_PROMPT and Path(REF_PROMPT).exists(), \"No prompt found. Run 6.2 first.\"\n",
        "\n",
        "p_wav, sr = torchaudio.load(REF_PROMPT)\n",
        "anchor = to_24k_mono(p_wav, sr)\n",
        "anchor = trim_edges(peak_norm(anchor), EDGE_TRIM_S)\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 3.4 Probe (isolated ‚Äî NOT reused in hymn)\n",
        "# -------------------------------------------------\n",
        "probe_text = (\"Kwaziwayi, zita rangu ndiAlvin. \"\n",
        "              \"Ndinoda ChiShona chakanaka.\")\n",
        "probe = gen.generate(\n",
        "    text=probe_text,\n",
        "    speaker=0,\n",
        "    context=[Segment(speaker=0, text=\"(anchor)\", audio=anchor)],\n",
        "    temperature=TEMP,\n",
        "    max_audio_length_ms=calc_max_ms(probe_text)\n",
        ")\n",
        "probe = (probe / (probe.abs().max() + 1e-7)).clamp(-1,1)\n",
        "PROBE_WAV = \"/content/shona_probe.wav\"\n",
        "torchaudio.save(PROBE_WAV, probe.unsqueeze(0).cpu(), 24000)\n",
        "print(\"‚úÖ Shona probe (isolated):\", PROBE_WAV)\n",
        "display(Audio(PROBE_WAV))\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 3.5 Hymn 66 (anchor-only, guard not chained)\n",
        "# -------------------------------------------------\n",
        "stanzas = [\n",
        "    \"Ndichamugamuchira, Nokuchingura nei? Ndichamunamatira, Nokubatira sei? She, mundiudze kwazvo, Muchanakirwa nei? Zvomunotenda nazvo, Ndingamufadza sei?\",\n",
        "    \"VeZion vakawadza Mashizha kareko; Neni handingaregi Kumuchingurawo. Nomwoyo wangu wose Ndichamuimbirai, Ndinoda kumukudza, Nokumurumbidzai!\",\n",
        "    \"Ndakanga ndakasungwa, Madzikunureni. Ndakanga ndakanyadzwa, Ndamutswa, She, nemi. Mandivigire fuma Yabva kudenga ko; Ndiyo yokusaora, nokusaperawo.\",\n",
        "    \"She Jesu uchauya Kuzotongesazve. Bva avo vakatenda Havangazomutyi. Uyai Tenzi Jesu! Kudenga tiisei, Kwatichafara isu, Tichinakirwa sei!\"\n",
        "]\n",
        "stanzas = [normalize_text(s) for s in stanzas]\n",
        "\n",
        "pause = torch.zeros(int(PAUSE_S * 24000))\n",
        "parts = []\n",
        "\n",
        "for i, stanza in enumerate(stanzas, 1):\n",
        "    print(f\"üéôÔ∏è Stanza {i}/{len(stanzas)} ‚Ä¶\")\n",
        "\n",
        "    # (A) Language guard to lock Shona ‚Äî generate it but DO NOT chain it\n",
        "\n",
        "    # Generate the guard clip ‚Äî note: not appended to final output automatically\n",
        "    guard_audio = gen.generate(\n",
        "        text=GUARD_TXT,\n",
        "        speaker=0,\n",
        "        context=[Segment(speaker=0, text=\"(anchor)\", audio=anchor)],\n",
        "        temperature=0.60,\n",
        "        max_audio_length_ms=1600\n",
        "    )\n",
        "\n",
        "    # Convert to numpy for optional diagnostics/playback (but not chaining)\n",
        "    guard_np = guard_audio.float().cpu().numpy().squeeze()\n",
        "\n",
        "    # (B) now the stanza, clause-by-clause, ANCHOR-ONLY context (no previous-output chaining)\n",
        "    for clause in split_clauses(stanza, max_words=14):\n",
        "        y = gen.generate(\n",
        "            text=clause,\n",
        "            speaker=0,\n",
        "            context=[Segment(speaker=0, text=\"(anchor)\", audio=anchor)],\n",
        "            temperature=TEMP,\n",
        "            max_audio_length_ms=calc_max_ms(clause)\n",
        "        )\n",
        "        y = (y / (y.abs().max() + 1e-7)).clamp(-1, 1)\n",
        "        parts += [y.cpu(), pause]\n",
        "\n",
        "# assemble\n",
        "final = torch.cat(parts[:-1]) if parts else torch.zeros(1)\n",
        "final = (final / (final.abs().max() + 1e-7)).clamp(-1,1)\n",
        "OUT = \"/content/hymn66_shona_chained.wav\"\n",
        "torchaudio.save(OUT, final.unsqueeze(0), 24000)\n",
        "print(\"‚úÖ Full hymn saved:\", OUT)\n",
        "display(Audio(OUT))"
      ],
      "metadata": {
        "id": "rbY0S6qWuA_8"
      },
      "id": "rbY0S6qWuA_8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.4 Build a Shona ‚Äúreference bank‚Äù (training-free adapter)"
      ],
      "metadata": {
        "id": "PS0mcz3a-4ri"
      },
      "id": "PS0mcz3a-4ri"
    },
    {
      "cell_type": "code",
      "source": [
        "# === 6.4 ‚Äî Build Shona reference bank (Demucs vocals if found; else from anchor) ===\n",
        "# Output: /content/ref_bank_shona/*.wav  (‚âà1.0s slices, 24k mono, normalized)\n",
        "\n",
        "from pathlib import Path\n",
        "import shutil, torch, torchaudio\n",
        "import torchaudio.transforms as T\n",
        "\n",
        "BANK_DIR = Path(\"/content/ref_bank_shona\")\n",
        "\n",
        "def ensure_empty_dir(p: Path):\n",
        "    if p.exists():\n",
        "        if p.is_symlink() or p.is_file():\n",
        "            p.unlink()\n",
        "        elif p.is_dir():\n",
        "            shutil.rmtree(p)\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def load_mono(path: Path):\n",
        "    w, sr = torchaudio.load(str(path))\n",
        "    if w.shape[0] > 1: w = w.mean(0, keepdim=True)\n",
        "    return w.squeeze(0), sr\n",
        "\n",
        "def resample(w, sr_in, sr_out=24000):\n",
        "    return (w if sr_in==sr_out else T.Resample(sr_in, sr_out)(w.unsqueeze(0)).squeeze(0), sr_out)\n",
        "\n",
        "def norm_peak(w):\n",
        "    peak = float(w.abs().max())\n",
        "    return w if peak==0 else w * (0.95/peak)\n",
        "\n",
        "def save_slices_1s(x_24k, out_dir: Path, prefix: str, win_sec=1.0, hop_sec=0.65, limit=48):\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    sr = 24000\n",
        "    win = int(win_sec*sr)\n",
        "    hop = int(hop_sec*sr)\n",
        "    i = 0\n",
        "    saved = 0\n",
        "    while i + win <= len(x_24k) and saved < limit:\n",
        "        seg = x_24k[i:i+win]\n",
        "        torchaudio.save(str(out_dir/f\"{prefix}_{saved:03d}.wav\"), seg.unsqueeze(0), sr)\n",
        "        saved += 1\n",
        "        i += hop\n",
        "    return saved\n",
        "\n",
        "# 1) Prefer your Demucs vocals\n",
        "VOCALS = Path(\"/content/drive/MyDrive/shona_youtube_source_separated/htdemucs/tambaoga_mwanangu/vocals.wav\")\n",
        "if not VOCALS.exists():\n",
        "    cands = sorted(Path(\"/content/drive/MyDrive/shona_youtube_source_separated/htdemucs\").rglob(\"vocals.wav\"))\n",
        "    VOCALS = cands[0] if cands else None\n",
        "\n",
        "# 2) Build bank\n",
        "ensure_empty_dir(BANK_DIR)\n",
        "saved = 0\n",
        "if VOCALS and VOCALS.exists():\n",
        "    print(\"üéØ Using Demucs vocals:\", VOCALS)\n",
        "    w, sr = load_mono(VOCALS)\n",
        "    if w.numel() >= int(2.0*sr):\n",
        "        w, _ = resample(w, sr, 24000)\n",
        "        w = norm_peak(w)\n",
        "        # Silero VAD (safe; if unavailable, we'll naive-slice)\n",
        "        try:\n",
        "            vad, utils = torch.hub.load('snakers4/silero-vad', 'silero_vad', force_reload=False, trust_repo=True)\n",
        "            (get_speech_timestamps, *_rest) = utils\n",
        "            w16 = T.Resample(24000, 16000)(w.unsqueeze(0)).squeeze(0)\n",
        "            ts = get_speech_timestamps(\n",
        "                w16.numpy(), model=vad, sampling_rate=16000,\n",
        "                threshold=0.5, min_speech_duration_ms=300,\n",
        "                min_silence_duration_ms=200, speech_pad_ms=80\n",
        "            )\n",
        "            if ts:\n",
        "                for seg_i, seg in enumerate(ts):\n",
        "                    s = int(seg['start'] * (24000/16000)); e = int(seg['end'] * (24000/16000))\n",
        "                    s = max(0, s); e = min(len(w), e)\n",
        "                    if e - s < int(0.60*24000):  # skip tiny regions\n",
        "                        continue\n",
        "                    saved += save_slices_1s(w[s:e], BANK_DIR, f\"speech_{seg_i}\", win_sec=1.0, hop_sec=0.65, limit=48 - saved)\n",
        "                    if saved >= 48: break\n",
        "            else:\n",
        "                print(\"‚ÑπÔ∏è VAD found no speech; naive slicing.\")\n",
        "                saved = save_slices_1s(w, BANK_DIR, \"demucs\", win_sec=1.0, hop_sec=0.65, limit=48)\n",
        "        except Exception:\n",
        "            print(\"‚ÑπÔ∏è Silero VAD unavailable; naive slicing.\")\n",
        "            saved = save_slices_1s(w, BANK_DIR, \"demucs\", win_sec=1.0, hop_sec=0.65, limit=48)\n",
        "\n",
        "# 3) Fallback: derive bank from the anchor (Shona-safe)\n",
        "if saved == 0:\n",
        "    print(\"‚ÑπÔ∏è Demucs vocals not found/empty; deriving bank from anchor.\")\n",
        "    REF_WAV = Path(\"/content/alvin_voice_ref.wav\")\n",
        "    if not REF_WAV.exists():\n",
        "        REF_WAV = Path(\"/content/alvin_voice_ref_shona.wav\")\n",
        "    assert REF_WAV.exists(), \"Anchor WAV missing; run 6.2 first.\"\n",
        "    w, sr = load_mono(REF_WAV)\n",
        "    w, _ = resample(w, sr, 24000)\n",
        "    w = norm_peak(w)\n",
        "    saved = save_slices_1s(w, BANK_DIR, \"anchor\", win_sec=1.0, hop_sec=0.65, limit=24)\n",
        "\n",
        "print(f\"‚úÖ Built Shona reference bank: {saved} clips -> {BANK_DIR}  ({'VAD slicing' if VOCALS and VOCALS.exists() else 'anchor slices'})\")\n",
        "for i, ex in enumerate(sorted(BANK_DIR.glob('*.wav'))[:6], 1):\n",
        "    print(f\"  {i}. {ex.name}\")\n",
        "\n",
        "# 4) Mirror to Drive for persistence (optional)\n",
        "DRIVE_BANK = Path(\"/content/drive/MyDrive/ref_bank_shona\")\n",
        "if DRIVE_BANK.exists():\n",
        "    if DRIVE_BANK.is_symlink() or DRIVE_BANK.is_file():\n",
        "        DRIVE_BANK.unlink()\n",
        "    elif DRIVE_BANK.is_dir():\n",
        "        shutil.rmtree(DRIVE_BANK)\n",
        "shutil.copytree(BANK_DIR, DRIVE_BANK)\n",
        "print(f\"üíæ Mirrored bank to Drive: {DRIVE_BANK}\")\n",
        "\n",
        "# Export for next cells\n",
        "BANK_DIR = BANK_DIR"
      ],
      "metadata": {
        "id": "5skytxLI-_NE"
      },
      "id": "5skytxLI-_NE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.5 Quick prep for inference (anchor & bank discovery)"
      ],
      "metadata": {
        "id": "eX7Q-B8zCK_s"
      },
      "id": "eX7Q-B8zCK_s"
    },
    {
      "cell_type": "code",
      "source": [
        "# === 6.5 ‚Äî Quick prep for 6.6 (anchor + bank wiring) ===\n",
        "from pathlib import Path\n",
        "import os, sys, shutil\n",
        "\n",
        "# Ensure repo import works\n",
        "if \"/content/csm\" not in sys.path:\n",
        "    sys.path.insert(0, \"/content/csm\")\n",
        "from generator import Segment, load_csm_1b  # sanity-import\n",
        "\n",
        "# Anchor candidates (prefer Shona)\n",
        "candidates = [\n",
        "    Path(\"/content/alvin_voice_ref_shona.wav\"),\n",
        "    Path(\"/content/alvin_voice_ref.wav\"),\n",
        "    Path(\"/content/short_prompt_10s.wav\"),\n",
        "    Path(\"/content/drive/MyDrive/alvin_voice_ref_shona.wav\"),\n",
        "    Path(\"/content/drive/MyDrive/alvin_voice_ref.wav\"),\n",
        "]\n",
        "REF_PROMPT = next((p for p in candidates if p.exists()), None)\n",
        "assert REF_PROMPT and REF_PROMPT.exists(), \"Missing anchor prompt. Run 6.2.\"\n",
        "\n",
        "# Bank: prefer local /content/ref_bank_shona; fallback to Drive\n",
        "LOCAL_BANK = Path(\"/content/ref_bank_shona\")\n",
        "DRIVE_BANK = Path(\"/content/drive/MyDrive/ref_bank_shona\")\n",
        "if not (LOCAL_BANK.is_dir() and any(LOCAL_BANK.glob(\"*.wav\"))):\n",
        "    if DRIVE_BANK.is_dir() and any(DRIVE_BANK.glob(\"*.wav\")):\n",
        "        if LOCAL_BANK.exists():\n",
        "            if LOCAL_BANK.is_symlink() or LOCAL_BANK.is_file():\n",
        "                LOCAL_BANK.unlink()\n",
        "            elif LOCAL_BANK.is_dir():\n",
        "                shutil.rmtree(LOCAL_BANK)\n",
        "        LOCAL_BANK.symlink_to(DRIVE_BANK, target_is_directory=True)\n",
        "\n",
        "num_bank = len(list(LOCAL_BANK.glob(\"*.wav\"))) if LOCAL_BANK.is_dir() else 0\n",
        "print(\"‚úÖ Prep ready\")\n",
        "print(f\"  ‚Ä¢ Anchor prompt: {REF_PROMPT}\")\n",
        "print(f\"  ‚Ä¢ Bank (visible to 6.6): {LOCAL_BANK} ‚Äî {num_bank} clips\")\n",
        "print(\"üëâ Now run 6.6.\")\n",
        "# Export names for 6.6\n",
        "BANK_DIR = LOCAL_BANK"
      ],
      "metadata": {
        "id": "-C8yE5uqCId8"
      },
      "id": "-C8yE5uqCId8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.6 Stable Shona generation (anchor-only default; optional bank)"
      ],
      "metadata": {
        "id": "bPoWw76yaV47"
      },
      "id": "bPoWw76yaV47"
    },
    {
      "cell_type": "code",
      "source": [
        "# === 6.6 ‚Äî Main generator ‚Äî Anti-mumble (visible progress + lighter budgets) ===\n",
        "import re, numpy as np, torch, torchaudio\n",
        "from pathlib import Path\n",
        "from IPython.display import Audio, display\n",
        "from generator import Segment, load_csm_1b\n",
        "\n",
        "# ---- Model & anchor ----\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "generator = load_csm_1b(device=DEVICE)\n",
        "\n",
        "assert 'REF_PROMPT' in globals() and Path(REF_PROMPT).exists(), \"No anchor prompt from 6.2/6.5.\"\n",
        "pw, sr = torchaudio.load(str(REF_PROMPT))\n",
        "\n",
        "def to_24k_mono(w, s):\n",
        "    if w.shape[0] > 1: w = w.mean(0, keepdim=True)\n",
        "    if s != 24000: w = torchaudio.transforms.Resample(s, 24000)(w)\n",
        "    return w.squeeze(0)\n",
        "\n",
        "anchor_prompt = to_24k_mono(pw, sr)\n",
        "\n",
        "# ---- Text helpers ----\n",
        "def guard_shona_text(s: str) -> str:\n",
        "    s = re.sub(r'\\bShe\\b', 'Ishe', s)\n",
        "    s = re.sub(r'Zion', 'Ziyoni', s, flags=re.I)\n",
        "    return s\n",
        "\n",
        "def split_into_sentences(text: str):\n",
        "    # Keep commas inside a sentence; split only on . ! ? ;\n",
        "    parts = re.split(r'([.!?;]+)\\s*', text.strip())\n",
        "    out = []\n",
        "    for i in range(0, len(parts)-1, 2):\n",
        "        sent = (parts[i] + parts[i+1]).strip()\n",
        "        if sent: out.append(sent)\n",
        "    return out\n",
        "\n",
        "# Words that drift ‚Äî give syllabified fallback\n",
        "HOTWORDS = {\n",
        "    \"mundiudze\":   \"mun-di-ud-ze\",\n",
        "    \"mandivigire\": \"man-di-vi-gi-re\",\n",
        "}\n",
        "\n",
        "def needs_fallback(txt: str) -> bool:\n",
        "    low = txt.lower()\n",
        "    return any(w in low for w in HOTWORDS.keys())\n",
        "\n",
        "def hyphenate_hotwords(txt: str) -> str:\n",
        "    low = txt.lower()\n",
        "    for w, syl in HOTWORDS.items():\n",
        "        low = low.replace(w, syl)\n",
        "    return low\n",
        "\n",
        "# ---- Dials (fuller sentences) ----\n",
        "TEMP_MAIN       = 0.56         # steady\n",
        "TEMP_RETRY      = 0.50         # safer retry\n",
        "WORDS_PER_SEC   = 1.25         # slower = more time to finish\n",
        "BUF_MS          = 1500\n",
        "MIN_MS          = 5800\n",
        "SAFETY          = 1.55\n",
        "FADE_MS         = 16\n",
        "TAIL_FADE_MS    = 120\n",
        "\n",
        "def calc_max_ms(txt):\n",
        "    n = max(1, len(re.findall(r\"\\w+\", txt)))\n",
        "    base = int(n/WORDS_PER_SEC*1000 + BUF_MS)\n",
        "    return int(max(MIN_MS, base) * SAFETY)\n",
        "\n",
        "def middle_crop(wav_24k, seconds=1.2):\n",
        "    need = int(seconds * 24000); L = wav_24k.shape[-1]\n",
        "    if L <= need: return wav_24k\n",
        "    s = (L - need)//2\n",
        "    return wav_24k[s:s+need]\n",
        "\n",
        "def xfade(prev_np, next_np, fade_ms=FADE_MS):\n",
        "    f = int(fade_ms*24)\n",
        "    if prev_np is None: return next_np\n",
        "    f = min(f, len(prev_np), len(next_np))\n",
        "    if f <= 0: return np.concatenate([prev_np, next_np])\n",
        "    out = prev_np.copy()\n",
        "    out[-f:] *= np.linspace(1.0, 0.0, f, dtype=prev_np.dtype)\n",
        "    nxt = next_np.copy()\n",
        "    nxt[:f] *= np.linspace(0.0, 1.0, f, dtype=nxt.dtype)\n",
        "    return np.concatenate([out, nxt])\n",
        "\n",
        "def trim_silence_np(y_np, sr=24000, thr_db=-38.0, min_head_ms=100, min_tail_ms=140):\n",
        "    if y_np.size == 0: return y_np\n",
        "    frame_ms, hop_ms = 20, 10\n",
        "    frame = max(1, int(sr*frame_ms/1000)); hop=max(1,int(sr*hop_ms/1000))\n",
        "    pad = (((len(y_np)-frame)//hop + 1)*hop + frame) - len(y_np)\n",
        "    if pad > 0: y_np = np.pad(y_np, (0, pad))\n",
        "    starts = np.arange(0, len(y_np)-frame+1, hop)\n",
        "    rms_db = np.array([20*np.log10(np.sqrt(np.mean(y_np[s:s+frame]**2)+1e-12)+1e-12) for s in starts])\n",
        "    above = np.where(rms_db >= thr_db)[0]\n",
        "    if len(above) == 0: return y_np[:1]\n",
        "    head = max(0, above[0]*hop - int(min_head_ms/1000*sr))\n",
        "    tail = min(len(y_np), above[-1]*hop + frame + int(min_tail_ms/1000*sr))\n",
        "    return y_np[head:tail].astype(np.float32)\n",
        "\n",
        "def fade_out_np(y_np, ms=TAIL_FADE_MS):\n",
        "    n = int(ms*24)\n",
        "    if y_np.size <= n: return y_np\n",
        "    y_np = y_np.copy()\n",
        "    y_np[-n:] *= np.linspace(1.0, 0.0, n, dtype=y_np.dtype)\n",
        "    return y_np\n",
        "\n",
        "def pause_len_for(text):\n",
        "    if re.search(r'[.!?]\\s*$', text): return 0.16\n",
        "    if re.search(r'[;:]\\s*$', text): return 0.10\n",
        "    if re.search(r',\\s*$', text):    return 0.06\n",
        "    return 0.08\n",
        "\n",
        "@torch.inference_mode()\n",
        "def generate_hymn_fast(full_text, anchor_audio, out_path=\"/content/hymn66_final_anchor.wav\"):\n",
        "    sentences = split_into_sentences(guard_shona_text(full_text))\n",
        "    a_mid = middle_crop(anchor_audio, 1.2)\n",
        "    assembled = np.zeros(int(0.12*24), dtype=np.float32)\n",
        "\n",
        "    for i, sent in enumerate(sentences, 1):\n",
        "        print(f\"üéôÔ∏è Sentence {i}/{len(sentences)} ‚Ä¶\")\n",
        "        ctx = [Segment(speaker=0, text=\"(anchor/full)\", audio=anchor_audio),\n",
        "               Segment(speaker=0, text=\"(anchor/mid)\",  audio=a_mid)]\n",
        "        max_ms = calc_max_ms(sent)\n",
        "        # word-based minimum we‚Äôll insist on:\n",
        "        n_words = max(1, len(re.findall(r\"\\w+\", sent)))\n",
        "        min_accept_sec = max(1.6, (n_words/WORDS_PER_SEC) * 0.95)\n",
        "\n",
        "        # first try\n",
        "        y = generator.generate(text=sent, speaker=0, context=ctx,\n",
        "                               temperature=TEMP_MAIN, max_audio_length_ms=max_ms)\n",
        "        cand = trim_silence_np(y.float().cpu().numpy().squeeze(),\n",
        "                               sr=24000, thr_db=-38.0, min_head_ms=100, min_tail_ms=140)\n",
        "\n",
        "        # retry if too short (anchors only, lower T, more ms)\n",
        "        if cand.size < int(min_accept_sec * 24000):\n",
        "            text_retry = hyphenate_hotwords(sent) if needs_fallback(sent) else sent\n",
        "            y2 = generator.generate(text=text_retry, speaker=0, context=ctx[:2],\n",
        "                                    temperature=TEMP_RETRY, max_audio_length_ms=int(max_ms*1.35))\n",
        "            cand2 = trim_silence_np(y2.float().cpu().numpy().squeeze(),\n",
        "                                    sr=24000, thr_db=-38.0, min_head_ms=110, min_tail_ms=150)\n",
        "            if cand2.size > cand.size:\n",
        "                cand = cand2\n",
        "\n",
        "        assembled = xfade(assembled, cand, fade_ms=FADE_MS)\n",
        "        if i < len(sentences):\n",
        "            assembled = np.concatenate([assembled, np.zeros(int(pause_len_for(sent)*24000), dtype=np.float32)])\n",
        "\n",
        "    final = assembled / (np.abs(assembled).max() + 1e-7)\n",
        "    final = fade_out_np(final, ms=TAIL_FADE_MS)\n",
        "    torchaudio.save(out_path, torch.tensor(final).unsqueeze(0), 24000)\n",
        "    print(f\"‚úÖ Saved: {out_path}\")\n",
        "    return out_path\n",
        "\n",
        "# ---- Text (same as before) ----\n",
        "H66_TEXT = \"\"\"Ndichamugamuchira, Nokuchingura nei? Ndichamunamatira, Nokubatira sei? She, mundiudze kwazvo, Muchanakirwa nei? Zvomunotenda nazvo, Ndingamufadza sei?\n",
        "VeZion vakawadza Mashizha kareko; Neni handingaregi Kumuchingurawo. Nomwoyo wangu wose Ndichamuimbirai, Ndinoda kumukudza, Nokumurumbidzai!\n",
        "Ndakanga ndakasungwa, Madzikunureni. Ndakanga ndakanyadzwa, Ndamutswa, She, nemi. Mandivigire fuma Yabva kudenga ko; Ndiyo yokusaora, nokusaperawo.\n",
        "She Jesu uchauya Kuzotongesazve. Bva avo vakatenda Havangazomutyi. Uyai Tenzi Jesu! Kudenga tiisei, Kwatichafara isu, Tichinakirwa sei!\n",
        "\"\"\".strip()\n",
        "\n",
        "out = generate_hymn_fast(H66_TEXT, anchor_prompt, \"/content/hymn66_final_anchor.wav\")\n",
        "display(Audio(out))\n"
      ],
      "metadata": {
        "id": "IN2LKOpKcAEe"
      },
      "id": "IN2LKOpKcAEe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.7 Post-processing & export (silence trim + gentle mastering)"
      ],
      "metadata": {
        "id": "ss3wawJ2acYZ"
      },
      "id": "ss3wawJ2acYZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# === 6.7 ‚Äî Trim + Smooth + Master (no ffmpeg) ===\n",
        "# Run this AFTER 6.6 writes /content/hymn66_final_anchor.wav (or your chosen file).\n",
        "\n",
        "import numpy as np, torch, torchaudio, re, math\n",
        "from pathlib import Path\n",
        "\n",
        "# ----------- Select input (auto-detect common names from your runs) -----------\n",
        "CANDIDATES = [\n",
        "    \"/content/hymn66_final_anchor.wav\",\n",
        "    \"/content/hymn66_final_baseline.wav\",\n",
        "    \"/content/h66_stable.wav\",\n",
        "    \"/content/hymn66_shona_chained.wav\",\n",
        "    \"/content/hymn66_final_bank.wav\",\n",
        "]\n",
        "SRC = next((Path(p) for p in CANDIDATES if Path(p).exists()), None)\n",
        "assert SRC is not None, \"No source WAV found. Make sure 6.6 finished and saved a file.\"\n",
        "\n",
        "# ----------- Controls (safe defaults) -----------\n",
        "SR                 = 24000\n",
        "DB_THR             = -40.0    # anything quieter than this is ‚Äúsilence‚Äù\n",
        "MIN_SIL_MS         = 300      # only cut gaps longer than this\n",
        "KEEP_HEAD_MS       = 70       # keep a little head before speech\n",
        "KEEP_TAIL_MS       = 90       # keep a little tail after speech\n",
        "BRIDGE_MS          = 120      # merge close speech islands separated by tiny gaps\n",
        "JOIN_CROSSFADE_MS  = 14       # smooth joins\n",
        "GLOBAL_HEAD_CUT_MS = 0        # set 120 to shave poor starts if needed (ms)\n",
        "\n",
        "def db_to_lin(db): return 10.0 ** (db / 20.0)\n",
        "\n",
        "def load_24k_mono(path: Path):\n",
        "    w, sr = torchaudio.load(str(path))\n",
        "    if w.shape[0] > 1:\n",
        "        w = w.mean(0, keepdim=True)\n",
        "    if sr != SR:\n",
        "        w = torchaudio.transforms.Resample(sr, SR)(w)\n",
        "    return w.squeeze(0).numpy()\n",
        "\n",
        "def frame_rms_db(x, frame_ms=20, hop_ms=10, sr=SR):\n",
        "    f = max(1, int(sr*frame_ms/1000))\n",
        "    h = max(1, int(sr*hop_ms/1000))\n",
        "    # pad so we can slide nicely\n",
        "    pad = (((len(x)-f)//h + 1)*h + f) - len(x)\n",
        "    if pad > 0: x = np.pad(x, (0, pad))\n",
        "    starts = np.arange(0, len(x)-f+1, h)\n",
        "    rms = np.sqrt(np.array([np.mean(x[s:s+f]**2) for s in starts]) + 1e-12)\n",
        "    db  = 20*np.log10(rms + 1e-12)\n",
        "    return db, f, h, len(x)\n",
        "\n",
        "def _merge_intervals(iv, min_gap_samp):\n",
        "    if not iv: return iv\n",
        "    out = [iv[0]]\n",
        "    for s,e in iv[1:]:\n",
        "        ps,pe = out[-1]\n",
        "        if s - pe <= min_gap_samp:\n",
        "            out[-1] = (ps, max(pe, e))\n",
        "        else:\n",
        "            out.append((s,e))\n",
        "    return out\n",
        "\n",
        "def _crop_head_tail(x, head_ms, tail_ms, sr=SR):\n",
        "    h = int(head_ms*sr/1000); t = int(tail_ms*sr/1000)\n",
        "    if len(x) <= h+t: return x\n",
        "    y = x.copy()\n",
        "    # head fade in\n",
        "    if h>0:\n",
        "        y[:h] *= np.linspace(0.0, 1.0, h, dtype=y.dtype)\n",
        "    # tail fade out\n",
        "    if t>0:\n",
        "        y[-t:] *= np.linspace(1.0, 0.0, t, dtype=y.dtype)\n",
        "    return y\n",
        "\n",
        "def _xfade_concat(a, b, ms, sr=SR):\n",
        "    if a is None:\n",
        "        return b\n",
        "    f = int(ms*sr/1000)\n",
        "    f = min(f, len(a), len(b))\n",
        "    if f <= 0:\n",
        "        return np.concatenate([a, b])\n",
        "    out = a.copy()\n",
        "    out[-f:] *= np.linspace(1.0, 0.0, f, dtype=out.dtype)\n",
        "    b2 = b.copy()\n",
        "    b2[:f] *= np.linspace(0.0, 1.0, f, dtype=b2.dtype)\n",
        "    return np.concatenate([out, b2])\n",
        "\n",
        "def gentle_master_np(y, sr=SR):\n",
        "    # high/low pass + soft limiter + -1 dBFS ceiling\n",
        "    x = torch.tensor(y, dtype=torch.float32).unsqueeze(0)  # (1,T)\n",
        "    x = torchaudio.functional.highpass_biquad(x, sr, cutoff_freq=70.0)\n",
        "    x = torchaudio.functional.lowpass_biquad(x, sr, cutoff_freq=10000.0)\n",
        "    # light gate for ultra-quiet tails\n",
        "    thr = db_to_lin(-45.0)\n",
        "    x = torch.where(x.abs() < thr, x * 0.2, x)\n",
        "    # soft limiter\n",
        "    k = 3.0\n",
        "    x = torch.tanh(k * x) / torch.tanh(torch.tensor(k))\n",
        "    # -1 dBFS\n",
        "    peak = x.abs().amax()\n",
        "    if peak > 0:\n",
        "        x = x * (db_to_lin(-1.0) / peak)\n",
        "    return x.squeeze(0).numpy()\n",
        "\n",
        "# ----------- Load, detect, cut, join -----------\n",
        "print(f\"üéß Source: {SRC}\")\n",
        "y = load_24k_mono(SRC)\n",
        "\n",
        "# Optional global head chop if the very beginning is rough\n",
        "if GLOBAL_HEAD_CUT_MS > 0 and len(y) > int(GLOBAL_HEAD_CUT_MS*SR/1000):\n",
        "    y = y[int(GLOBAL_HEAD_CUT_MS*SR/1000):]\n",
        "\n",
        "db, frame, hop, padded_len = frame_rms_db(y, frame_ms=20, hop_ms=10, sr=SR)\n",
        "mask = db >= DB_THR  # True where ‚Äúspeechy‚Äù\n",
        "# Build raw speech intervals in samples\n",
        "idx = np.where(mask)[0]\n",
        "intervals = []\n",
        "if idx.size:\n",
        "    start = idx[0]\n",
        "    prev  = idx[0]\n",
        "    for k in idx[1:]:\n",
        "        if k - prev > 1:\n",
        "            # end previous island\n",
        "            s = start*hop\n",
        "            e = prev*hop + frame\n",
        "            intervals.append((s,e))\n",
        "            start = k\n",
        "        prev = k\n",
        "    # last island\n",
        "    s = start*hop\n",
        "    e = prev*hop + frame\n",
        "    intervals.append((s,e))\n",
        "\n",
        "# Expand by KEEP_HEAD/Tail, then drop islands shorter than KEEP_HEAD+KEEP_TAIL\n",
        "exp = []\n",
        "for s,e in intervals:\n",
        "    s2 = max(0, s - int(KEEP_HEAD_MS*SR/1000))\n",
        "    e2 = min(padded_len, e + int(KEEP_TAIL_MS*SR/1000))\n",
        "    if e2 - s2 >= int(0.03*SR):  # keep only >30 ms\n",
        "        exp.append((s2,e2))\n",
        "\n",
        "# Merge islands that are close (‚â§ BRIDGE_MS)\n",
        "merged = _merge_intervals(exp, int(BRIDGE_MS*SR/1000))\n",
        "\n",
        "# Drop gaps shorter than MIN_SIL_MS from being removed (i.e., keep natural tiny pauses)\n",
        "final_iv = []\n",
        "for (s,e) in merged:\n",
        "    # keep as-is; we‚Äôll handle tiny pauses by letting JOIN_CROSSFADE_MS + inserted 80ms work\n",
        "    final_iv.append((s,e))\n",
        "\n",
        "# If nothing detected, fall back to original\n",
        "if not final_iv:\n",
        "    print(\"‚ö†Ô∏è No speech islands found above threshold; keeping original audio.\")\n",
        "    out = y.copy()\n",
        "else:\n",
        "    # Stitch with crossfades and preserve tiny micro-pause (~80ms) between islands\n",
        "    MICRO_PAUSE_SAMP = int(0.08*SR)\n",
        "    segments = []\n",
        "    for i,(s,e) in enumerate(final_iv):\n",
        "        seg = y[s:e]\n",
        "        # apply tiny head/tail taper to each segment to avoid clicks\n",
        "        seg = _crop_head_tail(seg, head_ms=KEEP_HEAD_MS, tail_ms=KEEP_TAIL_MS, sr=SR)\n",
        "        if i>0:\n",
        "            # add micro-pause buffer before joining\n",
        "            segments.append(np.zeros(MICRO_PAUSE_SAMP, dtype=seg.dtype))\n",
        "        segments.append(seg)\n",
        "\n",
        "    # Concatenate with crossfades at each join\n",
        "    out = None\n",
        "    for seg in segments:\n",
        "        out = _xfade_concat(out, seg, JOIN_CROSSFADE_MS, sr=SR)\n",
        "\n",
        "# Normalize and master\n",
        "if out.size > 0:\n",
        "    out = out / (np.abs(out).max() + 1e-7)\n",
        "    out = gentle_master_np(out, sr=SR)\n",
        "\n",
        "OUT = SRC.with_name(SRC.stem + \"_trim_master.wav\")\n",
        "torchaudio.save(str(OUT), torch.tensor(out).unsqueeze(0), SR)\n",
        "\n",
        "def secs(n):\n",
        "    m = int(n//60); s = n - 60*m\n",
        "    return f\"{m}:{s:05.2f}\"\n",
        "\n",
        "print(\"‚úÖ Done.\")\n",
        "print(f\"  ‚Ä¢ Input  : {secs(len(y)/SR)}  ({SRC.name})\")\n",
        "print(f\"  ‚Ä¢ Output : {secs(len(out)/SR)}  ({OUT.name})\")\n",
        "\n",
        "# Quick listen in Colab\n",
        "try:\n",
        "    from IPython.display import Audio, display\n",
        "    display(Audio(str(OUT)))\n",
        "except Exception:\n",
        "    pass"
      ],
      "metadata": {
        "id": "7mV1pDMHAB1P"
      },
      "id": "7mV1pDMHAB1P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 6 ‚Äî Inference Conditioning for Shona Voice Cloning üéôÔ∏èüáøüáº\n",
        "\n",
        "**Summary:** Instead of training new weights, we *condition* the CSM-1B model at inference using a short **anchor** clip (sets voice/timbre) plus a tiny **reference bank** of ~1-sec snippets (reinforces Shona tone & color). It‚Äôs fast, training-free, and reproducible ‚Äî great for long-form hymn narration with light post-processing.\n",
        "\n",
        "### How it works üß†‚û°Ô∏èüîä\n",
        "\n",
        "For each clause/sentence, we pass the **anchor** (and occasionally one **bank** clip) as context segments. The model then speaks the target text in the anchored voice, with timing budgets that favor complete lines and smoother joins.\n",
        "\n",
        "### What worked ‚úÖ\n",
        "\n",
        "* **Stable timbre early** in passages; less drift to English.\n",
        "* **Cleaner pacing** via clause budgets + crossfades.\n",
        "* **Quieter gaps** after a gentle post-trim.\n",
        "* Fully **training-free** and easy to rerun in Colab.\n",
        "\n",
        "### Rough edges ‚ö†Ô∏è\n",
        "\n",
        "* Occasional **early cut-offs / skipped words** (esp. after commas).\n",
        "* Some **phonetic drift** on hard words (e.g., *mundiudze*, *mandivigire*).\n",
        "* Banked runs can add **hesitation** on long reads; anchor-only is often clearer.\n",
        "* Over-tight trimming may shave soft syllables ‚Äî prefer the **‚Äúnatural‚Äù** preset.\n",
        "\n",
        "### ‚ÄúShip this‚Äù preset üö¢\n",
        "\n",
        "* **Mode:** Anchor-only for full hymns; bank for short promos.\n",
        "* **Dials:** `TEMP ‚âà 0.56‚Äì0.60`, `WORDS_PER_SEC ‚âà 1.4‚Äì1.5`, generous max-ms.\n",
        "* **Reliability:** 1 retry if a clause comes out too short (lower temp, longer budget).\n",
        "* **Polish:** Gentle mastering + **natural trim** to keep micro-pauses.\n",
        "\n",
        "### Light roadmap üî≠\n",
        "\n",
        "* Small **LoRA/PEFT** on Shona to lock phonics.\n",
        "* Add **phoneme/G2P** or a tiny lexicon for tricky words.\n",
        "* **Alignment-guided** durations to avoid early EOS.\n",
        "* Curate bank for **steady vowels** + matched loudness.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "tEMq6czbXBt8"
      },
      "id": "tEMq6czbXBt8"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}